* Deutung der allgemeinen Themen im Rahmen der politischen Debatten zu Rechenzentren in Deutschland

Dieses Dokument stellt ein Workflow zur Deutung der allgemeinen Themen im Rahmen der politischen Debatten zu Rechenzentren in Deutschland dar. Wir verwenden die Ergebnisse aus unserem [[file:02-WF-Rech-BT.org][zweiten Workflow]] zur Topic-Modell-Analyse der Debatten zu Rechenzentren in Deutschland. Wie unsere zwei ersten Workflow kann dieses Workflow als Anwendung verwendet werden (s. u.).

** Vorgehen

Am Ende von unserer Topic-Modell-Analyse haben wir die Ergebnisse bzw. die Topics jeder Wahlperiode zu einer KI gesendet, die die Zusammenstellung von Begriffen nach gemeinsamer Bedeutung prüfen sollte. Die Berichte der KI haben wir gelesen und korrigiert haben, wo es sein musste. Diese Berichte wollen wir mit zwei Zielen behandeln:

- Ziel 1: welche -- wichtige bzw. zentrale oder unwichtige bzw. nicht zentrale --  Bedeutung solche Rahmenthemen in diesen Debatten gehabt haben? Zur Beantwortung dieser Frage vergleichen wir die Dokumente miteinander. Diese Analyse versucht Ähnlichkeiten zwischen Dokumenten zu vergleichen.
- Ziel 2: im Rahmen der Debatten, die mit Bezug auf die Rechenzentren in Deutschland entwickelt wurden, können spezifischere Rahmenthemen erkannt werden? Zur Beantwortung dieser Frage vergleichen wir die Sätze der Dokumente miteinander, um ähnliche semantischen Sätze in Clusters ohne Berücksichtigung derer Angehörigkeit zu bestimmten Dokumenten zu klassifizieren.

Wir vergleichen dann beide Ergebnisse (Ähnlichkeit der Dokumente und Ähnlichkeit der Sätze), um den Platz deuten zu können, den spezifische Themen zu Rechenzentren in den Protokollen des Bundestages von 1949 bis heute gehabt haben bzw. um ihren Gewicht in den Debatten des Bundestages auf lange Sicht besser verstehen zu können.

** Dieses Workflow als Anwendung benutzen

Dieses Workflow kann wie eine Anwendung verwendet werden. Erforderlich dafür ist die Installation vom Texteditor Emacs mit Org-mode (ab emacs-28 ist Org-mode mit dem Texteditor geliefert und muss nicht separat installiert werden). Dieses Workflow kann auf der Kommandozeile mit dem folgenden Skript 'bert-rech.sh' ausgeführt werden. Ein solcher Skript wird im Arbeitsordner hergestellt, den wir im Folgenden mit diesem Code-Block herstellen:

#+name: user-path
#+begin_src shell :var user="/home/cpsoz/ROM-Data" :results silent
  mkdir $user/BERT-Analyse
#+end_src

Unsere Analyse wird in diesem Ordner 'BERT-Analyse' stattfinden. Dort stellen wir einen Ordner 'BERT-Skripten' für die Skripten, die wir im Rahmen von diesem Workflow schreiben werden, und wir definieren den vollständigen Pfad zum Ordner 'BERT-Analyse' als neuen Benutzerpfad:

#+name: nuser
#+begin_src shell :var nuserpath="/home/cpsoz/ROM-Data/BERT-Analyse" :results silent
  echo $nuserpath
#+end_src

#+name: bert-skripten
#+begin_src shell :var userpath=nuser :results silent
  mkdir $userpath/BERT-Skripten
#+end_src

Wichtig: wie in den zwei ersten Workflow müssen Pfade von Benutzern des Workflows angepasst werden.

Dann schreiben wir den 'bert-rech.sh' Skript:

#+begin_src shell :results silent :var user=nuser
  touch $user/bert-rech.sh
  echo "#!/bin/bash" >> $user/bert-rech.sh
  echo 'emacs --batch \' >> $user/bert-rech.sh
  echo "      --eval \"(require 'org)\" \ " >> $user/bert-rech.sh
  echo "      --eval \"(setq org-confirm-babel-evaluate nil)\" \ " >> $user/bert-rech.sh
  echo "      --eval '(org-babel-tangle-file \"03-WF-Rech-TM.org\")' \ " >> $user/bert-rech.sh
  chmod +x $user/bert-rech.sh
#+end_src

#+begin_src shell :results silent :var user=nuser
  touch $user/bert-rech.sh
  echo "#!/bin/bash" >> $user/bert-rech.sh
  echo "emacs /home/cpsoz/Gitub/rom/Methodologie/03-WF-Rech-TM.org --batch -l /home/cpsoz/.emacs.d/init.el --eval \"(setq org-confirm-babel-evaluate nil)\" --eval \"(org-babel-execute-buffer)\"" >> $user/bert-rech.sh
  chmod +x $user/bert-rech.sh
#+end_src

Dieser Skript führt alle Code-Blöcke in diesem Workflow aus. Er kann entsprechend mit bash verwendet werden, wie etwa: bash bert-rech.sh (hier muss das Workflow im gleich Verzeichnis sein, in dem bert-rech.sh sich befindet).

Im Rahmen dieser Analyse verwenden wir einen ersten python-Skript für die Berechnung der Ähnlichkeit zwischen den Berichten der KI (TeSi.py) und einen zweiten python-Skript für die semantischen Ähnlichkeiten zwischen Sätzen aus diesen Berichten (SCT.py). Beide Skripten befinden sich in einem Ordner 'Workflow_RES', weshalb wir sie zu unserem Ordner 'BERT-Skripten' kopieren

#+name: bert-copy
#+begin_src shell :var mtap="/home/cpsoz/Workflow_RES" :var user=nuser :results silent
  cp $mtap/TeSi.py $user/BERT-Skripten && cp $mtap/SCT.py $user/BERT-Skripten
#+end_src

* Ziel 1. Bedeutung von Rahmenthemen zum Thema Rechenzentren in Deutschland

Um unser erstes Ziel zu erreichen, verwenden wir unseren TeSi.py-Skript auf die Berichte der KI. Da TeSi stopwords braucht, um die Analyse durchzuführen, schreiben wir einen Code-Block zum Pfad der Stopwords auf unserem Rechner:

#+name: stops
#+begin_src shell :var stopwords="/home/cpsoz/Org/Stopwords" :results silent
  echo $stopwords
#+end_src

Dann verwenden wir TeSi automatisch mit einer Datei 'tesi.txt', in der wir die Befehle schreiben, die TeSi braucht, um die Analyse durchzuführen; anschließend führen wir diese Analyse durch:

#+name: tesi
#+begin_src shell :var mtaki="/home/cpsoz/ROM-Data/TM-Analyse/MTA-KI" :var user=nuser :var stopw=stops mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  touch $user/BERT-Skripten/tesi.txt
  echo $mtaki"/*" >> $user/BERT-Skripten/tesi.txt
  echo "y" >> $user/BERT-Skripten/tesi.txt
  echo $stopw"/de.txt" >> $user/BERT-Skripten/tesi.txt
  echo "4" >> $user/BERT-Skripten/tesi.txt
  cat $user/BERT-Skripten/tesi.txt | python3 $user/BERT-Skripten/TeSi.py
  mv $mtadir/TeSi-Results* $user/
#+end_src

Damit haben wir eine bessere Sicht zu den Berichten der KI, die wenige Ähnlichkeiten zwischen Berichten zeigt -- die interessantesten Ergebnisse betreffen die Datei mit Ähnlichkeiten von 0.2 bis 0.29 auf einer Skala von 0.0 bis 1.0. Dort befinden sich schwache Verbindungen zwischen Berichten, die jedoch nicht zufällig entstanden sind. Über 0.3 gibt es eine Verbindung zwischen zwei Berichten mit einer Ähnlichkeit zwischen 0.4 bis 0.49, die jedoch das Thema der Rechenzentren oder Themen, die damit verbunden wären (wie Technologie, Rechner, Fortschritt usw.) nicht betreffen. Unter 0.2 gibt es sehr viele Verbindungen zwischen Berichten, die jedoch von weniger Relevanz sind, da es hier davon ausgegangen kann, dass solche Verbindungen aufgrund von sehr allgemeinen Merkmalen der Berichte der KI hergestellt werden (etwa es sind wahrscheinlich Protokolle von Debatten auf der politischen Ebene, die Themen der Wirtschaft, der Wissenschaft usw. betreffen).

Ein solches Ergebnis zeigt, dass wir viel Rausch in unserer Topic-Modell-Analyse haben bzw. dass das Thema Rechenzentren in Deutschland wahrscheinlich nur eine bescheidene Rolle spielt in den Debatten im Bundestag. Dies wollen wir jetzt vertiefen, und dafür wenden wir eine Analyse der semantischen Bedeutung der Berichte. Sie wird uns zum Ziel 2 bringen.

* Ziel 2. Spezifische Themen zum Oberthema Rechenzentren in Deutschland

Ähnlich wie bei unserem 'tesi' Code-Block bereiten wir einen Code-Block für die automatische Durchführung des SCT.py-Skript vor. Im Unterschied zum 'tesi' Code-Block brauchen wir keine Variable für den Pfad zu den Stopwords zu definieren, da unser Skript keine Stopword benutzt. Wir definieren Wörter und Wörterwurzel, die wir den SCT.py-Skript senden, damit er die Sätze in den Berichten zu den Topics aufnimmt, die diese Wörter und entsprechende Wörter mit der gegebenen Wurzel enthalten. Wir geben weiter die minimale Anzahl an Sätzen je Cluster, die wir bilden wollen (hier 2, weil wir wenige Dokumente haben), und wir geben das Koeffizient zwischen 0.0 und 0.99 für die Verbindung zwischen Sätzen an. Wenn dieses Koeffizient hoch ist, dann sucht SBERT nach Sätzen, die inhaltlich eng miteinander verbunden sind. Da wir im Ziel 1 gesehen haben, dass das Thema Rechenzentren wahrscheinlich eher am Rande der Debatten des Bundestages auftaucht, die wir modelliert haben, wählen wir ein Koeffizient von 0.4 für eine schwache jedoch nicht zufällige inhaltliche Verbindung zwischen Sätzen, die die Cluster bilden.

Wir können den Code-Block 'sct' mit diesen Informationen herstellen und ausführen:

#+name: sct
#+begin_src shell :var mtaki="/home/cpsoz/ROM-Data/TM-Analyse/MTA-KI" :var user=nuser mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  touch $user/BERT-Skripten/sct.txt
  echo $mtaki"/*" >> $user/BERT-Skripten/sct.txt
  echo "y" >> $user/BERT-Skripten/sct.txt
  echo "1" >> $user/BERT-Skripten/sct.txt
  echo "digit rechner rechenzentr techn computer informatik" >> $user/BERT-Skripten/sct.txt
  echo "2" >> $user/BERT-Skripten/sct.txt
  echo "2" >> $user/BERT-Skripten/sct.txt
  echo "0.4" >> $user/BERT-Skripten/sct.txt
  echo "0" >> $user/BERT-Skripten/sct.txt
  cat $user/BERT-Skripten/sct.txt | python3 $user/BERT-Skripten/SCT.py
  mv $mtadir/KI-Results* $user/
#+end_src

Entsprechend erhalten wir die Cluster mit variablen Sätzen, die SBERT mit einem Koeffizient von 0.4 miteinander verbindet. Dieses Ergebnis vergleichen wir jetzt mit dem Ergebnis aus unserem ersten Ziel in dem folgenden Code-Block:

#+name: comp
#+begin_src shell :var user=nuser :var user_res="/home/cpsoz/ROM-Data/BERT-Analyse" :results none
  a=`awk '{print $1}' $user/Ki-Results*/Clusters_Years*.txt`
  b=`awk -F, '{print $1}' $user/TeSi-Results*/Corr_02_*.csv`
  c=`awk -F, '{print $2}' $user/TeSi-Results*/Corr_02_*.csv`
  echo "$a" | grep -Fx "$b" | awk '!seen[$0]++' > $user_res/comp_1
  echo "$a" | grep -Fx "$c" | awk '!seen[$0]++' > $user_res/comp_2
  cat $user_res/comp_1 $user_res/comp_2 | awk '!seen[$0]++' > $user_res/comp_3.csv && rm $user_res/comp_1 $user_res/comp_2
#+end_src

Um eine visuelle Darstellung des Ergebnisses von diesem Vergleich herzustellen, schreiben wir den folgenden Code-Block zur Hervorhebung der konvergenten Gemeinsamkeiten aus dem ersten und dem zweiten Ziel, den wir dann zu einem Skript tangeln (mit C-c C-v t):

#+name: convergences
#+begin_src python :tangle /home/cpsoz/ROM-Data/BERT-Analyse/BERT-Skripten/Pdf_high.py :results silent
  #!/usr/bin/env python
  import pymupdf
  import pandas
  incoming = input("Path to pdf source: ")
  in_data = input("Path to comparison data: ")
  outgoing = input("Path to pdf result: ")
  pdf_plot=pymupdf.open(incoming)
  page = pdf_plot[0]
  color = (pymupdf.pdfcolor["pink"])
  colnames = ['year']
  data = pandas.read_csv(in_data, names=colnames)
  year_lst = data.year.tolist()
  for i in year_lst:
    rects = page.search_for(i)
    annot = page.add_highlight_annot(rects)
    annot.set_colors(stroke=color)
    annot.update()
  pdf_plot.save(outgoing)
#+end_src

Wir führen dann den Vergleich durch, den wir als die Netzwerkkarte 'Network_highlight.pdf' abdrucken:

#+name: pdf_plot_highlight
#+begin_src shell :var tesipath="/home/cpsoz/Github/rom/Methodologie" :var user=nuser :results none
  chmod +x $user/BERT-Skripten/Pdf_high.py
  d=`ls $tesipath/TeSi-Results*/Networkg_02*.pdf`
  echo "$d" >> $user/BERT-Skripten/pdf_high.txt
  echo $user"/comp_3.csv" >> $user/BERT-Skripten/pdf_high.txt
  echo $user"/Network_highlight.pdf" >> $user/BERT-Skripten/pdf_high.txt
  cat $user/BERT-Skripten/pdf_high.txt | python3 $user/BERT-Skripten/Pdf_high.py
#+end_src

Das Ergebnis bestätigt, dass wir viel Rausch in unseren Daten haben, selbst wenn bestimmte Themen zu Rechenzentren auftauchen und eine unterschiedliche Bedeutung zeigen:

- Topics 3 der 13 WP und 4 der 18 WP sind mit wichtigen Themen der Debatten in BT verbunden;
- Topics 2 der 18 und 20 WP und Topic 3 der 17 WP sind mit weniger wichtigen Themen der Debatten in BT verbunden;
- Topics 1 und 4 der 17 WP sind mit Themen der Debatten in BT verbunden, die im Vergleich mit den anderen Topics deutlich weniger wichtig sind.

Dieses Ergebnis zeigt, dass die Themen, die mit den Rechenzentren verbunden sind, in ihrer Mehrheit einer spezifischen Agenda angehören, die meistens am Rande der herrschenden Themen der Debatten im BT angesiedelt sind. Um mehr zu diesen Themen zu wissen, müssen wir dann den Rausch in unserer Daten reduzieren. Dies machen wir, wenn wir nur Teile von den Protokollen nehmen, in denen die Rechenzentren explizit erwähnt werden. Dies machen wir im Folgenden.


* TM-Analyse auf Teile von Protokollen, die die Rechenzentren explizit erwähnen. Training der Modelle

Wir müssen zuerst die Dateien aus unserem Ordner 'Rechenzentren' sortieren, die die Rechenzentren explizit erwähnen. Wir schreiben einen ersten Code-Block, in dem wir einen Ordner 'Rechenzentren_Teile' herstellen, wo wir die relevanten Dateien aus dem Ordner 'Rechenzentren' speichern:

#+name: mata-data-2
#+begin_src shell :var romdata="/home/cpsoz/ROM-Data" :var rechpath="/home/cpsoz/ROM-Data/Rechenzentren" :results silent
     mkdir $romdata/Rechenzentren_Teile
     teile=`grep -rl '[Rr]echenzentr' $rechpath`
     echo "$teile" | while IFS= read -r line ; do cp $line $romdata/Rechenzentren_Teile/; done
#+end_src

Wir [[https://github.com/cp1972/mta-app/blob/main/automate.md][automatisieren]] MTA mit der folgenden 'mta-train.txt'-Datei, und wir stellen einen Ordner 'BERT-TM-Skripten' her, um unsere Dateien und Skripten für die TM Analyse in diesem Ordner zu speichern:

#+name: autotrain-01
#+begin_src shell :var user=nuser :var rech="/home/cpsoz/ROM-Data/Rechenzentren_Teile" :var stopw=stops :results silent
  mkdir $user/BERT-TM-Skripten
  touch $user/BERT-TM-Skripten/mta-train.txt
  echo $rech"/*" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-train.txt
  echo $stopw"/de.txt" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "5" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "de" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "a" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "1" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "15" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "4" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "0" >> $user/BERT-TM-Skripten/mta-train.txt
#+end_src

Diese Datei trainiert MTA mit Modellen, die von 2 bis 15 Topics reichen. Wir führen MTA mit dieser Datei im folgenden Code-Block aus:

#+name: trainmta
#+begin_src shell :var user=nuser :var usermta="/home/cpsoz/ROM-Data/TM-Analyse/TM-Skripten" :results none
  cat $user/BERT-TM-Skripten/mta-train.txt | python3 $usermta/MTA.py
#+end_src

Aus den Ergebnissen von MTA nehmen wir aus der Datei 'Summary*.log' die relevanten Informationen zu den optimalen Zahlen der Topics je Kreuzvalidierungsmethode, die MTA verwendet. Wir übernehmen auch die Information zu der besten Anzahl der Topics nach Cophenet Korrelationskoeffizient. Wir speichern diese Informationen in einer Datei 'TM-train-scores.txt'.

#+name: trainscores
#+begin_src shell :var mtadir="/home/cpsoz/Github/rom/Methodologie" :var user=nuser :results silent
  echo " " >> $user/BERT-TM-train-scores.txt
  cat $mtadir/MTA-Results*/Summary*.log | sed -n '/Elbow /,/Correlation values LDA/p' | awk 'NF' | awk '{$1=$1;print}' >> $user/BERT-TM-train-scores.txt
  echo "------" >> $user/BERT-TM-train-scores.txt
  echo " " >> $user/BERT-TM-train-scores.txt
  find $mtadir -type d -name "MTA-Results*" -exec rm -r {} +
#+end_src

Wir können dann die Ergebnisse aus der Datei 'TM-train-scores.txt' mit dem folgenden Code-Block lesen.

#+name: mta-scores
#+begin_src shell :var user=nuser :results drawer
    cat $user/BERT-TM-train-scores.txt
#+end_src

#+RESULTS: mta-scores
:results:

Elbow | No optimal topic
Silhouette | Optimal topics, better to worst: 6 8 10 11 12 13 14
Calinski Harabasz | Optimal topics, better to worst: 13 14
Davies Bouldin | Optimal topics, better to worst: 3 4 5 6 8 10 11 12 13 14
NMF-Cophenet | Optimal topics, better to worst: 3 5 6 7 10 12 13
Correlation values NMF-Cophenet: (0.7172416876046004, 0.6107818751672857, 0.6411485869549876, 0.6314090328283718, 0.7760202232221576, 0.7284745654214617, 0.763058470800228)
LDA-Cophenet | Optimal topics, better to worst: 3 8 11 13
Correlation values LDA-Cophenet: (0.6291944961666273, 0.8664864589342771, 0.7144070029386059, 0.9145840305388004)
------

:end:

Wir können jetzt die Dateien mit dem optimalen Anzahl an Topics modellieren.

* Modellierung

Dafür stellen wir eine veränderte Version von unserem Code-Block 'autotrain-01', die wir 'autotest-01' benennen:

#+name: autotest-01
#+begin_src shell :var user=nuser :var rech="/home/cpsoz/ROM-Data/Rechenzentren_Teile" :var stopw=stops :results silent
  touch $user/BERT-TM-Skripten/mta-test.txt
  echo $rech"/*" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-test.txt
  echo $stopw"/de.txt" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "5" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "de" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "a" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "1" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "10" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "2" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "12" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "0" >> $user/BERT-TM-Skripten/mta-test.txt
#+end_src

Dann modellieren wir den ersten Ordner:

#+name: testnmta
#+begin_src shell :var user=nuser :var usermta="/home/cpsoz/ROM-Data/TM-Analyse/TM-Skripten" :results none
  cat $user/BERT-TM-Skripten/mta-test.txt | python3 $usermta/MTA.py
#+end_src

Wir stellen einen Ordner 'MTA-Results' im Ordner BERT-TM-Analyse, um dort die Ergebnisse aus der Modellierung für jeden Subordner vom Ordner 'Rechenzentren' zu speichern:

#+name: mtaresults
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  mkdir $user/MTA-Results
  mv $mtadir/MTA* $user/MTA-Results/
#+end_src

Wir können jetzt die Ergebnisse interpretieren.

* Interpretation der Ergebnisse

Wir automatisieren die Interpretation der Ergebnisse mit einer KI. Dafür haben wir die [[https://github.com/aandrew-me/tgpt][Anwendung tgpt]] installiert, die wir programmatisch verwenden können. In einem ersten Schritt stellen wir den Ordner 'MTA-KI' her, in dem wir die Ergebnisse von unserer Interpretation der Topic-Modell-Analyse speichern werden:

#+name: mta-ki-results
#+begin_src shell :var user=nuser :results none
  mkdir $user/MTA-KI
#+end_src

Wir zerlegen die Datei 'Top_Words_NMF_Topics_*.csv' so, dass wir ein Dokument mit ".out" Endung je Säule der Datei 'Top_Words_NMF_Topics_*.csv' herstellen. Dann passen wir den Inhalt von diesen ".out"-Dateien zur KI und wir speichern die Deutung der KI in einem Dokument. Zuerst schreiben wir den Skript, um die Ergebnisse von MTA zur KI zu senden und die Antworten der KI in eine Datei 'MTA-KI' zu schreiben:

#+name: mta-ki-interpret
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/" :var user=nuser :var mtaint="01-MTA-KI.txt" :var mtcut="01-MTA-KI-" :results none
  cd $mtares/MTA-*
  cp Top_Words_NMF_Topics_*.csv TW.txt
  sed -i '1d' TW.txt
  awk -F, '{for (i=1;i<=NF;i++) print $i > i".out"}' TW.txt
  for x in *.out; do echo -e "\nTOPIC '${x%.*}'\n" >> MTA-KI.txt && awk 'BEGIN { ORS = " " } { print }' "$x" | tgpt -q "welche thematischen Gemeinsamkeiten erkennst du zwischen diesen Wörtern" >> MTA-KI.txt; done
  rm TW.txt *.out
  mv MTA-KI.txt $user/MTA-KI/ && cd $user/MTA-KI/ && mv MTA-KI.txt $mtaint
  csplit $mtaint /TOPIC/ '{*}' --prefix $mtcut -b "%02d.txt" && rm $mtaint && rm *-KI-00.txt
#+end_src

An diesem Punkt empfiehlt sich, die Interpretation durch die KI zu kontrollieren bzw. zu korrigieren, und nicht nützliche Informationen aus der Dateien zu entfernen (etwa die Wiederholung der Wortlisten, die wir mit der Modellierung generiert haben).

Einmal die Kontrolle der Berichte erfolgt, bilden wir die für das Thema der Rechenzentren aussagkräftigsten Topics:

#+name: copy-dt
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/" :results silent
  cd $mtares/MTA-*
  cp Dominant_Topics_NMF_*.csv $mtares/DT.csv
#+end_src

Wir bilden einmal alle neun Topics ab:

#+name: trends-9t
#+begin_src python :var dt="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/DT.csv" :var saveplot="/home/cpsoz/ROM-Data/BERT-Analyse/Trends9T.pdf" :results Trends9T.pdf file
  import matplotlib.pyplot as plt
  import matplotlib.patches as mpatches
  import numpy as np
  import seaborn as sns
  import pandas as pd
  import csv
  from matplotlib import rc

  # Schrift
  #rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
  rc('font',**{'family':'serif','serif':['Times'],'size':9})
  rc('text', usetex=True)

  path = dt
  pathplot = saveplot
  df = pd.read_csv(path)
  df.rename(columns={ df.columns[0]: "Dokumente" }, inplace = True)
  df.drop('Dominant_Topic_NMF', axis=1, inplace=True)
  df['Jahr'] = df['Dokumente']
  df['Proto'] = df['Dokumente']
  df['Jahr']= df['Jahr'].map(lambda x: str(x)[0:4])
  df['Jahr'].astype(int)
  df['Proto']= df['Proto'].map(lambda x: str(x)[6:14])
  df_trends = df.sort_values(by='Jahr',ascending=True)

  df_trends['Verteidigung'] = df_trends['0'].rolling(25).mean()
  df_trends['Hessen'] = df_trends['1'].rolling(25).mean()
  df_trends['Forsch/Wiss.'] = df_trends['2'].rolling(25).mean()
  df_trends['Apotheken/Med.'] = df_trends['3'].rolling(25).mean()
  df_trends['Energie/Strom/Wirt.'] = df_trends['4'].rolling(25).mean()
  df_trends['Datenschutz'] = df_trends['6'].rolling(25).mean()
  df_trends['Darmstadt/Bildung/Forsch.'] = df_trends['7'].rolling(25).mean()
  df_trends['Energie/Wirt./Optim./Nachhalt.'] = df_trends['8'].rolling(25).mean()
  df_trends['Apotheken/Krankenkass./Med.'] = df_trends['9'].rolling(25).mean()

  sns.lineplot(x="Jahr",y="Verteidigung",
           label="Verteidigung", data=df_trends,
           ci=None, color='#001219')
  sns.lineplot(x="Jahr",y="Hessen",
           label="Hessen", data=df_trends,
           ci=None, color='#005f73')
  sns.lineplot(x="Jahr",y="Forsch/Wiss.",
           label="Forsch/Wiss.", data=df_trends,
           ci=None, color='#0a9396')
  sns.lineplot(x="Jahr",y="Apotheken/Med.",
           label="Apotheken/Med.", data=df_trends,
           ci=None, color='#94d2bd')
  sns.lineplot(x="Jahr",y="Energie/Strom/Wirt.",
           label="Energie/Strom/Wirt.", data=df_trends,
           ci=None, color='#e9d8a6')
  sns.lineplot(x="Jahr",y="Datenschutz",
           label="Datenschutz", data=df_trends,
           ci=None, color='#ee9b00')
  sns.lineplot(x="Jahr",y="Darmstadt/Bildung/Forsch.",
           label="Darmstadt/Bildung/Forsch.", data=df_trends,
           ci=None, color='#ca6702')
  sns.lineplot(x="Jahr",y="Energie/Wirt./Optim./Nachhalt.",
           label="Energie/Wirt./Optim./Nachhalt.", data=df_trends,
           ci=None, color='#bb3e03')
  sns.lineplot(x="Jahr",y="Apotheken/Krankenkass./Med.",
           label="Apotheken/Krankenkass./Med.", data=df_trends,
           ci=None, color='#ae2012')

  plt.legend(loc=2, prop={'size':14}, bbox_to_anchor=(1,1),ncol=1)
  plt.ylabel('Rollender Durchschnitt')
  plt.xlabel('Jahre')
  plt.xticks(rotation=45, ha="right")

  plt.savefig(pathplot, dpi=300, bbox_inches='tight')
  #return '/home/cpsoz/Github/minipublic/images/Trends.pdf'
#+end_src

Wir stellen ähnliche Topics zusammen und bilden dann die übrigen Topics ab:

#+name: trends-7t
#+begin_src python :var dt="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/DT.csv" :var saveplot="/home/cpsoz/ROM-Data/BERT-Analyse/Trends7T.pdf" :results Trends7T.pdf file
  import matplotlib.pyplot as plt
  import matplotlib.patches as mpatches
  import numpy as np
  import seaborn as sns
  import pandas as pd
  import csv
  from matplotlib import rc

  # Schrift
  #rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
  rc('font',**{'family':'serif','serif':['Times'],'size':9})
  rc('text', usetex=True)

  path = dt
  pathplot = saveplot
  df = pd.read_csv(path)
  df.rename(columns={ df.columns[0]: "Dokumente" }, inplace = True)
  df.drop('Dominant_Topic_NMF', axis=1, inplace=True)
  df['Jahr'] = df['Dokumente']
  df['Proto'] = df['Dokumente']
  df['Jahr']= df['Jahr'].map(lambda x: str(x)[0:4])
  df['Jahr'].astype(int)
  df['Proto']= df['Proto'].map(lambda x: str(x)[6:14])
  df_trends = df.sort_values(by='Jahr',ascending=True)
  df_trends['Apo/Med'] = df_trends[['3', '9']].mean(axis=1)
  df_trends['Energie/Wirt.'] = df_trends[['4', '8']].mean(axis=1)


  df_trends['Verteidigung'] = df_trends['0'].rolling(25).mean()
  df_trends['Hessen'] = df_trends['1'].rolling(25).mean()
  df_trends['Forsch/Wiss.'] = df_trends['2'].rolling(25).mean()
  df_trends['Apotheken/Med.'] = df_trends['Apo/Med'].rolling(25).mean()
  df_trends['Datenschutz'] = df_trends['6'].rolling(25).mean()
  df_trends['Darmstadt/Bildung/Forsch.'] = df_trends['7'].rolling(25).mean()
  df_trends['Energie/Wirt./Optim./Nachhalt.'] = df_trends['Energie/Wirt.'].rolling(25).mean()

  sns.lineplot(x="Jahr",y="Verteidigung",
           label="Verteidigung", data=df_trends,
           ci=None, color='#001219')
  sns.lineplot(x="Jahr",y="Hessen",
           label="Hessen", data=df_trends,
           ci=None, color='#005f73')
  sns.lineplot(x="Jahr",y="Forsch/Wiss.",
           label="Forsch/Wiss.", data=df_trends,
           ci=None, color='#0a9396')
  sns.lineplot(x="Jahr",y="Apotheken/Med.",
           label="Apotheken/Med.", data=df_trends,
           ci=None, color='#94d2bd')
  sns.lineplot(x="Jahr",y="Datenschutz",
           label="Datenschutz", data=df_trends,
           ci=None, color='#ee9b00')
  sns.lineplot(x="Jahr",y="Darmstadt/Bildung/Forsch.",
           label="Darmstadt/Bildung/Forsch.", data=df_trends,
           ci=None, color='#ca6702')
  sns.lineplot(x="Jahr",y="Energie/Wirt./Optim./Nachhalt.",
           label="Energie/Wirt./Optim./Nachhalt.", data=df_trends,
           ci=None, color='#bb3e03')

  plt.legend(loc=2, prop={'size':14}, bbox_to_anchor=(1,1),ncol=1)
  plt.ylabel('Rollender Durchschnitt')
  plt.xlabel('Jahre')
  plt.xticks(rotation=45, ha="right")

  plt.savefig(pathplot, dpi=300, bbox_inches='tight')
  #return '/home/cpsoz/Github/minipublic/images/Trends.pdf'
#+end_src
