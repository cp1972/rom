* Deutung der allgemeinen Themen im Rahmen der politischen Debatten zu Rechenzentren in Deutschland

Dieses Dokument stellt ein Workflow zur Deutung der allgemeinen Themen im Rahmen der politischen Debatten zu Rechenzentren in Deutschland dar. Wir verwenden die Ergebnisse aus unserem [[file:02-WF-Rech-BT.org][zweiten Workflow]] zur Topic-Modell-Analyse der Debatten zu Rechenzentren in Deutschland. Wie unsere zwei ersten Workflow kann dieses Workflow als Anwendung verwendet werden (s. u.).

** Vorgehen

Am Ende von unserer Topic-Modell-Analyse haben wir die Ergebnisse bzw. die Topics jeder Wahlperiode zu einer KI gesendet, die die Zusammenstellung von Begriffen nach gemeinsamer Bedeutung prüfen sollte. Die Berichte der KI haben wir gelesen und korrigiert haben, wo es sein musste. Diese Berichte wollen wir mit zwei Zielen behandeln:

- Ziel 1: welche -- wichtige bzw. zentrale oder unwichtige bzw. nicht zentrale --  Bedeutung solche Rahmenthemen in diesen Debatten gehabt haben?
- Ziel 2: im Rahmen der Debatten, die mit Bezug auf die Rechenzentren in Deutschland entwickelt wurden, können spezifische Rahmenthemen erkannt werden?

Zum Ziel 1 verwenden wir eine Analyse der Ähnlichkeiten zwischen den Berichten der KI, die uns zeigen wird, welche von diesen Berichten eine wichtige bzw. zentrale Bedeutung gehabt haben. Weil diese Berichte Themen erwähnen, die nicht immer und nicht unbedingt nur mit dem Thema der Rechenzentren in Deutschland verbunden sind, dann sollen wir aus den Berichten der KI die Textstellen identifizieren, die spezifischer mit dem Thema der Rechenzentren in Deutschland verbunden sind. Damit erreichen wir unser zweites Ziel, und in der entsprechenden Umsetzung führen wir auf die Berichte eine Analyse der semantischen Ähnlichkeiten auf der Ebene von Sätzen der Berichte der KI mit dem SBert-Algorithmus. Wir vergleichen dann beide Ergebnisse, um den Platz deuten zu können, den solche spezifische Themen in den Protokollen des Bundestages in der Zeit genommen haben bzw. um ihren Gewicht in den Debatten des Bundestages auf lange Sicht besser verstehen zu können.

** Dieses Workflow als Anwendung benutzen

Dieses Workflow kann wie eine Anwendung verwendet werden. Erforderlich dafür ist die Installation vom Texteditor Emacs mit Org-mode (ab emacs-28 ist Org-mode mit dem Texteditor geliefert und muss nicht separat installiert werden). Dieses Workflow kann auf der Kommandozeile mit dem folgenden Skript 'bert-rech.sh' ausgeführt werden. Ein solcher Skript wird im Arbeitsordner hergestellt, den wir im Folgenden mit diesem Code-Block herstellen:

#+name: user-path
#+begin_src shell :var user="/home/cpsoz/ROM-Data" :results silent
  mkdir $user/BERT-Analyse
#+end_src

Unsere Analyse wird in diesem Ordner 'BERT-Analyse' stattfinden. Dort stellen wir einen Ordner 'BERT-Skripten' für die Skripten, die wir im Rahmen von diesem Workflow schreiben werden, und wir definieren den vollständigen Pfad zum Ordner 'BERT-Analyse' als neuen Benutzerpfad:

#+name: nuser
#+begin_src shell :var nuserpath="/home/cpsoz/ROM-Data/BERT-Analyse" :results silent
  echo $nuserpath
#+end_src

#+name: bert-skripten
#+begin_src shell :var userpath=nuser :results silent
  mkdir $userpath/BERT-Skripten
#+end_src

Wichtig: wie in den zwei ersten Workflow müssen Pfade von Benutzern des Workflows angepasst werden.

Dann schreiben wir den 'bert-rech.sh' Skript:

#+begin_src shell :results silent :var user=nuser
  touch $user/bert-rech.sh
  echo "#!/bin/bash" >> $user/bert-rech.sh
  echo 'emacs --batch \' >> $user/bert-rech.sh
  echo "      --eval \"(require 'org)\" \ " >> $user/bert-rech.sh
  echo "      --eval \"(setq org-confirm-babel-evaluate nil)\" \ " >> $user/bert-rech.sh
  echo "      --eval '(org-babel-tangle-file \"03-WF-Rech-TM.org\")' \ " >> $user/bert-rech.sh
  chmod +x $user/bert-rech.sh
#+end_src

Dieser Skript führt alle Code-Blöcke in diesem Workflow aus. Er kann entsprechend mit bash verwendet werden, wie etwa: bash bert-rech.sh (hier muss das Workflow im gleich Verzeichnis sein, in dem bert-rech.sh sich befindet).

Im Rahmen dieser Analyse verwenden wir einen ersten python-Skript für die Berechnung der Ähnlichkeit zwischen den Berichten der KI (TeSi.py) und einen zweiten python-Skript für die semantischen Ähnlichkeiten zwischen Sätzen aus diesen Berichten (SCT.py). Beide Skripten befinden sich in einem Ordner 'Workflow_RES', weshalb wir sie zu unserem Ordner 'BERT-Skripten' kopieren

#+name: bert-copy
#+begin_src shell :var mtap="/home/cpsoz/Workflow_RES" :var user=nuser :results silent
  cp $mtap/TeSi.py $user/BERT-Skripten && cp $mtap/SCT.py $user/BERT-Skripten
#+end_src

* Ziel 1. Bedeutung von Rahmenthemen zum Thema Rechenzentren in Deutschland

Um unser erstes Ziel zu erreichen, verwenden wir unseren TeSi.py-Skript auf die Berichte der KI. Da TeSi stopwords braucht, um die Analyse durchzuführen, schreiben wir einen Code-Block zum Pfad der Stopwords auf unserem Rechner:

#+name: stops
#+begin_src shell :var stopwords="/home/cpsoz/Org/Stopwords" :results silent
  echo $stopwords
#+end_src

Dann verwenden wir TeSi automatisch mit einer Datei 'tesi.txt', in der wir die Befehle schreiben, die TeSi braucht, um die Analyse durchzuführen; anschließend führen wir diese Analyse durch:

#+name: tesi
#+begin_src shell :var mtaki="/home/cpsoz/ROM-Data/TM-Analyse/MTA-KI" :var user=nuser :var stopw=stops  :results none
  touch $user/BERT-Skripten/tesi.txt
  echo $mtaki"/*" >> $user/BERT-Skripten/tesi.txt
  echo "y" >> $user/BERT-Skripten/tesi.txt
  echo $stopw"/de.txt" >> $user/BERT-Skripten/tesi.txt
  echo "4" >> $user/BERT-Skripten/tesi.txt
  cat $user/BERT-Skripten/tesi.txt | python3 $user/BERT-Skripten/TeSi.py
#+end_src

Damit haben wir eine bessere Sicht zu den Berichten der KI, die wenige Ähnlichkeiten zwischen Berichten zeigt -- die interessantesten Ergebnisse betreffen die Datei mit Ähnlichkeiten von 0.2 bis 0.29 auf einer Skala von 0.0 bis 1.0. Dort befinden sich schwache Verbindungen zwischen Berichten, die jedoch nicht zufällig entstanden sind. Über 0.3 gibt es eine Verbindung zwischen zwei Berichten mit einer Ähnlichkeit zwischen 0.4 bis 0.49, die jedoch das Thema der Rechenzentren oder Themen, die damit verbunden wären (wie Technologie, Rechner, Fortschritt usw.) nicht betreffen. Unter 0.2 gibt es sehr viele Verbindungen zwischen Berichten, die jedoch von weniger Relevanz sind, da es hier davon ausgegangen kann, dass solche Verbindungen aufgrund von sehr allgemeinen Merkmalen der Berichte der KI hergestellt werden (etwa es sind wahrscheinlich Protokolle von Debatten auf der politischen Ebene, die Themen der Wirtschaft, der Wissenschaft usw. betreffen).

Ein solches Ergebnis zeigt, dass wir viel Rausch in unserer Topic-Modell-Analyse haben bzw. dass das Thema Rechenzentren in Deutschland wahrscheinlich nur eine bescheidene Rolle spielt in den Debatten im Bundestag. Dies wollen wir jetzt vertiefen, und dafür wenden wir eine Analyse der semantischen Bedeutung der Berichte. Sie wird uns zum Ziel 2 bringen.

* Ziel 2. Spezifische Themen zum Oberthema Rechenzentren in Deutschland

Ähnlich wie bei unserem 'tesi' Code-Block bereiten wir einen Code-Block für die automatische Durchführung des SCT.py-Skript vor. Im Unterschied zum 'tesi' Code-Block brauchen wir keine Variable für den Pfad zu den Stopwords zu definieren, da unser Skript keine Stopword benutzt. Wir definieren Wörter und Wörterwurzel, die wir den SCT.py-Skript senden, damit er die Sätze in den Berichten zu den Topics aufnimmt, die diese Wörter und entsprechende Wörter mit der gegebenen Wurzel enthalten. Wir geben weiter die minimale Anzahl an Sätzen je Cluster, die wir bilden wollen (hier 2, weil wir wenige Dokumente haben), und wir geben das Koeffizient zwischen 0.0 und 0.99 für die Verbindung zwischen Sätzen an. Wenn dieses Koeffizient hoch ist, dann sucht SBERT nach Sätzen, die inhaltlich eng miteinander verbunden sind. Da wir im Ziel 1 gesehen haben, dass das Thema Rechenzentren wahrscheinlich eher am Rande der Debatten des Bundestages auftaucht, die wir modelliert haben, wählen wir ein Koeffizient von 0.4 für eine schwache jedoch nicht zufällige inhaltliche Verbindung zwischen Sätzen, die die Cluster bilden.

Wir können den Code-Block 'sct' mit diesen Informationen herstellen und ausführen:

#+name: sct
#+begin_src shell :var mtaki="/home/cpsoz/ROM-Data/TM-Analyse/MTA-KI" :var user=nuser :var stopw=stops  :results none
  touch $user/BERT-Skripten/sct.txt
  echo $mtaki"/*" >> $user/BERT-Skripten/sct.txt
  echo "y" >> $user/BERT-Skripten/sct.txt
  echo "1" >> $user/BERT-Skripten/sct.txt
  echo "digit rechner rechenzentr techn computer informatik" >> $user/BERT-Skripten/sct.txt
  echo "2" >> $user/BERT-Skripten/sct.txt
  echo "2" >> $user/BERT-Skripten/sct.txt
  echo "0.4" >> $user/BERT-Skripten/sct.txt
  cat $user/BERT-Skripten/sct.txt | python3 $user/BERT-Skripten/SCT.py
#+end_src

Entsprechend erhalten wir die Cluster mit variablen Sätzen, die SBERT mit einem Koeffizient von 0.4 miteinander verbindet.

a=`awk '{print $1}' Clusters_Years-11_06_2025_14_12_09.txt`
b=`awk -F, '{print $1}' Corr_02_11_06_2025_14_17_53.csv
c=`awk -F, '{print $2}' Corr_02_11_06_2025_14_17_53.csv`
echo "$a" | grep -Fx "$b" | uniq
echo "$a" | grep -Fx "$c" | uniq



* TM-Analyse. Training der Modelle

Im Rahmen von Topic-Modell-Analysen müssen wir zuerst wissen, wie viele Themen für einen bestimmten Datensatz sinnvoll zu modellieren sind. Deshalb müssen wir in einem ersten Schritt MTA auf die Dateien trainieren, die wir in den Unterordnern vom Ordner 'Rechenzentren' gespeichert haben. Wir schreiben einen ersten Code-Block zum Ordner 'Rechenzentren'

#+name: rechpfad
#+begin_src shell :var rechpath="/home/cpsoz/ROM-Data/Rechenzentren" :results silent
  echo $rechpath
#+end_src

Wir müssen auch bedenken, dass MTA eine Liste von Wörtern (ein Wort je Zeile) braucht, die für die Analyse sehr wenig bis nicht relevant sind und deshalb nicht berücksichtigt werden müssen. Es sind Stop-Wörter, die in unserem Fall deutsche Wörter sind und sich im folgenden Ordner befinden:

#+name: stops
#+begin_src shell :var stopwords="/home/cpsoz/Org/Stopwords" :results silent
  echo $stopwords
#+end_src

Wir [[https://github.com/cp1972/mta-app/blob/main/automate.md][automatisieren]] MTA mit der folgenden 'mta-train.txt'-Datei, die wir in unserem 'TM-Skripten' Ordner speichern:

#+name: autotrain-01
#+begin_src shell :var user=nuser :var rech=rechpfad :var stopw=stops :results silent
  touch $user/TM-Skripten/mta-train.txt
  echo $rech"/01/*" >> $user/TM-Skripten/mta-train.txt
  echo "y" >> $user/TM-Skripten/mta-train.txt
  echo $stopw"/de.txt" >> $user/TM-Skripten/mta-train.txt
  echo "5" >> $user/TM-Skripten/mta-train.txt
  echo "n" >> $user/TM-Skripten/mta-train.txt
  echo "de" >> $user/TM-Skripten/mta-train.txt
  echo "a" >> $user/TM-Skripten/mta-train.txt
  echo "1" >> $user/TM-Skripten/mta-train.txt
  echo "y" >> $user/TM-Skripten/mta-train.txt
  echo "15" >> $user/TM-Skripten/mta-train.txt
  echo "4" >> $user/TM-Skripten/mta-train.txt
  echo "n" >> $user/TM-Skripten/mta-train.txt
  echo "0" >> $user/TM-Skripten/mta-train.txt
#+end_src

Diese Datei trainiert MTA mit Modellen, die von 2 bis 15 Topics reichen. Wir führen MTA mit dieser Datei im folgenden Code-Block aus:

#+name: trainmta
#+begin_src shell :var user=nuser :results none
  cat $user/TM-Skripten/mta-train.txt | python3 $user/TM-Skripten/MTA.py
#+end_src

Aus den Ergebnissen von MTA nehmen wir aus der Datei 'Summary*.log' die relevanten Informationen zu den optimalen Zahlen der Topics je Kreuzvalidierungsmethode, die MTA verwendet. Wir übernehmen auch die Information zu der besten Anzahl der Topics nach Cophenet Korrelationskoeffizient. Wir speichern diese Informationen in einer Datei 'TM-train-scores.txt'.

#+name: trainscores
#+begin_src shell :var mtadir="/home/cpsoz/Github/rom/Methodologie" :var user=nuser :results silent
  echo " " >> $user/TM-train-scores.txt
  cat $mtadir/MTA-Results*/Summary*.log | sed -n '/Elbow /,/Correlation values LDA/p' | awk 'NF' | awk '{$1=$1;print}' >> $user/TM-train-scores.txt
  echo "------" >> $user/TM-train-scores.txt
  echo " " >> $user/TM-train-scores.txt
  find $mtadir -type d -name "MTA-Results*" -exec rm -r {} +
#+end_src

Wir evaluieren die folgenden Code-Blöcke für die weiteren Unterordner im Ordner 'Rechenzentren':

#+name: autotrain-02
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/01/02/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-04
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/02/04/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-05
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/04/05/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-06
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/05/06/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-08
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/06/08/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-09
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/08/09/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-10
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/09/10/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-11
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/10/11/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-13
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/11/13/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-14
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/13/14/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-15
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/14/15/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-16
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/15/16/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-17
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/16/17/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-18
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/17/18/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

Für den Ordner 19 haben wir nur zwei große Dateien, deshalb zerschneiden wir die Dateien in 20 Dateien jeweils:

#+name: split-19
#+begin_src shell :var rech=rechpfad :results none
  cd $rech/19
  for i in *.txt; do split -n 20 --numeric-suffixes "$i" "$i".fin ; done
  rm *.txt
  for i in *.txt.fin*; do mv "$i" "${i%}.txt"; done
#+end_src

Dann modellieren wir den Ordner 19:

#+name: autotrain-19
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/18/19/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

#+name: autotrain-20
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/19/20/' $user/TM-Skripten/mta-train.txt
  <<trainmta>>
  <<trainscores>>
#+end_src

Wir können dann alle Ergebnisse aus der Datei 'TM-train-scores.txt' mit dem folgenden Code-Block lesen.

#+name: mta-scores
#+begin_src shell :var user=nuser :results drawer
    cat $user/TM-train-scores.txt
#+end_src

Wir können jetzt die Dateien mit dem optimalen Anzahl an Topics modellieren.

* Modellierung

Dafür stellen wir eine veränderte Version von unserem Code-Block 'autotrain-01', die wir 'autotest-01' benennen:

#+name: autotest-01
#+begin_src shell :var user=nuser :var rech=rechpfad :var stopw=stops :results silent
  touch $user/TM-Skripten/mta-test.txt
  echo $rech"/01/*" >> $user/TM-Skripten/mta-test.txt
  echo "y" >> $user/TM-Skripten/mta-test.txt
  echo $stopw"/de.txt" >> $user/TM-Skripten/mta-test.txt
  echo "5" >> $user/TM-Skripten/mta-test.txt
  echo "n" >> $user/TM-Skripten/mta-test.txt
  echo "de" >> $user/TM-Skripten/mta-test.txt
  echo "a" >> $user/TM-Skripten/mta-test.txt
  echo "1" >> $user/TM-Skripten/mta-test.txt
  echo "n" >> $user/TM-Skripten/mta-test.txt
  echo "6" >> $user/TM-Skripten/mta-test.txt
  echo "n" >> $user/TM-Skripten/mta-test.txt
  echo "2" >> $user/TM-Skripten/mta-test.txt
  echo "2" >> $user/TM-Skripten/mta-test.txt
  echo "y" >> $user/TM-Skripten/mta-test.txt
  echo "0" >> $user/TM-Skripten/mta-test.txt
#+end_src

Dann modellieren wir den ersten Ordner:

#+name: testmta
#+begin_src shell :var user=nuser :results none
  cat $user/TM-Skripten/mta-test.txt | python3 $user/TM-Skripten/MTA.py
#+end_src

Wir stellen einen Ordner 'MTA-Results' im Ordner TM-Analyse, um dort die Ergebnisse aus der Modellierung für jeden Subordner vom Ordner 'Rechenzentren' zu speichern:

#+name: mtaresults
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  mkdir $user/MTA-Results
  mv $mtadir/MTA* $user/MTA-Results/
#+end_src

Dasselbe machen wir für die weiteren Subordner im Ordner 'Rechenzentren' mit Anpassung des Ordners (Zeile 1), der Anzahl an Topics (Zeile 10) und des Fensters für die Modellierung in der Zeit (Zeile 13). Wir benennen die MTA-Results-Ordner nach dem Subordner im Ordner 'Rechenzentren' um:

#+name: autotest-02
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  mv $user/MTA-Results/MTA* $user/MTA-Results/MTA-01
  sed -i '1 s/01/02/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/6/4/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/2/9/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-02
#+end_src

#+name: autotest-04
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/02/04/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/4/7/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/9/16/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-04
#+end_src

#+name: autotest-05
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/04/05/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/7/6/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/16/121/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-05
#+end_src

#+name: autotest-06
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/05/06/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/6/5/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/121/108/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-06
#+end_src

#+name: autotest-08
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/06/08/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/5/6/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/108/18/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-08
#+end_src

#+name: autotest-09
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/08/09/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/6/6/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/18/83/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-09
#+end_src

#+name: autotest-10
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/09/10/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/6/8/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/83/39/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-10
#+end_src

#+name: autotest-11
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/10/11/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/8/4/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/39/28/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-11
#+end_src

#+name: autotest-13
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/11/13/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/4/8/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/28/70/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-13
#+end_src

#+name: autotest-14
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/13/14/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/8/5/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/70/54/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-14
#+end_src

#+name: autotest-15
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/14/15/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/5/6/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/54/28/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-15
#+end_src

#+name: autotest-16
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/15/16/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/6/4/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/28/2/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-16
#+end_src

#+name: autotest-17
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/16/17/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/4/5/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/2/3/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-17
#+end_src

#+name: autotest-18
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/17/18/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/5/6/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/3/62/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-18
#+end_src

#+name: autotest-19
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/18/19/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/6/7/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/62/4/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-19
#+end_src

#+name: autotest-20
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none :noweb yes
  sed -i '1 s/19/20/' $user/TM-Skripten/mta-test.txt
  sed -i '10 s/7/3/' $user/TM-Skripten/mta-test.txt
  sed -i '13 s/4/32/' $user/TM-Skripten/mta-test.txt
  <<testmta>>
  <<mtaresults>>
  mv $user/MTA-Results/MTA-Results* $user/MTA-Results/MTA-20
#+end_src

Wir können jetzt die Ergebnisse interpretieren.

* Interpretation der Ergebnisse

Wir automatisieren die Interpretation der Ergebnisse mit einer KI. Dafür haben wir die [[https://github.com/aandrew-me/tgpt][Anwendung tgpt]] installiert, die wir programmatisch verwenden können. In einem ersten Schritt stellen wir den Ordner 'MTA-KI' her, in dem wir die Ergebnisse von unserer Interpretation der Topic-Modell-Analyse speichern werden:

#+name: mta-ki-results
#+begin_src shell :var user=nuser :results none
  mkdir $user/MTA-KI
#+end_src

Wir gehen dann in den jeweiligen Ordner mit den Ergebnissen aus der Topic-Modell-Analyse, wir zerlegen die Datei 'Top_Words_NMF_Topics_*.csv' so, dass wir ein Dokument mit ".out" Endung je Säule der Datei 'Top_Words_NMF_Topics_*.csv' herstellen. Dann passen wir den Inhalt von diesen ".out"-Dateien zur KI und wir speichern die Deutung der KI in einem Dokument. Zuerst schreiben wir den Skript, um die Ergebnisse von MTA zur KI zu senden und die Antworten der KI in eine Datei 'MTA-KI' zu schreiben:

#+name: mta-ki-interpret
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-01/" :var user=nuser :var mtaint="01-MTA-KI.txt" :var mtcut="01-MTA-KI-" :results none
  cd $mtares
  cp Top_Words_NMF_Topics_*.csv TW.txt
  sed -i '1d' TW.txt
  awk -F, '{for (i=1;i<=NF;i++) print $i > i".out"}' TW.txt
  for x in *.out; do echo -e "\nTOPIC '${x%.*}'\n" >> MTA-KI.txt && awk 'BEGIN { ORS = " " } { print }' "$x" | tgpt -q "welche thematischen Gemeinsamkeiten erkennst du zwischen diesen Wörtern" >> MTA-KI.txt; done
  rm TW.txt *.out
  mv MTA-KI.txt $user/MTA-KI/ && cd $user/MTA-KI/ && mv MTA-KI.txt $mtaint
  csplit $mtaint /TOPIC/ '{*}' --prefix $mtcut -b "%02d.txt" && rm $mtaint && rm *-KI-00.txt
#+end_src

Dann machen wir die Interpretation für jeden Ordner:

#+name: mta-ki-02
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-02/" :var user=nuser :var mtaint="02-MTA-KI.txt" :var mtcut="02-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-04
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-04/" :var user=nuser :var mtaint="04-MTA-KI.txt" :var mtcut="04-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-05
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-05/" :var user=nuser :var mtaint="05-MTA-KI.txt" :var mtcut="05-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-06
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-06/" :var user=nuser :var mtaint="06-MTA-KI.txt" :var mtcut="06-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-08
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-08/" :var user=nuser :var mtaint="08-MTA-KI.txt" :var mtcut="08-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-09
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-09/" :var user=nuser :var mtaint="09-MTA-KI.txt" :var mtcut="09-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-10
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-10/" :var user=nuser :var mtaint="10-MTA-KI.txt" :var mtcut="10-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-11
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-11/" :var user=nuser :var mtaint="11-MTA-KI.txt" :var mtcut="11-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-13
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-13/" :var user=nuser :var mtaint="13-MTA-KI.txt" :var mtcut="13-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-14
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-14/" :var user=nuser :var mtaint="14-MTA-KI.txt" :var mtcut="14-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-15
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-15/" :var user=nuser :var mtaint="15-MTA-KI.txt" :var mtcut="15-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-16
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-16/" :var user=nuser :var mtaint="16-MTA-KI.txt" :var mtcut="16-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-17
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-17/" :var user=nuser :var mtaint="17-MTA-KI.txt" :var mtcut="17-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-18
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-18/" :var user=nuser :var mtaint="18-MTA-KI.txt" :var mtcut="18-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-19
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-19/" :var user=nuser :var mtaint="19-MTA-KI.txt" :var mtcut="19-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

#+name: mta-ki-20
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/TM-Analyse/MTA-Results/MTA-20/" :var user=nuser :var mtaint="20-MTA-KI.txt" :var mtcut="20-MTA-KI-" :results none :noweb yes
  <<mta-ki-interpret>>
#+end_src

An diesem Punkt empfiehlt sich, die Interpretation durch die KI zu kontrollieren bzw. zu korrigieren, und nicht nützliche Informationen aus der Dateien zu entfernen (etwa die Wiederholung der Wortlisten, die wir mit der Modellierung generiert haben). Diese Interpretationsberichte verwenden wir in einem dritten Workflow zur Erkennung von semantischen Ähnlichkeiten in der Interpretation der Modelle, die Auskunft über die Anwesenheit von ähnlichen Themen im Rahmen der 20 Wahlperioden, die wir berücksichtigen.

* Fazit

Mit diesem zweiten Workflow haben wir eine Modellierung des allgemeinen Kontextes der Debatten im Bundestag zum Thema Rechenzentren in Deutschland für die Zeit von 1949 bis 2025 vorgeschlagen. Wie hilfreich eine solche Modellierung ist, untersuchen wir in einem dritten Workflow. In diesem dritten Workflow analysieren wir die Ähnlichkeiten zwischen Themen in den unterschiedlichen Wahlperioden, was uns erlaubt, wiederholende Themen in der Zeit von 1949 bis 2025 zu erkennen, sowie die Entstehung von neuen Themen und das Verschwinden von alten Themen zu datieren.

In diesem Zusammenhang werden wir uns fragen, ob die vorhandene Information ausreicht, um das Thema der Rechenzentren in Deutschland besser zu verstehen, oder ob wir gezielt eine eingeschränkte Anzahl an Dateien modellieren sollten, um mehr bzw. präzisere Informationen zu diesem Thema zu erhalten.
