* Deutung der allgemeinen Themen im Rahmen der politischen Debatten zu Rechenzentren in Deutschland

Dieses Dokument stellt ein /workflow/ zur Deutung der allgemeinen Themen im Rahmen der Debatten zu Rechenzentren im deutschen Bundestag/Parlament dar. Wir verwenden die Ergebnisse aus unserem [[file:02-WF-Rech-BT.org][zweiten workflow]] zur Topic-Modell-Analyse dieser Dokumente. Wie unsere zwei ersten /workflow/ kann dieses /workflow/ als Anwendung verwendet werden (s. u.).

** Vorgehen

Am Ende von unserer Topic-Modell-Analyse haben wir die Ergebnisse bzw. die Topics für jede Wahlperiode zu einer KI gesendet, die die Zusammenstellung von Begriffen nach gemeinsamer Bedeutung prüfen sollte. Die Berichte der KI haben wir gelesen und korrigiert. Diese Berichte wollen wir mit den zwei folgenden Zielen weiter behandeln:

- *Ziel 1*: welches Bedeutung schreibt die KI den Themen zu, die aus der Topic-Modell-Analyse erkannt worden sind, und sieht man dort Ähnlichkeiten? Zur Beantwortung dieser Frage vergleichen wir die KI-Berichte miteinander.
- *Ziel 2*: gibt es unter diesen Themen manche, die besonders relevant für unsere Analyse sind? Zur Beantwortung dieser Frage vergleichen wir jede Sätze aus den KI-Berichten miteinander.

Wir vergleichen dann beide Ergebnisse (Vergleich der KI-Berichte bzw. der Sätze in diesen Berichten), um das Gewicht deuten zu können, das spezifische Themen zu Rechenzentren in den Protokollen des Bundestages von 1949 bis heute gehabt haben.

** Dieses /workflow/ als Anwendung benutzen

Dieses /workflow/ kann wie eine Anwendung mit dem folgenden Skript 'bert-rech.sh' ausgeführt werden. Ein solcher Skript wird im Arbeitsordner hergestellt, den wir im Folgenden mit diesem Code-Block schaffen (Pfad anpassen):

#+name: user-path
#+begin_src shell :var user="/home/cpsoz/ROM-Data" :results silent
  mkdir $user/BERT-Analyse
#+end_src

Unsere Analyse wird in diesem Ordner 'BERT-Analyse' stattfinden. Dort stellen wir einen Ordner 'BERT-Skripten' für die Skripten, die wir im Rahmen von diesem /workflow/ schreiben, und wir definieren den vollständigen Pfad zum Ordner 'BERT-Analyse' als neuen Benutzerpfad (Pfad anpassen):

#+name: nuser
#+begin_src shell :var nuserpath="/home/cpsoz/ROM-Data/BERT-Analyse" :results silent
  echo $nuserpath
#+end_src

#+name: bert-skripten
#+begin_src shell :var userpath=nuser :results silent
  mkdir $userpath/BERT-Skripten
#+end_src

Dann schreiben wir den Inhalt vom 'bert-rech.sh' Skript im Skript selbst:

#+begin_src shell :results silent :var user=nuser
  touch $user/bert-rech.sh
  echo "#!/bin/bash" >> $user/bert-rech.sh
  echo "emacs /home/cpsoz/Gitub/rom/Methodologie/03-WF-Rech-TM.org --batch -l /home/cpsoz/.emacs.d/init.el --eval \"(setq org-confirm-babel-evaluate nil)\" --eval \"(org-babel-execute-buffer)\"" >> $user/bert-rech.sh
  chmod +x $user/bert-rech.sh
#+end_src

Dieser Skript führt alle Code-Blöcke in diesem /workflow/ aus. Er kann entsprechend mit bash verwendet werden, wie etwa: bash bert-rech.sh oder ./bert-rech.sh.

In diesem /workflow/ verwenden wir einen ersten python-Skript für die Berechnung der Ähnlichkeit zwischen den KI-Berichten (TeSi.py) und einen zweiten python-Skript für die semantischen Ähnlichkeiten zwischen Sätzen aus diesen Berichten (SCT.py). Beide Skripten befinden sich in einem Ordner 'Workflow_RES', weshalb wir sie zu unserem Ordner 'BERT-Skripten' kopieren (Pfad anpassen):

#+name: bert-copy
#+begin_src shell :var mtap="/home/cpsoz/Workflow_RES" :var user=nuser :results silent
  cp $mtap/TeSi.py $user/BERT-Skripten && cp $mtap/SCT.py $user/BERT-Skripten
#+end_src

* Ziel 1. Vergleich der KI-Berichte miteinander

Um unser erstes Ziel zu erreichen, verwenden wir unseren TeSi.py-Skript auf die KI-Berichte. Da TeSi stopwords braucht, um die Analyse durchzuführen, schreiben wir einen Code-Block zum Pfad der Stopwords auf unserem Rechner (Pfad anpassen):

#+name: stops
#+begin_src shell :var stopwords="/home/cpsoz/Org/Stopwords" :results silent
  echo $stopwords
#+end_src

Dann verwenden wir TeSi automatisch mit einer Datei 'tesi.txt', in der wir die Befehle schreiben, die TeSi braucht, um die Analyse durchzuführen; anschließend führen wir diese Datei aus:

#+name: tesi
#+begin_src shell :var mtaki="/home/cpsoz/ROM-Data/TM-Analyse/MTA-KI" :var user=nuser :var stopw=stops mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  touch $user/BERT-Skripten/tesi.txt
  echo $mtaki"/*" >> $user/BERT-Skripten/tesi.txt
  echo "y" >> $user/BERT-Skripten/tesi.txt
  echo $stopw"/de.txt" >> $user/BERT-Skripten/tesi.txt
  echo "4" >> $user/BERT-Skripten/tesi.txt
  cat $user/BERT-Skripten/tesi.txt | python3 $user/BERT-Skripten/TeSi.py
  mv $mtadir/TeSi-Results* $user/
#+end_src

Das Ergebnis zeigt wenige Ähnlichkeiten zwischen den KI-Berichten -- die interessantesten Ergebnisse betreffen die Dateien mit Ähnlichkeiten von 0.2 bis 0.29 auf einer 0-1 Skala. Über diese Werte gibt es eine Verbindung zwischen zwei Berichten mit einer Ähnlichkeit zwischen 0.4 bis 0.49, die jedoch das Thema der Rechenzentren oder Themen, die damit verbunden wären (wie Technologie, Rechner, Fortschritt usw.) nicht betreffen. Unter dem Wert von 0.2 gibt es sehr viele Verbindungen zwischen KI-Berichten, die jedoch allgemeine Elemente der KI-Deutung betreffen und mit dem Thema 'Rechenzentrum' nicht verbunden sind.

Ein solches Ergebnis zeigt, dass wir viel Rausch in unserer Topic-Modell-Analyse haben bzw. dass das Thema Rechenzentren in Deutschland wahrscheinlich nur eine kleine Rolle in den Debatten im Bundestag/im Parlament spielt. Dies wollen wir jetzt vertiefen, und dafür wenden wir eine Analyse der semantischen Bedeutung der Berichte auf der Ebene von deren jeweiligen Sätzen (Ziel 2).

* Ziel 2. Spezifische Themen zum Thema Rechenzentren in Deutschland

Ähnlich wie bei unserem 'tesi' Code-Block bereiten wir einen Code-Block für die automatische Durchführung des SCT.py-Skript vor. Im Unterschied zum 'tesi' Code-Block brauchen wir keine Variable für den Pfad zu den Stopwords, weil wir keine Stopword benutzen. Wir definieren Wörter und Wörterwurzel, die wir dem SCT.py-Skript senden, damit er die Sätze in den KI-Berichten zu den Topics aufnimmt, die diese Wörter und entsprechende Wörter mit der gegebenen Wurzel enthalten. Wir geben weiter die minimale Anzahl an Sätzen je Cluster, die wir bilden (hier 2, weil wir wenige Dokumente haben), und wir definieren einen Koeffizient mit einem Wert zwischen 0.0 und 0.99, der besagt, welche Ähnlichkeiten die Sätze haben können, um im selben Cluster zusammengefügt zu werden. Wenn dieser Koeffizient hoch ist, dann sucht SBERT nach Sätzen, die inhaltlich eng miteinander verbunden sind. Weil wir im Ziel 1 gesehen haben, dass das Thema Rechenzentren wenig Bedeutung für die Debatten des Bundestages/des Parlaments hat, wählen wir ein Koeffizient von 0.4 für eine schwache jedoch nicht zufällige inhaltliche Verbindung zwischen Sätzen.

Wir können den Code-Block 'sct' mit diesen Informationen schreiben und ausführen:

#+name: sct
#+begin_src shell :var mtaki="/home/cpsoz/ROM-Data/TM-Analyse/MTA-KI" :var user=nuser mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  touch $user/BERT-Skripten/sct.txt
  echo $mtaki"/*" >> $user/BERT-Skripten/sct.txt
  echo "y" >> $user/BERT-Skripten/sct.txt
  echo "1" >> $user/BERT-Skripten/sct.txt
  echo "digit rechner rechenzentr techn computer informatik" >> $user/BERT-Skripten/sct.txt
  echo "2" >> $user/BERT-Skripten/sct.txt
  echo "2" >> $user/BERT-Skripten/sct.txt
  echo "0.4" >> $user/BERT-Skripten/sct.txt
  echo "0" >> $user/BERT-Skripten/sct.txt
  cat $user/BERT-Skripten/sct.txt | python3 $user/BERT-Skripten/SCT.py
  mv $mtadir/KI-Results* $user/
#+end_src

Entsprechend erhalten wir die Cluster mit variablen Sätzen, die SBERT mit einem Koeffizient von 0.4 miteinander verbindet. Dieses Ergebnis vergleichen wir jetzt mit dem Ergebnis aus unserem ersten Ziel in dem folgenden Code-Block:

#+name: comp
#+begin_src shell :var user=nuser :var user_res="/home/cpsoz/ROM-Data/BERT-Analyse" :results none
  a=`awk '{print $1}' $user/Ki-Results*/Clusters_Years*.txt`
  b=`awk -F, '{print $1}' $user/TeSi-Results*/Corr_02_*.csv`
  c=`awk -F, '{print $2}' $user/TeSi-Results*/Corr_02_*.csv`
  echo "$a" | grep -Fx "$b" | awk '!seen[$0]++' > $user_res/comp_1
  echo "$a" | grep -Fx "$c" | awk '!seen[$0]++' > $user_res/comp_2
  cat $user_res/comp_1 $user_res/comp_2 | awk '!seen[$0]++' > $user_res/comp_3.csv && rm $user_res/comp_1 $user_res/comp_2
#+end_src

Um eine visuelle Darstellung dieses Vergleichs aufzubauen, schreiben wir den folgenden Code-Block zur Hervorhebung der konvergierenden Gemeinsamkeiten aus dem ersten und dem zweiten Ziel, den wir dann als python-Skript speichern:

#+name: convergences
#+begin_src python :tangle /home/cpsoz/ROM-Data/BERT-Analyse/BERT-Skripten/Pdf_high.py :results silent
  #!/usr/bin/env python
  import pymupdf
  import pandas
  incoming = input("Path to pdf source: ")
  in_data = input("Path to comparison data: ")
  outgoing = input("Path to pdf result: ")
  pdf_plot=pymupdf.open(incoming)
  page = pdf_plot[0]
  color = (pymupdf.pdfcolor["pink"])
  colnames = ['year']
  data = pandas.read_csv(in_data, names=colnames)
  year_lst = data.year.tolist()
  for i in year_lst:
    rects = page.search_for(i)
    annot = page.add_highlight_annot(rects)
    annot.set_colors(stroke=color)
    annot.update()
  pdf_plot.save(outgoing)
#+end_src

Wir bauen die Abbildung bzw. die Netzwerkkarte 'Network_highlight.pdf' auf:

#+name: pdf_plot_highlight
#+begin_src shell :var tesipath="/home/cpsoz/Github/rom/Methodologie" :var user=nuser :results none
  chmod +x $user/BERT-Skripten/Pdf_high.py
  d=`ls $tesipath/TeSi-Results*/Networkg_02*.pdf`
  echo "$d" >> $user/BERT-Skripten/pdf_high.txt
  echo $user"/comp_3.csv" >> $user/BERT-Skripten/pdf_high.txt
  echo $user"/Network_highlight.pdf" >> $user/BERT-Skripten/pdf_high.txt
  cat $user/BERT-Skripten/pdf_high.txt | python3 $user/BERT-Skripten/Pdf_high.py
#+end_src

Das Ergebnis bestätigt, dass wir viel Rausch in unseren Daten haben, selbst wenn einige Themen zu Rechenzentren auftauchen:

- Topics 3 der 13 Wahlperiode (WP) und 4 der 18 WP sind mit wichtigen Themen der Debatten im Bundestag/Parlament verbunden;
- Topics 2 der 18 und 20 WP und Topic 3 der 17 WP sind mit weniger wichtigen Themen der Debatten im Bundestag/Parlament verbunden;
- Topics 1 und 4 der 17 WP sind mit Themen der Debatten im Bundestag/Parlament verbunden, die im Vergleich mit den anderen Topics deutlich weniger wichtig sind.

Dieses Ergebnis zeigt, dass die Themen, die mit den Rechenzentren verbunden sind, in ihrer Mehrheit einer spezifischen Agenda angehören, die meistens am Rande der herrschenden Themen in den Debatten im Bundestag/Parlament auftauchen. Um mehr zu diesen Themen zu wissen, müssen wir dann den Rausch in unserer Daten reduzieren. Dafür nehmen wir statt ganze Protokolle nur Teile von den Protokollen, in denen die Rechenzentren explizit erwähnt werden.

* TM-Analyse auf Teile von Protokollen. Training der Modelle

Wir müssen zuerst die Dateien aus unserem Ordner 'Rechenzentren' sortieren, die die Rechenzentren explizit erwähnen. Wir schreiben einen ersten Code-Block, in dem wir einen Ordner 'Rechenzentren_Teile' herstellen, wo wir die relevanten Dateien aus dem Ordner 'Rechenzentren' speichern:

#+name: mata-data-2
#+begin_src shell :var romdata="/home/cpsoz/ROM-Data" :var rechpath="/home/cpsoz/ROM-Data/Rechenzentren" :results silent
     mkdir $romdata/Rechenzentren_Teile
     teile=`grep -rl '[Rr]echenzentr' $rechpath`
     echo "$teile" | while IFS= read -r line ; do cp $line $romdata/Rechenzentren_Teile/; done
#+end_src

Wir [[https://github.com/cp1972/mta-app/blob/main/automate.md][automatisieren]] MTA mit der folgenden 'mta-train.txt'-Datei, und wir schaffen einen Ordner 'BERT-TM-Skripten', in dem wir unsere Dateien und Skripten zur TM-Analyse speichern:

#+name: autotrain-01
#+begin_src shell :var user=nuser :var rech="/home/cpsoz/ROM-Data/Rechenzentren_Teile" :var stopw=stops :results silent
  mkdir $user/BERT-TM-Skripten
  touch $user/BERT-TM-Skripten/mta-train.txt
  echo $rech"/*" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-train.txt
  echo $stopw"/de.txt" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "5" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "de" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "a" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "1" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "15" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "4" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-train.txt
  echo "0" >> $user/BERT-TM-Skripten/mta-train.txt
#+end_src

Diese Datei trainiert MTA mit Modellen von 2 bis 15 Topics. Wir führen MTA mit dieser Datei im folgenden Code-Block aus:

#+name: trainmta
#+begin_src shell :var user=nuser :var usermta="/home/cpsoz/ROM-Data/TM-Analyse/TM-Skripten" :results none
  cat $user/BERT-TM-Skripten/mta-train.txt | python3 $usermta/MTA.py
#+end_src

Aus der Datei 'Summary*.log' übernehmen wir die relevanten Informationen zu der optimalen Topics-Anzahl je Kreuzvalidierungsmethode, die MTA verwendet. Wir übernehmen auch die Information zu der besten Topics-Anzahl nach dem Cophenet Korrelationskoeffizient. Wir speichern diese Informationen in einer Datei 'TM-train-scores.txt'.

#+name: trainscores
#+begin_src shell :var mtadir="/home/cpsoz/Github/rom/Methodologie" :var user=nuser :results silent
  echo " " >> $user/BERT-TM-train-scores.txt
  cat $mtadir/MTA-Results*/Summary*.log | sed -n '/Elbow /,/Correlation values LDA/p' | awk 'NF' | awk '{$1=$1;print}' >> $user/BERT-TM-train-scores.txt
  echo "------" >> $user/BERT-TM-train-scores.txt
  echo " " >> $user/BERT-TM-train-scores.txt
  find $mtadir -type d -name "MTA-Results*" -exec rm -r {} +
#+end_src

Wir können dann die Ergebnisse aus der Datei 'TM-train-scores.txt' mit dem folgenden Code-Block drucken.

#+name: mta-scores
#+begin_src shell :var user=nuser :results drawer
    cat $user/BERT-TM-train-scores.txt
#+end_src

#+RESULTS: mta-scores
:results:

Elbow | No optimal topic
Silhouette | Optimal topics, better to worst: 6 8 10 11 12 13 14
Calinski Harabasz | Optimal topics, better to worst: 13 14
Davies Bouldin | Optimal topics, better to worst: 3 4 5 6 8 10 11 12 13 14
NMF-Cophenet | Optimal topics, better to worst: 3 5 6 7 10 12 13
Correlation values NMF-Cophenet: (0.7172416876046004, 0.6107818751672857, 0.6411485869549876, 0.6314090328283718, 0.7760202232221576, 0.7284745654214617, 0.763058470800228)
LDA-Cophenet | Optimal topics, better to worst: 3 8 11 13
Correlation values LDA-Cophenet: (0.6291944961666273, 0.8664864589342771, 0.7144070029386059, 0.9145840305388004)
------

:end:

Damit gehen wir zur Modellierung der Dokumentteile über.

* Modellierung

Wir schreiben eine veränderte Version von unserem Code-Block 'autotrain-01', den wir 'autotest-01' umbenennen:

#+name: autotest-01
#+begin_src shell :var user=nuser :var rech="/home/cpsoz/ROM-Data/Rechenzentren_Teile" :var stopw=stops :results silent
  touch $user/BERT-TM-Skripten/mta-test.txt
  echo $rech"/*" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-test.txt
  echo $stopw"/de.txt" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "5" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "de" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "a" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "1" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "10" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "n" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "2" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "12" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "y" >> $user/BERT-TM-Skripten/mta-test.txt
  echo "0" >> $user/BERT-TM-Skripten/mta-test.txt
#+end_src

Dann modellieren wir die Dokumentteile im Ordner 'Rechenzentren_Teile':

#+name: testnmta
#+begin_src shell :var user=nuser :var usermta="/home/cpsoz/ROM-Data/TM-Analyse/TM-Skripten" :results none
  cat $user/BERT-TM-Skripten/mta-test.txt | python3 $usermta/MTA.py
#+end_src

Wir stellen einen Ordner 'MTA-Results' im Ordner BERT-TM-Analyse, um dort die Ergebnisse aus unserer Modellierung zu speichern:

#+name: mtaresults
#+begin_src shell :var user=nuser :var mtadir="/home/cpsoz/Github/rom/Methodologie" :results none
  mkdir $user/MTA-Results
  mv $mtadir/MTA* $user/MTA-Results/
#+end_src

Wir können jetzt die Ergebnisse interpretieren.

* Interpretation der Ergebnisse

Wir automatisieren die Interpretation der Ergebnisse mit einer KI, wie wir es für die erste Modellierung gemacht haben. In einem ersten Schritt stellen wir den Ordner 'MTA-KI' her, in dem wir die Ergebnisse von unserer Interpretation der Topic-Modell-Analyse speichern werden:

#+name: mta-ki-results
#+begin_src shell :var user=nuser :results none
  mkdir $user/MTA-KI
#+end_src

Wir zerlegen die Datei 'Top_Words_NMF_Topics_*.csv' so, dass wir ein Dokument mit ".out" Endung je Säule der Datei 'Top_Words_NMF_Topics_*.csv' schreiben. Dann passen wir den Inhalt von diesen ".out"-Dateien zur KI und wir speichern die Deutung der KI in einem Dokument.

Zuerst schreiben wir den Skript, um die Ergebnisse von MTA zur KI zu senden und die Antworten der KI in eine Datei 'MTA-KI' zu schreiben:

#+name: mta-ki-interpret
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/" :var user=nuser :var mtaint="01-MTA-KI.txt" :var mtcut="01-MTA-KI-" :results none
  cd $mtares/MTA-*
  cp Top_Words_NMF_Topics_*.csv TW.txt
  sed -i '1d' TW.txt
  awk -F, '{for (i=1;i<=NF;i++) print $i > i".out"}' TW.txt
  for x in *.out; do echo -e "\nTOPIC '${x%.*}'\n" >> MTA-KI.txt && awk 'BEGIN { ORS = " " } { print }' "$x" | tgpt -q "welche thematischen Gemeinsamkeiten erkennst du zwischen diesen Wörtern" >> MTA-KI.txt; done
  rm TW.txt *.out
  mv MTA-KI.txt $user/MTA-KI/ && cd $user/MTA-KI/ && mv MTA-KI.txt $mtaint
  csplit $mtaint /TOPIC/ '{*}' --prefix $mtcut -b "%02d.txt" && rm $mtaint && rm *-KI-00.txt
#+end_src

Einmal die Kontrolle der KI-Berichte erfolgt, bilden wir die für das Thema der Rechenzentren aussagkräftigsten Topics ab:

#+name: copy-dt
#+begin_src shell :var mtares="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/" :results silent
  cd $mtares/MTA-*
  cp Dominant_Topics_NMF_*.csv $mtares/DT.csv
#+end_src

Wir bilden einmal das Modell mit allen Topics ab:

#+name: trends-9t
#+begin_src python :var dt="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/DT.csv" :var saveplot="/home/cpsoz/ROM-Data/BERT-Analyse/Trends9T.pdf" :results Trends9T.pdf file
  import matplotlib.pyplot as plt
  import matplotlib.patches as mpatches
  import numpy as np
  import seaborn as sns
  import pandas as pd
  import csv
  from matplotlib import rc

  # Schrift
  #rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
  rc('font',**{'family':'serif','serif':['Times'],'size':9})
  rc('text', usetex=True)

  path = dt
  pathplot = saveplot
  df = pd.read_csv(path)
  df.rename(columns={ df.columns[0]: "Dokumente" }, inplace = True)
  df.drop('Dominant_Topic_NMF', axis=1, inplace=True)
  df['Jahr'] = df['Dokumente']
  df['Proto'] = df['Dokumente']
  df['Jahr']= df['Jahr'].map(lambda x: str(x)[0:4])
  df['Jahr'].astype(int)
  df['Proto']= df['Proto'].map(lambda x: str(x)[6:14])
  df_trends = df.sort_values(by='Jahr',ascending=True)

  df_trends['Verteidigung'] = df_trends['0'].rolling(25).mean()
  df_trends['Hessen'] = df_trends['1'].rolling(25).mean()
  df_trends['Forsch/Wiss.'] = df_trends['2'].rolling(25).mean()
  df_trends['Apotheken/Med.'] = df_trends['3'].rolling(25).mean()
  df_trends['Energie/Strom/Wirt.'] = df_trends['4'].rolling(25).mean()
  df_trends['Datenschutz'] = df_trends['6'].rolling(25).mean()
  df_trends['Darmstadt/Bildung/Forsch.'] = df_trends['7'].rolling(25).mean()
  df_trends['Energie/Wirt./Optim./Nachhalt.'] = df_trends['8'].rolling(25).mean()
  df_trends['Apotheken/Krankenkass./Med.'] = df_trends['9'].rolling(25).mean()

  sns.lineplot(x="Jahr",y="Verteidigung",
           label="Verteidigung", data=df_trends,
           ci=None, color='#001219')
  sns.lineplot(x="Jahr",y="Hessen",
           label="Hessen", data=df_trends,
           ci=None, color='#005f73')
  sns.lineplot(x="Jahr",y="Forsch/Wiss.",
           label="Forsch/Wiss.", data=df_trends,
           ci=None, color='#0a9396')
  sns.lineplot(x="Jahr",y="Apotheken/Med.",
           label="Apotheken/Med.", data=df_trends,
           ci=None, color='#94d2bd')
  sns.lineplot(x="Jahr",y="Energie/Strom/Wirt.",
           label="Energie/Strom/Wirt.", data=df_trends,
           ci=None, color='#e9d8a6')
  sns.lineplot(x="Jahr",y="Datenschutz",
           label="Datenschutz", data=df_trends,
           ci=None, color='#ee9b00')
  sns.lineplot(x="Jahr",y="Darmstadt/Bildung/Forsch.",
           label="Darmstadt/Bildung/Forsch.", data=df_trends,
           ci=None, color='#ca6702')
  sns.lineplot(x="Jahr",y="Energie/Wirt./Optim./Nachhalt.",
           label="Energie/Wirt./Optim./Nachhalt.", data=df_trends,
           ci=None, color='#bb3e03')
  sns.lineplot(x="Jahr",y="Apotheken/Krankenkass./Med.",
           label="Apotheken/Krankenkass./Med.", data=df_trends,
           ci=None, color='#ae2012')

  plt.legend(loc=2, prop={'size':14}, bbox_to_anchor=(1,1),ncol=1)
  plt.ylabel('Rollender Durchschnitt')
  plt.xlabel('Jahre')
  plt.xticks(rotation=45, ha="right")

  plt.savefig(pathplot, dpi=300, bbox_inches='tight')
  #return '/home/cpsoz/Github/minipublic/images/Trends.pdf'
#+end_src

Wir stellen ähnliche Topics zusammen und bilden eine verdichtete Darstellung mit sieben Topics ab:

#+name: trends-7t
#+begin_src python :var dt="/home/cpsoz/ROM-Data/BERT-Analyse/MTA-Results/DT.csv" :var saveplot="/home/cpsoz/ROM-Data/BERT-Analyse/Trends7T.pdf" :results Trends7T.pdf file
  import matplotlib.pyplot as plt
  import matplotlib.patches as mpatches
  import numpy as np
  import seaborn as sns
  import pandas as pd
  import csv
  from matplotlib import rc

  # Schrift
  #rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
  rc('font',**{'family':'serif','serif':['Times'],'size':9})
  rc('text', usetex=True)

  path = dt
  pathplot = saveplot
  df = pd.read_csv(path)
  df.rename(columns={ df.columns[0]: "Dokumente" }, inplace = True)
  df.drop('Dominant_Topic_NMF', axis=1, inplace=True)
  df['Jahr'] = df['Dokumente']
  df['Proto'] = df['Dokumente']
  df['Jahr']= df['Jahr'].map(lambda x: str(x)[0:4])
  df['Jahr'].astype(int)
  df['Proto']= df['Proto'].map(lambda x: str(x)[6:14])
  df_trends = df.sort_values(by='Jahr',ascending=True)
  df_trends['Apo/Med'] = df_trends[['3', '9']].mean(axis=1)
  df_trends['Energie/Wirt.'] = df_trends[['4', '8']].mean(axis=1)


  df_trends['Verteidigung'] = df_trends['0'].rolling(25).mean()
  df_trends['Hessen'] = df_trends['1'].rolling(25).mean()
  df_trends['Forsch/Wiss.'] = df_trends['2'].rolling(25).mean()
  df_trends['Apotheken/Med.'] = df_trends['Apo/Med'].rolling(25).mean()
  df_trends['Datenschutz'] = df_trends['6'].rolling(25).mean()
  df_trends['Darmstadt/Bildung/Forsch.'] = df_trends['7'].rolling(25).mean()
  df_trends['Energie/Wirt./Optim./Nachhalt.'] = df_trends['Energie/Wirt.'].rolling(25).mean()

  sns.lineplot(x="Jahr",y="Verteidigung",
           label="Verteidigung", data=df_trends,
           ci=None, color='#001219')
  sns.lineplot(x="Jahr",y="Hessen",
           label="Hessen", data=df_trends,
           ci=None, color='#005f73')
  sns.lineplot(x="Jahr",y="Forsch/Wiss.",
           label="Forsch/Wiss.", data=df_trends,
           ci=None, color='#0a9396')
  sns.lineplot(x="Jahr",y="Apotheken/Med.",
           label="Apotheken/Med.", data=df_trends,
           ci=None, color='#94d2bd')
  sns.lineplot(x="Jahr",y="Datenschutz",
           label="Datenschutz", data=df_trends,
           ci=None, color='#ee9b00')
  sns.lineplot(x="Jahr",y="Darmstadt/Bildung/Forsch.",
           label="Darmstadt/Bildung/Forsch.", data=df_trends,
           ci=None, color='#ca6702')
  sns.lineplot(x="Jahr",y="Energie/Wirt./Optim./Nachhalt.",
           label="Energie/Wirt./Optim./Nachhalt.", data=df_trends,
           ci=None, color='#bb3e03')

  plt.legend(loc=2, prop={'size':14}, bbox_to_anchor=(1,1),ncol=1)
  plt.ylabel('Rollender Durchschnitt')
  plt.xlabel('Jahre')
  plt.xticks(rotation=45, ha="right")

  plt.savefig(pathplot, dpi=300, bbox_inches='tight')
  #return '/home/cpsoz/Github/minipublic/images/Trends.pdf'
#+end_src

Mit dieser letzten Abbildung haben wir eine bessere Sicht der Entwicklung von relevanten Themen, die mit dem Oberthema 'Rechenzentre' verbunden sind und in den Debatten im deutschen Bundestag/im Parlament vorkommen. Diese Abbildung gibt uns eine Grundlage, um in die relevanten Dateien zu gehen und nach Wortmeldungen von Politikern zu suchen, die mit einem spezifischen Thema verbunden sind, das wir untersuchen möchten.

Mit diesem dritten /worflow/ sind wir am Ende der Arbeit gekommen, die wir im Rahmen von dieser einführenden Untersuchung zum Thema 'Rechenzentren' in den Debatten im deutschen Bundestag/im Parlament leisten wollten.
