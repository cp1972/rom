#+Setupfile: /home/cpsoz/OrgTemplates/odt-de.org
#+Title: Rechenzentren in Machtbalancen. Ein Erweiterungsvorschlag.
#+Bibliography: /home/cpsoz/Github/rom/CP-ROM.bib

* Abstract

Aus der Betrachtung Norbert Elias' Begriff der Figuration hat Reinhold Sackmann einen figurationssoziologischen Ansatz zur Analyse von Machtbalancen erarbeitet. Mit diesem Ansatz hat er untersucht, wie Akteure und Kollektive, die sich aufeinander beziehen (etwa im Rahmen von Generationen), in Konkurrenz geraten können und wie daraus Handlungsoptionen produziert werden, die Handlungsprogramme strukturieren. In diesem Kapitel verwenden wir den Satellisierungsansatz der Theorie der Relation -- das Relationieren der Macht durch Allianzen, um sie besser, ferner und länger auszuüben --, um den Ansatz der Machtbalance in zweierlei Weise in Bezug auf a) die interne Dynamisierung von Machtbalancen und b) ihre Kontrolle zwecks relationaler Vorteile in der Konkurrenz mit anderen (Kollektiv)Akteuren zu vertiefen. Die Forschungsfrage in diesem Beitrag ergibt sich aus dieser doppelten Zielstellung und kann wie folgt formuliert werden: Wie stellen (Kollektiv)Akteure Machtbalancen her, wie dynamisieren sie diese und welche relationalen Vorteile ziehen sie daraus, um die Herstellung von Machtbalancen durch andere (Kollektiv)Akteure zu schwächen oder gar zu verhindern. Unsere Untersuchung entwickeln wir am Beispiel der Rechenzentren in Deutschland im Kontext der Diskussion zu ihrem Energieverbrauch und ihrer Energieeffizienz. In einem ersten Schritt zeigen wir, dass diese Frage von der deutschen Regierung in Allianz mit der Wissenschaft und der Wirtschaft aufgegriffen wird. Eine solche Allianz müssen die Betreiber von Rechenzentren zu einer Machtbalance entwickeln, in der die Energieeffizienz von Rechenzentren in Unterstützung des verantwortlichen Umgangs mit natürlichen Ressourcen und mit der Umwelt verstanden wird. In einem zweiten Schritt zeigen wir, dass in einer Informationsgesellschaft im Werden, deren Folgen die deutsche Politik bis zum Jahr 2009 wenig thematisiert, die Renchenzentren und ihre Betreiber immer mehr an Bedeutung gewinnen und schnell expandieren. Dies schwächt die Satellisierungsstrategie der deutschen Regierung, die immer mehr Mühe hat, die Betreiber von Rechenzentren als Satellit ihrer politischen Agenda einzubeziehen. Die deutsche Regierung wie ihre Satelliten in der Wissenschaft und in der Wirtschaft verlieren umso mehr an Einfluss, als Rechenzentren immer mehr unter die Einflussmacht von großen Techkonzernen bzw. von entscheidenden Medienakteuren in der Gesellschaft fallen. Diese Entwicklung erklären wir in einem dritten Schritt, indem wir uns vom Beispiel der Rechenzentren in Deutschland entfernen, um eine globalere Sicht anzubieten. Dabei zeigen wir, wie solche mächtigen Techkonzerne die Frage des Energieverbrauchs bzw. der Energieeffizienz von Rechenzentren um die Frage des Umgangs mit natürlichen Ressourcen mit dem Ziel umformulieren, sich einen relationalen Vorteil zu verschaffen, und dabei Wissenschaft wie Wirtschaft für ihre Satellisierung zu gewinnen, die wiederum die Grundlage einer anderen Machtbalance im Bereich von Rechenzentren bilden soll, die von Techkonzernen kontrolliert wird.

* Einleitung

Im /Oeuvre/ Reinhold Sackmanns gibt es einen Ansatz, der zwar nicht unbedingt im Vordergrund seiner wissenschaftlichen Produktion steht, nichtsdestotrotz aber in der ein oder anderen Arbeit zur Demographie, zur Lebenslaufsoziologie und zu gesellschaftlichen Instanzen der Sozialisation wie den (Hoch)Schulen, dem Arbeitsmarkt oder dem Rentensystem Erwähnung genießt. Nehmen wir etwa die Schlussfolgerungen seiner Habilitationsschrift, in denen Sackmann die folgende Bilanz zur Lebenslaufsoziologie zieht: "An den Anfängen dieser Disziplin (...) stand die Vorstellung, daß Alter neben seiner biologischen Komponente auch gesellschaftlich kulturelle Elemente enthält. Gesellschaft war ein Nebenfaktor, der wahrgenommen werden sollte. In der Theorie des institutionalisierten Lebenslaufs gewann die Vorstellung Kontur, daß die modernen gesellschaftlichen Institutionen (...) spezifische Lebensläufe konstituieren" [cite:@sackmann98:_konkur_gener_arbeit 228-229]. Dabei legt Sackmann nahe, dass sich die künftige Forschung in der Lebenslaufsoziologie mit der Art und Weise auseinandersetzen sollte, wie Lebensläufe als eingebettete Prozesse an der Schnittstelle der Biographien von Akteuren und der formalen Operationen von gesellschaftlichen Instanzen entstehen und von einer solchen Einbettung strukturiert werden. "Lebensläufe", wie er in einem späteren Beitrag hervorhebt, "vollziehen sich eingebettet, in Gruppen, in Gemeinschaften, Gesellschaften und v.a. Organisationen" [cite:@sackmann07:_leben_biogr 206]. Dieser Ansatz ist aus den folgenden Gründen interessant:

Sackmann versteht Lebensläufe nicht mehr im geläufigen soziologischen Sinne von "trajectoires", die den Fokus auf den Weg der Akteure von einer gesellschaftlichen Instanz der Sozialisation zu weiteren gesellschaftlichen Instanzen der Sozialisation legen. Gesellschaftliche Sozialisationsinstanzen wie etwa (Hoch)Schulen oder der Arbeitsmarkt sind also mehr als nur "verpflichtende Anlaufstationen" von Akteuren [cite:@latour05:_reass_social]. Sie tun mehr als Akteure lediglich zu registrieren und sie je nach Sozialisationserfolg unterschiedlich auf weitere gesellschaftliche Bahnen umzuverteilen. Gesellschaftliche Instanzen geben den Akteuren Einschreibungsmöglichkeiten in der Gesellschaft. Sie reflektieren über ihre Rolle in diesem Zusammenhang. Sie entwickeln dauernd formale Verfahren, die wie Orientierungsmuster bzw. "Leitbilder" auf die Akteure wirken sollen [cite:@sackmann07:_leben_biogr 206]. Dass eine solche Wirkung auch unintendierte Folgen haben und Ungleichheiten zwischen Akteuren bzw. Akteurgenerationen generieren kann, hat Sackmann mehrmals im Sinne einer kritischen soziologischen Betrachtung von gesellschaftlichen Instanzen unterstrichen [cite: vgl. etwa @sackmann15:_bedeut_auswah_erzeug_bildun; vgl. auch @sackmann19:_mechan_eliteb]. Aber eine kritische Betrachtung von gesellschaftlichen Instanzen reicht allein nicht aus. Nach Sackmann müssen ebenfalls Korrekturmaßnahmen von gesellschaftlichen Instanzen abgebildet werden. Solche Korrekturen zielen darauf ab, Maßnahmen und entsprechende formale Verfahren zur Einschränkungen bzw. Schrumpfung der Ungleichheitsproduktion zu formulieren bzw. zu gestalten.

Mit diesem konstruktiven Korrelat zur kritischen Betrachtung von gesellschaftlichen Instanzen rundet Sackmann seinen Ansatz ab. Kollektivakteure fungieren als Teil des Einschreibungskontextes, den sie mit den Einzelakteuren aufbauen und innerhalb dessen die Laufbahn von solchen Akteuren strukturiert wird. Deshalb ist es aus Sicht einer soziologischen Makroperspektive mindestens ebenso relevant zu verstehen, wie gesellschaftliche Instanzen überhaupt an ihren formalen Operationen arbeiten. Diese Arbeit leisten sie nicht nur im Sinne der Stärkung der eigenen Position in der Gesellschaft. Mit formalen Operationen fördern gesellschaftliche Instanzen auch den Lebenslauf ihrer Adressaten. So stärken sie die Zuverlässigkeit ihrer eigenen (positiven wie negativen) Sanktionsoperationen an der Wurzel der (Um)Verteilung von Akteuren auf gesellschaftliche Tätigkeiten, auf entsprechende Bereiche und dort aktive Instanzen. Diesem Ansatz entnehmen wir zwei wichtige Botschaften, die die Brücke zur Sackmann'schen Rezeption der Figurationssoziologie von Elias schlagen.

Die erste Botschaft betrifft den gesellschaftlichen Zusammenhalt. Der gesellschaftliche Zusammenhalt ist eine Dynamik mit eigener Elastizität [cite:@sackmann98:_konkur_gener_arbeit 82]. Er hängt davon ab, wie gut oder weniger gut die Lebensläufe durch die Einbettung von Akteuren und gesellschaftlichen Instanzen strukturiert werden. Um eine solche Dynamik zu problematisieren, kann der Begriff der Figuration von Norbert Elias verwendet werden. Besonders die Interdependenz der protagonistischen und antagonistischen Akteuren in Figurationen sowie die entsprechenden Machtbalancen sind hier wichtig (ebd., bes. 73ff.). Beide Begriffe machen aus Figurationen dynamische Zusammenstellungen von Einzel- und Kollektiveakteuren sowie von Nicht-Akteuren, die in Zeit und Raum mehr oder weniger verbreitet oder geschrumpft werden. Im Rahmen von Figurationen denkt Elias die Machtbalancen sowohl innerhalb von einer Figuration als auch zwischen Figurationen. Dies bedeutet, wie Sackmann feststellt, dass (Kollektiv)Akteure in Figurationen "nicht gleich stark" sind (ebd. 75), weshalb auch ungleich starke Asymmetrien entstehen: "selten gelingt es einer Konfliktpartei, die andere vollkommen zu entmachten" (ebd.). Dasselbe gilt für Machtbalancen zwischen Figurationen. Oder anders gesagt: Die Macht wird nicht nur als Machtbalance dynamisiert, sondern in ihrer Relationalität konzeptualisiert, was mit dem Begriff "Balance" wiedergegeben wird. Die Macht ist in das Wechselspiel der (Kollektiv)Akteure eingebettet. Sie wird im Laufe der Strukturierung der Lebensläufe sowohl von Einzelakteuren als auch von der Position von gesellschaftlichen Instanzen mitstrukturiert. Figurationssoziologisch gesprochen, sehen Lebensläufe von Einzelakteuren und Generationen von Akteuren also nicht mehr wie individuelle Mikrophänomene "neben" der Gesellschaft (als Makrophänomen) aus. Eine solche Unterscheidung kann zugunsten eines prozeduralen Verständnisses von Figurationen als Einbettungs- bzw. Einschreibungskontexte gesellschaftlicher Dimensionen verwendet werden -- etwa für Forschungsfragen der Form: Welche Figurationen haben wir in unserer Gesellschaft? Welche Folgen haben sie für die Handlung in dieser Gesellschaft und für diese Gesellschaft selbst?

Diese Fragen sind auch im Rahmen der Theorie der Relation (TDR), die Relation nach einem Makroansatz definiert und entwickelt [cite:@papilloud22:_skizz_theor_relat], von zentraler Bedeutung. Verglichen mit Sackmanns Formulierung eines figurationssoziologischen Ansatzes in der Folge von Elias geht es in diesem Theorierahmen jedoch darum, die Einbettungszusammenhänge radikaler als Relationsstrukturen zu konzipieren. Relationsstrukturen sind analytische Werkzeuge, die Ordnungen von Verhältnissen mit (Kollektiv)Akteuren, Nicht-Akteuren und Medien darstellen. Sie entwickeln sich nach ihrer je spezifischen Dynamik bzw. nach einer spezifischen Balance und zwar nicht nur von asymmetrischen, sondern von allen möglichen Verhältnissen, die als Relationalität von Relationsstrukturen verstanden werden. Im Vergleich zu Figurationen haben Relationsstrukturen den analytischen Vorteil, dass sie keine unmittelbare Interdependenz der (Kollektiv)Akteure voraussetzen und Machtbalancen nicht von einer solchen Interdependenz abhängig machen. Deshalb eignen sich Relationsstrukturen auch für die Untersuchung von heterogenen Figurationen bzw. Zusammenstellungen von (Kollektiv)Akteuren, davon ihre Abhängigkeit nur einen Fall des Möglichen darstellt. Fraglich bleibt in diesem Zusammenhang allerdings, ob mit einem solchen Werkzeug wie Relationsstrukturen Asymmetrien, wie sie mit dem Begriff der Figuration erfasst werden, ebenfalls gut abgebildet werden können. Mit dieser Forschungsfrage beschäftigt sich die nachfolgende einführende Untersuchung des Kollektivakteurs "Rechenzentrum".

Im Laufe dieser Untersuchung wird gezeigt, dass Asymmetrien nicht nur abgebildet, sondern auch in ihrer dynamischen Entwicklung rekonstruiert werden können. Die Beschreibung einer solchen Entwicklung führt dazu, Macht nicht als Besitz (Macht haben/nicht haben) oder als Durchsetzungskraft zu verstehen, sondern als relationales Phänomen. In der Erweiterung der Vorstellung von Macht als Kontingenz/Möglichkeit bedeutet Macht als relationales Phänomen, eine Person oder eine Gruppe dazu zu bringen, Verhältnisse mit ihrer Umgebung einzugehen und zu entfalten, die diese Person oder Gruppe ansonsten nicht eingegangen wäre, geschweige entfaltet hätte. Macht wird somit in Relation gebracht und ferner auf (Kollektiv)Akteure verteilt bzw. in Allianzen dimensioniert, damit sie überhaupt wirkt. In unserer Untersuchung zeigen wir, dass dies nicht von selbst vonstatten geht, sondern eine bedeutsame Arbeit von (Kollektiv)Akteuren verlangt, damit aus dieser Relationierung der Macht Vorteile gezogen werden können. Diese Vorteile betreffen nicht nur die Stabilisierung der Macht, sondern auch die Beeinflussung von Handlungen und Handlungsprogrammen von (Kollektiv)Akteuren. Somit kann Macht gesellschaftlich an struktureller Wirksamkeit gewinnen. Aber weil Zusammenstellungen von (Kollektiv)Akteuren nicht zwangsläufig homogen sind, erweist sich die Stabilisierung von Macht als keine Selbstverständlichkeit. Wenn zudem, wie am Beispiel von Rechenzentren, die technische Entwicklung sehr schnell vor sich geht und sehr viele Technologien betrifft, dann wird eine solche Stabilisierung von Macht zu einer schwierigen Herausforderung für (Kollektiv)Akteure außerhalb des Bereiches von Rechenzentren. Dagegen ermächtigt diese technologische Entwicklung (Kollektiv)Akteure, die in diesem Bereich tätig sind, deshalb in besonderem Maße, weil sie wie ein Multiplikator auf die Relationierung ihrer Macht zu wirken imstande ist. Unser Beispiel hebt eine solche Situation hervor, deren Folgen vertieft werden sollen. Als erster Schritt in diesem Vorhaben gilt es jedoch, die Rechenzentren als eine spezifische Art von gesellschaftlicher Instanzen -- von gesellschaftlichen Institutionen bzw. Organisationen -- zu beschreiben.

* Rechenzentren als eine spezifische Art gesellschaftlicher Instanzen

Relationsstrukturen machen aus der Homogenität, die sich in Figurationen als Produkt der Interdependenz von (Kollektiv)Akteuren ergibt, den besonderen Fall von mehr oder weniger heterogenen Zusammenstellungen von diesen (Kollektiv)Akteuren. In diesem Sinne relationieren Relationsstrukturen. Sie bringen Personen (Akteure), Institutionen und Organisationen (Instanzen) ebenso in Verbindung wie Nicht-Akteure und Medien, wobei unter Medien alle symbolischen und formalen Mediationen von Verhältnissen, wie etwa Sprache oder Gebrauchsanweisungen, gemeint sind. Im Rahmen der TDR sagen wir, dass diese Verbindungen nicht beliebig entwickelt werden, sondern für jede Relationsstruktur nach einer bestimmten Anordnung von Sequenzen. Wir sprechen diesbezüglich von der spezifischen Relationalität einer Relationsstruktur (etwa in der Systemtheorie würde man hier stattdessen von Code sprechen). Aus Platzgründen beschreiben wir diesen Ansatz in diesem Aufsatz nicht weiter, aber wir können ihn wie folgt zusammenfassen: Eine Relationsstruktur enthält Verhältnisse (sie hat Relationen), die sie nach der ihr eigenen Relationalität strukturiert; eine Relationsstruktur entwickelt ihre Relationalität nach außen (sie ist Relation) in Richtung von anderen Relationsstrukturen, um Einfluss auf diese anderen Relationstrukturen auszuüben. Diese Einflussnahme von Relationsstrukturen auf andere Relationsstrukturen bezeichnen wir in der TDR als eine Satellisierung. Mit dem Terminus der Satellisierung ist ausgedrückt, dass Relationsstrukturen Allianzen über ihre Institutionen und Organisationen hinaus bilden, die sich mit Institutionen und Organisationen in anderen Relationsstrukturen in Verbindung setzen. Dies geschieht jedoch keineswegs von selbst, weshalb Allianzen weder stabil sind noch von ewiger Dauerhaftigkeit. Sie halten vielmehr eine bestimmte Zeit lang, wenn sie überhaupt zustande kommen. Diese Allianzen bilden die notwendigen Bedingungen für die Entwicklung von einer Satellisierung. Sie zielen immer darauf ab, andere Relationsstrukturen unter Kontrolle zu bringen bzw. aus diesen anderen Relationsstrukturen Satelliten der eigenen Relationsstruktur zu machen und somit die eigene Relationalität innerhalb einer anderen bzw. fremden Relationsstruktur zu implementieren.

Dieser Ansatz ruft ein erstes Problem hervor, das die TDR lösen muss und sich in die Diskrepanz zwischen dem Realen und dem Formalen bei der Verortung von Instanzen der Gesellschaft übersetzen lässt. Mit der Unterscheidung zwischen dem Realen und dem Formalen wollen wir festhalten, dass Praktiken als Formen von Tätigkeiten Eigenschaften beinhalten, die sie teilen können, selbst wenn sie real nicht identisch entwickelt werden, weil solche Tätigkeiten in unterschiedlichen Feldern ausgeübt werden und dort ihren Sinn als diese besondere Tätigkeit erhalten. Dies bezeichnet die Art der Theorie, die die TDR anbietet, die wiederum nicht nach einem strikten realistischen Ansatz argumentiert.

Das Problem der Diskrepanz zwischen dem Realen und dem Formalen taucht unmittelbar bei der Beschreibung der Position von gesellschaftlichen Instanzen in Relationsstrukturen als einer dynamischen Ordnung von Verhältnissen auf. Real können Instanzen und deren Subinstanzen an unterschiedlichen Orten der Gesellschaft aufgefunden werden. Nehmen wir das Beispiel der Forschung. Forschung kann als gesellschaftliche Instanz an die akademische Forschung im Rahmen von Hochschulen gekoppelt sein oder an Forschungszentren getätigt werden. Sie kann auch in Forschungsabteilungen von Industrien oder Firmen sowie im Rahmen der Politikberatung oder des Journalismus praktisiert werden. Wenn wir die Forschung formal allein als Praxis betrachten, dann beobachten wir vergleichbare Rahmenbedingungen zwischen den Bereichen, in denen sie praktisiert wird. Sie setzt einen Zugang zu einer zuverlässigen Information voraus. Sie setzt folglich den Einbezug von Akteuren, Kollektiven, Nicht-Akteuren und Medien voraus, damit die forschende Tätigkeit und ihre Ergebnisse kontrolliert und vertieft werden können. Sie setzt häufig auch eine mehr oder weniger breite Öffentlichkeit voraus, die die Ergebnisse dieser Forschung beziehen kann. Forschung kann also überall dort in der Gesellschaft auftauchen, wo solche Bedingungen für die Praxis einer Forschung vorhanden sind. Aber nicht überall in der Gesellschaft ist Forschung gleich Forschung -- die akademischen Forschung unterscheidet sich als Praxis von der Forschung in Firmen, im Journalismus oder in der Politikberatung deutlich.

Diese Diskrepanz zwischen dem Realen und dem Formalen, die mit dem Begriff der Relationsstruktur eingeführt wird, kann wie folgt für die soziologische Untersuchung produktiv gemacht werden. Bleiben wir beim Beispiel der Forschung. Forschung ist nicht gleich Forschung, weil Forschung in einer Relationstruktur eingebettet ist, die die Forschung strukturiert. Damit wird behauptet, dass die Forschung an Universitäten nicht kategoriell unterschiedlich als etwa die Forschung in Firmen ist. Beide Forschungspraxen unterscheiden sich viel mehr wegen der Verhältnisse zwischen Akteuren, Instanzen, Nicht-Akteuren und Medien, die in beiden Forschungpraxen unterschiedlich entwickelt, ver- und entbunden werden. Sie unterscheiden sich also aufgrund einer anderen Relationalität oder einer anderen relationalen Dynamik von Forschung -- und damit aufgrund von etwa anderen Mitteln, anderen Zielen, anderen Finanzierungsplänen, anderen Einstellungskriterien für das forschende Personal, anderen Formen der Mitarbeit mit Dritten. Daraus ergibt sich, dass diese Relationalität zum Leitbild für die Strukturierung von Handlungsprogrammen und Handlungen von kollektiven Akteuren ebenso generiert wie von Einzelakteuren. Diese Überlegung kann gleichermaßen zwischen Relationsstrukturen entwickelt werden. Eine Relationsstruktur kann andere Relationsstrukturen nicht anders als nach ihrem Leitbild, nach ihrer Relationalität -- nach ihrem Muster der Zusammenstellung und der Trennung von (Nicht-)Menschen und Kollektiven -- über ihre eigenen Instanzen hinaus beobachten, deuten und beeinflussen. Nichtsdestotrotz verbindet die Relationsstrukturen ihre Relationalität, die als Merkmal einer Relationsstruktur vorhanden ist, selbst wenn sie unterschiedlich entwickelt wird. Diese Ausgangslage bereitet die Grundlage der Einflussstrategie von Relationsstrukturen auf andere Relationsstrukturen vor, die die Theorie der Relation als Einflussmacht durch Allianzen begreift und mit dem Terminus der Satellisierung analytisch auffasst.

Was wir am Beispiel der Forschung gesagt haben, übernehmen wir, um die Rechenzentren zu behandeln. Sie gehören nicht zwangsläufig einem bestimmten Bereich der Gesellschaft und einer einzigen Ordnung von Verhältnissen an. Jedoch sind Rechenzentren nicht deshalb kategoriell unterschiedlich voneinander, sondern sie zeigen vergleichbare Grundmerkmale, von denen das wichtigste das materielle Merkmal ist. Ohne Rechner kein Internet, weshalb im Bereich der Rechenzentren und im Allgemeinen in der Medienwelt die materielle Bedingung äußerst wichtig für die Relationalität ist, die diese Medienwelt strukturiert. Diese Wichtigkeit hebt auch die soziologische bzw. sozialwissenschaftliche Literatur zu Rechenzentren hervor. Sie versteht die Rechenzentren bevorzugt als -- in unseren Worten -- Instanzen einer medialen Relationsstruktur bzw. der Medienwelt in der Verlängerung unzähliger digitaler Technologien. Sie zeigt, dass die abstrakte bzw. virtuelle Welt der Informationsgesellschaft viele konkrete Elemente (Menschen und Maschinen) voraussetzt, ohne die sie gar nicht existieren könnte [cite:vgl. etwa @blanchette11:_mater_histor_bits;@mattern13:_code_clay_data_dirt;@parks15:_signal_traff;@starosielski15:_under_networ]. Diese Informationsgesellschaft verbraucht immer mehr Medien als materielle Bedingungen der Entwicklung von immer mehr/besseren/umfangreicheren medialen Verhältnissen. Dieser Ansatz, der seit der letzten Dekade in den Sozialwissenschaften an Aufmerksamkeit gewinnt, unterscheidet sich von einem anderen Ansatz, der die materiellen Bedingungen von Rechenzentren ebenfalls berücksichtigt. Aber er versteht sie anders bzw. in Bezug auf die Verbesserung der Leistung von Rechenzentren.

Dieser letzte Ansatz taucht in einer Fülle von Beiträgen aus der Literatur in den Bereichen der Technikwissenschaften (Ingenieurwissenschaft, Informatik, Physik) auf, die sich speziell mit Rechenzentren als Zusammenstellung von unterschiedlichen wissenschaftlichen Verfahren und Techniken auseinandersetzen. In dieser Literatur werden Rechenzentren nicht bevorzugt als Instanzen einer medialen Relationsstruktur verstanden, sondern vor allem als Instanzen der Wissenschaft -- in unseren Termini eines Tätigkeitsbereiches in einer anderen (soziokulturellen) Relationsstruktur. Rechenzentren werden hier anders bzw. nach einer Relationalität aufgefasst, die (Kollektiv)Akteure zusammenstellt, um wissenschaftliches Wissen zu konkretisieren und für weitere Akteure attraktiv zu machen. Bei einer solchen Relationalität handelt es sich darum, Instanzen wie Rechenzentren zu verwenden, um Materien für Techniken zum Vorteil der Miniaturisierung von Techniken zu optimieren, damit wissenschaftliche Vorhaben verstärkt entwickelt werden. Konkret geht es darum, bessere rechnerische Kapazitäten von Rechenzentren zu gewinnen, die gleichzeitig weniger Raum brauchen und schneller funktionieren. In dieser Hinsicht stellen Rechenzentren eine Möglichkeit dar, zu prüfen, wie mit weniger Materie mehr rechnerische und am Ende mehr wissenschaftliche Leistung generiert werden kann.

In vergangenen Arbeiten haben wir Untersuchungen zu diesem letzten Ansatz durchgeführt. Wir haben gezeigt, dass er nach dem Zweiten Weltkrieg mit der Entstehung von interaktiven Medien und der Entwicklung von Nanotechnologien in Verbindung mit unterschiedlichen Branchen der Wirtschaft (Kommunikationstechnologien, Lebensmittel, Verpackung) und Disziplinen der Wissenschaft (Chemie, Physik, Medizin und Pharmazie) unermüdlich weiter getragen wird. [cite:@monoPapilloud2007;@monoPapilloud2012;@kapitelPapilloud2013;@monoPapilloudSchultze2023]. Insbesondere im Zusammenhang der Nanotechnologien konnten wir feststellen, dass ein solcher Ansatz nach der Umverteilung von Räumlichkeiten argumentiert (was da draußen als Raum beobachtet werden kann, wird dank der Eroberung von Räumlichkeiten innerhalb von Materien eingespart), um das Problem des Energieverbrauchs von Materialien zu lösen. Oder anders gesagt: Wenn mehr Raum innerhalb von Materien für Technologien geschafft werden kann, dann können Technologien vermehrt werden, ohne mehr Räumlichkeiten in der Welt zu beanspruchen. Sie verlangen entsprechend weniger Energieressourcen. Mehr (Technologien) führt zu weniger (Raum- und Energieverbrauch).

Dieser spezielle Ansatz zur Umverteilung von Raum und Energieressourcen kollidiert mit dem ersten Ansatz zu Rechenzentren als Instanzen der Medienwelt, wenn wir daran erinnern, dass Rechenzentren zum Kern der Informations- und Kommunikationstechnologien (IKT) und damit der Informationsgesellschaft avancieren. An diesem Punkt stoßen wir also auf zwei Relationalitäten und zwei Relationsstrukturen, die die Rechenzentren nicht nur an sich, sondern gleichsam auch in Bezug auf ihre gesellschaftliche Rolle unterschiedlich verstehen. Dies ist der Ausgangspunkt der Bildung einer Asymmetrie zwischen der Medienwelt und der Wissenschaft zum Vorteil der Medienwelt. Die Asymmetrie zum Vorteil der Medienwelt baut dabei auf die Infragestellung des Ansatz zur Umverteilung von Raum und Energieressourcen mit dem Argument auf, dass Rechenzentren für die ganze Gesellschaft eingesetzt und deshalb vermehrt werden müssen.

* Rechenzentren als Kern der Informationsgesellschaft

Dass Rechenzentren zum Kern der Informationsgesellschaft werden, beobachtet Bernard Aebischer (ETH-Zürich) im Rahmen des /Centre for Energy Policy and Economics/ seit langem. Er untersucht das breite Spektrum der IKT in historischer und transnationaler Perspektive mit einem Modellierungsansatz. Er schlägt eine Periodisierung der Entwicklung von IKT vor. In diesem Rahmen spricht er von den Rechenzentren, um zu untersuchen, wann sie immer bedeutsamer für die Informationsgesellschaft wurden und weiter werden. Dieser Bedeutungsgewinn beginnt mit der Suche nach Maßnahmen zur Einsparung von Energie nach den zwei Ölkrisen von 1973 und 1979 [cite:@aebischer14:_energ_deman_ict 6]. Strom wird überall teurer, deshalb wollen die Länder wissen, wie sie Strom sparen können. Alles, was Strom verbraucht, wird berücksichtigt, so auch die Rechner, die im Laufe der 80er Jahre in Form des /Personal Computer/ vermehrt in der Wirtschaft und in der Wissenschaft verwendet werden (ebd., 4). Die ersten Studien zum Stromverbrauch von Rechnern arbeiten mit einem Technologieansatz, der an Moores Gesetz angedockt, demnach die Anzahl an Transistoren in integrierten Schaltkreisen aller zwei Jahre verdoppelt wird (ebd.). Sie kommen zu vergleichbaren Ergebnissen: Die Vermehrung von Rechnern lassen den Energieverbrauch in der Gesellschaft steigen. Aber dank der technologischen Entwicklung soll er schnell wieder sinken. Simulationen und Szenarien, die für eine Zeitspanne von 40 Jahren gebildet werden (1985-2025), kommen zu dem Schluss, dass es gut möglich sei, dass in 2025 Rechner insgesamt nicht mehr Energie als im Jahr 1985 verbrauchen würden (etwa am Beispiel der Schweiz, ebd.). Dabei werden auch sog. /mainframes/ bzw. existierende Rechenzentren berücksichtigt, selbst wenn sie noch keine spezielle Hervorhebung genießen.

Rechenzentren in Gesellschaften vor dem Internet werden nicht mit der Vorstellung von einer Informationsgesellschaft verbunden. Häufig außerhalb von Großstädten in billigen Lagergebäuden angesiedelt, unterstützen solche Rechenzentren maßgeblich die rechnerischen Tätigkeiten in der Wissenschaft und in der Wirtschaft [cite:@carnino19:_du 168]. Sie bieten lediglich eine Automatisierung und eine Beschleunigung von einigen Verfahren an, die zuvor von Menschen mit entsprechendem Aufwand und nicht immer fehlerfrei durchgeführt wurden. In Bezug auf die Frage des Energieverbrauchs von solchen Rechenzentren betont Aebischer: "the financial sector, research institutions and universities, a few industries and some governmental agencies were the only important users of large computers. Electricity demand of these machines was a concern for these organizations but was barely registered by policy makers or the general public" (ebd., 11). Was Aebischer mit "barely registered by policy makers" meint, können wir am Beispiel Deutschlands qualitativ anhand von einem Topic-Modell festmachen. Um Platz zu sparen, und weil in der Zwischenzeit diese Methode in den Sozialwissenschaften rezipiert wurde, stellen wir sie hier nicht nochmal vor [cite:vlg. stattdessen @papilloud18:_einfü_analy_texten_topic_model], sondern wir kommen unmittelbar zu unserer Operationalisierung.

Im Kontext dieses Vorhabens haben wir als Grundlage unserer Modellierung der Aufmerksamkeit, die die deutsche Politik den Rechenzentren schenkt, die Parlamentsdokumente der Bundesrepublik Deutschland und die Protokollen des Bundestages herangezogen. Diese Dokumente können auf der folgenden Adresse als XML-Dateien, mit einer API oder nach handwerklicher Suche heruntergeladen werden: https://www.bundestag.de/services/opendata. Ein Github-Konto bietet diesen Datensatz als R-Objekt an: https://github.com/benjaminguinaudeau/tidybundestag. Inhaltlich liefern diese Dokumente unterschiedliche Informationen zu den politischen Entscheidungen, die von 1949 bis heute auf Bundesebene getroffen wurden. Bezogen auf unser Vorhaben erlauben sie eine Rekonstruktion der thematischen Zusammenhänge, in denen die Rechenzentren von deutschen Politikern angesprochen wurden. Wir haben uns auf die XML-Dateien bezogen, die wir in Textdateien umgewandelt haben. Diese Dateien haben wir um die letzten Parlamentsdokumente und Protokolle (bis Juni 2025) vervollständigt. Anschließend haben wir die Dokumente nach Wahlperioden klassifiziert und nach Datum, Sprecher, politischer Partei des Sprechers und politischem Status des Sprechers (etwa Ministerpräsidenten) zerlegt. Bei der Selektion der relevanten Dokumente sind wir zuerst mit dem folgenden breiten Ansatz vorgegangen: Wenn das Wort "Rechenzentren" zumindest ein Mal in einem Dokument enthalten ist, dann fließt dieses Dokument in die Analyse ein. Weil dieser Ansatz sehr viele Dokumente generiert hat, die mit dem Thema "Rechenzentrum" lose verbunden waren, haben wir ihn enger gefasst. Wir haben nur die Text-Teile in den Dokumenten bzw. die einzelnen Wortmeldungen von Sprechern ausgewählt, die unmittelbar mit dem Thema "Rechenzentrum" verbunden waren. Mit diesem letzten Ansatz konnten wir eine verdichtete Abbildung der Themen zum Oberthema "Rechenzentrum" im Bundestag in der Zeit erhalten (vgl. Abbildung 1). Die Modellierung haben wir mit unserer Anwendung /MTA/ durchgeführt [cite:@papilloud17:_mta_multi_text_analy].

#+Caption: Entwicklung der Themen zu "Rechenzentrum" in den Debatten des deutschen Bundestages
#+ATTR_ODT: :width 15 :height 15
[[./Trends7T.png]]

Die Abbildung 1 zeigt einerseits, dass die Debatten im Bundestag das Thema "Rechenzentrum" in verschiedenen Richtungen perspektivieren. Es ergeben sich daher sieben Themenkomplexe im Zusammenhang mit Rechenzentren, die wiederum in der Zeit unterschiedlich bedeutsam sind. Bezogen auf die Aussage von Aebischer kann zudem festgestellt werden, dass die deutsche Politik das Thema Rechenzentren seit langem debattiert. Fokussieren wir nun den Zusammenhang zwischen Energie und Rechenzentren, so zeigt sich, dass dieser nur im Themenkomplex "Energie/Wirtschaft/Optimierung/Nachhaltigkeit" verhandelt wird. Dieser Themenkomplex bildet ferner nur zwischen 1995 und 2000 das Leitthema der Debatten zu Rechenzentren im Bundestag. Davor bleibt er hinter dem Thema "Datenschutz" zurück und verliert danach weiter an Bedeutung im Vergleich zu den Themen "Forschung/Wissenschaft" und "Apotheken/Medizin" (in diesem Zusammenhang insbesondere in Bezug auf die Verbesserung der automatischen Herstellung von Rechnungen und der entsprechenden Zahlung dieser Rechnungen). Am Ende der Zeitspanne herrschen insbesondere die Themen Bundesverteidigung sowie "Darmstadt/Bildung/Forschung" in Bezug auf die Veränderung der internationalen Lage (Krieg zwischen Russland und der Ukraine, Covid-19 und Entwicklung der Fernarbeit, Einsatz des Blockchains zur Verschlüsselung von Transaktionen und Kommunikationen, Durchbruch der künstlichen Intelligenz) vor.

Wenn wir andererseits den Themenkomplex "Energie/Wirtschaft/Optimierung/Nachhaltigkeit" in den Jahren 1995-2000 in den Blick nehmen, dann fällt auf, dass wir nur eine Erwähnung von Energie im Rahmen von Rechenzentren in Bezug auf das FCKW-Halon-Verbot registrieren können. Frau Monika Ganseforth (SPD) spricht am 16.03.1995 dieses Thema an. Sie bedauert, dass dieses Verbot u. a. noch nicht für Rechenzentren und EDV-Anlagen gelte. Wie Aebischer sagt, wird die Strom- und im Allgemeinen die Energiefrage bei Rechenzentren in den 90er Jahren von der deutschen Politik kaum berücksichtigt. Dieser Befund lässt sich auf die Debatten des Bundestags beinahe bis heute erweitern. Dennoch beobachten wir eine leichte Wiederbelebung des Themenkomplexes "Energie/Wirtschaft/Optimierung/Nachhaltigkeit" in den Jahren 2022/2023. Wenn wir diese letzten Jahre des Aufgreifens der Rechenzetrum-Thematik im Bundestag in unseren Dokumenten prüfen, so wird offenbar, dass sich die Debatten über die Rechenzentren um die Frage drehen, ob Rechenzentren als Hebel einer grünen Ökonomie fungieren könnten, die von wissenschaftlichen Innovationen unterstützt wäre. Dieser Aspekt der jüngsten Debatten um die Rechenzentren im deutschen Bundestag wollen wir im Folgenden vertiefen.

Er betrifft ein Problem, das dazu beigetragen hat, die Bedeutung von Rechenzentren in der Gesellschaft zu verdeutlichen: Das Dilemma Energieverbrauch vs. Energieeffizienz. Dieses Problem spiegelt nicht nur die wachsende Asymmetrie wider, die die Medienwelt gegenüber der Wissenschaft mit dem Ziel entwickelt, dass Rechenzentren im Dienst der ganzen Gesellschaft verbreitet werden müssen. Es zeigt auch den Versuch vonseiten der Politik, diese Einflussstrategie zu dämpfen bzw. eine eigene Einflussstrategie auf die Medienwelt mit der Zielsetzung zu entwickeln, dass Rechenzentren nur dann in der ganzen Gesellschaft Verbreitung finden sollen, wenn sie ökologisch freundlich funktionieren. In diesem letzten Punkt ziehen die Politiker und Politikerinnen im Bundestag aber längst nicht am selben Strang.

* Energie und Rechenzentren im politischen Diskurs Deutschlands

Dass Rechenzentren für die Politik in den letzten Jahren an Bedeutung im Vergleich zu den Jahren davor gewonnen haben, zeigt unsere Topic-Modell-Analyse. Das dies nicht immer der Fall war, kann am Beispiel der Auseinandersetzung zwischen Paul Laufs (CDU) und Erwin Stahl (SPD) zu den Rechenzentren im Protokoll des Bundestages vom 28.09.1978 veranschaulicht werden: "(Laufs) Aus welchen Gründen schlägt die Bundesregierung vor, die Mittelzuweisungen aus dem Haushalt für Forschung und Technologie für die Finanzierung von regionalen Rechenzentren gegenüber dem Plan des 3. DV-Programms 1976-79 drastisch zu kürzen?"; "(Stahl) Herr Kollege Dr. Laufs, es trifft nicht zu, daß die Mittel für die Finanzierung von regionalen Rechenzentren gegenüber dem Plan des 3. DV-Programms drastisch gekürzt worden sind. Im Zeitraum von 1976 bis 1979 werden 142 Millionen DM bereitgestellt werden; das sind 15 % weniger als ursprünglich geplant. Die Mittel haben bisher ausgereicht und werden auch im Jahre 1979 ausreichen"; "(Laufs) Herr Staatssekretär, sind Ihnen die Befürchtungen bei den regionalen Rechenzentren bekannt, daß die deutsche rechenintensive Forschung gegenüber der Industrie und dem Ausland ins Hintertreffen geraten wird, weil die regionalen Großrechenanlagen hinsichtlich ihres Preis-Leistung-Verhältnisses und auch ihrer Rechenleistung durch diese Politik der Bundesregierung nicht auf dem Stand der Zeit gehalten werden können?"; "(Stahl) Derartige Äußerungen, Herr Kollege Dr. Laufs, sind mir nicht bekannt. Ich darf nochmals darauf aufmerksam machen, daß für DV-Beschaffungen im Regionalprogramm bis zum 31. Dezember 1977 einschließlich des DV-Sonderprogramms insgesamt 290,6 Millionen DM ausgegeben worden sind. Weitere Klagen sind nicht bekannt".

45 Jahre später ist für die deutsche Politik deutlicher geworden, dass angesichts der wachsenden Bedeutung von Rechenzentren in der ganzen Gesellschaft in Rechenzentren investiert werden muss. Aber vollkommen ausgeräumt sind die Kontroversen nicht. Sie betreffen nunmehr lediglich eine andere Frage, die an der umstrittenen Schnittstelle des ökonomischen Wachstums und der ökologischen Bilanz debattiert wird. Das Protokoll des Bundestages zur Sitzung vom 17.05.2023 zeigt exemplarisch, wie die Politik uneins in Bezug auf Rechenzentren reagiert. In seinem Redebeitrag im Bundestag stellt Uwe Kamann (LKR, IT-Unternehmer) die folgende Frage, die eine Debatte zu den Rechenzentren in dieser Sitzung hervorruft: "Sie fordern von der Bundesregierung, den Stromverbrauch für den Ausbau des 5G-Netzes und die Auswirkung dessen auf Rechenzentren zu validieren. Wenn diese dann höher ausfallen, als es ideologisch akzeptierbar ist, was ist dann? Wollen Sie dann wie beim Schadstoffausstoß des Diesels willkürliche Grenzwerte festlegen, oder wollen Sie gar ganze Rechenzentren stilllegen?". Dazu äußern sich Timon Gremmels und Falko Mohrs (SPD) sowie Dieter Janecek (Bündnis 90/Die Grünen). Sie plädieren dafür, dass Rechenzentren auch im Rahmen der Energiewende berücksichtigt werden müssen, weil sie in den Debatten zur Digitalisierung eine wichtige Rolle spielen. Hansjörg Durz (CSU) erwidert darauf, dass dies schon seit 2022 der Fall ist, und fügt hinzu, dass Rechenzentren bald Teil von einer "Digitalagenda" sein werden: "Viele Ihrer Forderungen sind darin bereits enthalten. Auch die Forderung nach energieeffizienteren digitalen Produkten und der Nutzung der Abwärme von Rechenzentren ist eine Forderung, die in Papieren der Union aus den vergangenen Jahren zu finden ist". Nichtsdestotrotz werfen Die Linke durch Frau Anke Domscheit der Regierung vor, dass eine solche Agenda eher vage bleibt.

In den Debatten im Bundestag kommt deutlich zum Vorschein, dass daran gezweifelt wird, wie energieeffiziente Rechenzentren gelingen können, ohne dass eine solche Energieeffizienz zu weniger Leistung führen würde. Dies würde nicht nur für die Wissenschaft, sondern auch für die Wirtschaft fatale Folgen zeitigen. Falko Mohrs erinnert in der Sitzung des Bundestages vom 17.05.2023 daran, dass dieser Punkt schon 2008 im Rahmen "der Beschaffungsstrategie des Bundes verankert [wurde]". Dies lässt sich in den Protokollen des Bundestages nicht wiederfinden, zumal es eine Beschaffungsstrategie des Bundes nicht gibt, sondern mehrere (etwa für Raumfahrttechnologien in der Partnerschaft mit der EU, für Rohstoffe und Energiequellen oder für Autos). Seit 1983 werden solche Strategien im Bundestag kontrovers diskutiert, die Debatten betreffen aber das Thema Rechenzentren nicht. Die Erwähnung des Jahres 2008 durch Falko Mohrs ist dennoch interessant. Im Anschluss an der IT-Messe /CeBIT/ findet in diesem Jahr eine Debatte einerseits zur Unterstützung der Forschung in den IT-Bereichen und andererseits zu ökologischen Maßnahmen statt (Sitzung des Bundestages am 05.03.2008). Zum ersten Punkt äußert sich Lothar Bisky (Die Linke), der besonders bedauert, dass die Bundesregierung die Forschung in den IT-Bereichen grundsätzlich als nur von den IT-Industrien getrieben sieht. Er plädiert stattdessen für mehr Unterstützung der wissenschaftlichen Forschung: "IT-Forschung ist nach dem Verständnis der Bundesregierung daher vorrangig ein Programm zur Subventionierung von Informations- und Kommunikationstechnologie in ausgewählten Anwendungsbereichen, vor allem Automobilbau, Telekommunikation, Logistik und Medizintechnik. (...) Darauf allein (...) lässt sich die Basis für eine Informations- und Wissensgesellschaft nicht gründen. (...) Den Hochschulen kommt auf diesem Feld eine wichtige, wenn nicht entscheidende Aufgabe für die Zukunft zu". Wissenschaftlicher statt industrieller Forschung soll deshalb Priorität eingeräumt werden, weil sich dort das Potential zur Herstellung von grüneren Produkten befinde: "Nicht umsonst gibt es 'Green IT', ein Schwerpunktthema der CeBIT". Heinz Schmitt (SPD) verlängert die Überlegung von Bisky: "Laut BUND ist der Stromverbrauch von IT-Geräten für 43 Prozent der CO2-Emissionen in Deutschland verantwortlich. Handy, Computer, Fernseher, moderne Informationstechnik benötigt immer mehr Energie. (...) Um den Energieverbrauch vom Wirtschaftswachstum zu entkoppeln, müssen wir quer durch alle Wirtschaftsbereiche energieeffiziente Produkte konstruieren, produzieren, nutzen und -- ein ganz wichtiger Punkt -- recyceln. Und dies ist nur mit innovativer Hightech machbar. Moderne Informationstechnik und Umweltschutz müssen also miteinander kombiniert werden. Davon profitiert die Umwelt; mit Green IT lässt sich aber auch viel Geld verdienen bzw. viel Geld einsparen".

Diese Debatten zu Rechenzentren im Bundestag verdeutlichen das, was für die deutsche Politik in diesem Zusammenhang auf dem Spiel steht. Zum einen haben wir Betreiber von Rechenzentren zusammen mit IT-Unternehmen, die versuchen, Einfluss auf die Politik auszuüben, um Rechenzentren in der ganzen Gesellschaft zu verbreiten. Hier spielt die Politik einerseits mit. Andererseits greift sie aber auch die Frage des Energieverbrauchs der Rechenzentren auf, um sich von dieser Einflussstrategie der Betreiber von Rechenzentren und IT-Unternehmen zu befreien und diese Unternehmer im Umkehrschluss zu beeinflussen. Zu diesem Zweck setzt die Politik ein wichtiges Mittel ein: Die Allianz mit der Wissenschaft, damit die Wirtschaft mit daran arbeiten muss, innovative Lösungen zu finden, die es erlauben, den Energieverbrauch von Rechenzentren besser zu regulieren. Der Redebeitrag von Schmitt verdeutlicht diese Strategie der Allianz zwischen Experten aus der Wissenschaft und der Wirtschaft, wenn er später in seiner Ausführung die Expertise des Fachverbands BITKOM im Bereich IT erwähnt. Im Zuge der Mobilisierung der wissenschaftlichen Forschung sollte auch BITKOM herangezogen werden, der sich als Fachverband in Fragen des Energieverbrauches von Rechenzentren in Deutschland gut auskenne. Der Wunsch nach Expertisen unter Mitwirkung spezialisierter Verbände aus der Wirtschaft und mit der Wissenschaft verdeutlicht die Entwicklung von einer Satellisierungsstrategie an der Seite der Politik. Sie benutzt die Wissenschaft und die Wirtschaft als Satelliten, um Einfluss auf die Medienwelt auszuüben und ihren Satellisierungsansatz zu schwächen, nach dem Rechenzentren in der Gesellschaft vermehrt werden müssen. Diesem Ansatz stellt die deutsche Politik die Satellisierungsstrategie von ökologisch vertretbaren Rechenzentren gegenüber. Sie erzielt eine bessere Machtbalance im Bereich von Rechenzentren. So unwiderstehlich Rechenzentren sein mögen bzw. so attraktiv sie seien, bleibe es wichtig, dass besonders bei Fragen des Energieverbrauchs und der Energieeffizienz andere gesellschaftliche Instanzen sowie Akteure in der Gesellschaft dieser Attraktivität von Rechenzentren nicht geopfert werden. Energie bräuchten nicht nur Rechenzentren, und Energie habe einen Preis im Sinne des Verbrauchs von ökologischen Ressourcen sowie im Sinne der Weltverschmutzung und des Klimawandels.

Anders gesagt: Die deutsche Politik versteht Rechenzentren als Umverteilungsproblem bzw. als Problem der Umverteilung von Energie in Anlehnung an die wissenschaftlich-technische Literatur zu Rechenzentren. Damit hinterfragt sie implizit das Gewicht von Rechenzentren in der Gesellschaft und die Bedeutung, die ihnen die Medienwelt beimisst. Durch Satelliten in der Wissenschaft und in der Wirtschaft zielt sie auf eine Schwächung der Verbreitung von einer Relationalität, wie sie die Medienwelt versteht, nach der in einer Zeit, in der alle Arten von Verhältnissen technologisiert werden, Rechenzentren expandieren müssen. Ein solches Unternehmen ist nicht neu, sondern es verlängert alte Bemühungen, die ab 2007 schon im Gang sind und immer weiter an Fahrt aufnehmen. Das Bundesministerium für Umwelt, Naturschutz, Bau und Reaktorensicherheit (BMU) veranstaltet in dieser Zeit einen "Fachdialog (...) zum Thema 'Zukunftsmarkt 'grüne' Rechenzentren'" mit BITKOM sowie Partnern aus der Wissenschaft (Oldenburg Center for Sustainability Economics and Management der Universität Oldenburg, dem Fraunhofer Institut für System- und Innovationsforschung in Karlsruhe sowie dem Institut für Zukunftsstudien und Technologiebewertung) [cite:@fichter07:_zukun_energ_rechen, I]. Es beauftragt die unabhängige und gemeinnützige Forschungseinrichtung Borderstep (Berlin) mit einem Bericht zur Frage der Rechenzentren und deren Energieeffizienz, der im selben Jahr veröffentlicht wird.

* Brüchige Satellisierung von wirtschaftlichen Instanzen

Mit ihrer Satellisierungstrategie versucht die deutsche Politik, ihren Einfluss bis in die Wirtschaft mit dem Ziel zu erstrecken, eine Machtbalance im Bereich der deutschen Rechenzentren zu etablieren. Um (Kollektiv)Akteure der Wirtschaft für ihre Strategie zu gewinnen, wird der Diskurs zu Rechenzentren mit einer ökonomischen Semantik codiert, die potentielle Alliierte aus der Wirtschaft unzweideutig verstehen dürften. Der Bericht von Borderstep bildet diese Diskursentwicklung hin zu einem ökonomischen Verständnis von Rechenzentren ab.

Zum Thema Rechenzentrum werden entsprechend "die Entwicklung der Wettbewerbsfähigkeit deutscher und europäischer Unternehmen im internationalen Vergleich, ihr Umfeld sowie Ansatzpunkte für eine Stärkung des deutschen und europäischen Innovationssystems" als zentrale Anliegen lanciert (ebd.). Eine solche Formulierung ist nicht nur typisch für die politische Wahrnehmung von Technologien, wie sie sich im politischen Diskurs niederschlägt, der seit den 70er Jahren die Partnerschaft zwischen Wissenschaft und Wirtschaft zur Entstehung einer Wissensökonomie fördern will. Sie spiegelt gleichsam die Grundlage der Satellisierungsstrategie ausgehend von der Politik in der Gesellschaft wider. Dabei besteht die Strategie darin, zum einen Expertise aus der Wissenschaft einzubeziehen, um gesellschaftliche Probleme zu dimensionieren, während zum anderen aus eben dieser Dimensionierung Lösungsvorschläge aus der Wirtschaft erwartet werden. So erfolgt die politische Handlung nicht nur formal in rechtlichen Regeln und Normen, sondern auch konkret in Förderungsmaßnahmen und Zuwendungen. Bei dieser Strategie der Satellisierung von Wissenschaft und Wirtschaft, die uns im Rahmen von Hochtechnologie häufig begegnet ist [cite:@monoPapilloud2012;@monoPapilloudSchultze2023], spielen Instanzen der Umverteilung in der Politik eine wichtige Rolle. Wie Instanzen der Umverteilung in anderen Bereichen der Gesellschaft tragen sie zur Erkennung von Problemen und der Formulierung von Vorschlägen für die Orientierung von Akteuren und gesellschaftlichen Instanzen bei. Sie messen, wiegen, vergleichen, beziffern, berechnen die Realität. Die Realität wird von ihnen also in Zahlen, Formeln, Indikatoren symbolisiert und ausgedrückt, wodurch Instanzen der Umverteilung nicht zuletzt dafür Sorge tragen, das Unbekannte sichtbar und bekannt zu machen. Im Fall der Rechenzentren sollen sie genau dies tun, damit "das Potential von einem solchen Markt besser benutzt wird" (ebd., 1).

Die Darstellung von Rechenzentren als Markt soll nicht nur Partner in der Wirtschaft zu mobilisieren erlauben. Sie soll auch das Problem der Definition von Rechenzentren lösen: "Bislang gibt es keine allgemein gültige Definition des Begriffs 'Rechenzentrum' bzw. 'data centre'" (ebd. 5). Mit dem Wort "Rechenzentrum" wird zwar die Verbindung zwischen Rechnern und Räumlichkeiten bezeichnet. Aber Rechenzentrum ist nicht gleich Rechenzentrum. Deshalb orientiert sich die Definition von Boderstep im Einklang mit der jüngsten Expertenliteratur aus den Vereinigten Staaten zuallererst auf die Schnittstelle zwischen Rechentechnik und Räumlichkeit, um sie zu beziffern und somit den Begriff "Rechenzentrum" zu präzisieren. Unter Rechenzentren versteht man demnach nun Zusammenstellungen von Dutzenden bis Tausenden von Servern in Räumlichkeiten von mindestens 50 bis mehr als 500 Quadratmeter (ebd., 5-6). Im Sinne einer technischen Definition bedeutet diese räumlich orientierte Definition von Rechenzentren, dass Rechenzentren als eben solche gelten, wenn sie über Server, Speicher und die entsprechende Netzwerkausrüstung ebenso verfügen, wie über unterbrechungsfreie Stromversorgung, Stromverteilung, Klimatisierung und Kühlung (ebd., 8).

Das Problem von dieser Definition der Rechenzentren ergibt sich fast von selbst: Rechenzentren sind eher ein Markt der Märkte. Sie verweisen auf IT-Produkte, auf Dienstleistungen im Bereich von Telekommunikationen, auf die Halbleiterindustrie, auf die Stromindustrie, auf das Bauwesen bis hin zu Startups und Spin-offs. Sie verweisen aber mindestens ebenso sehr auf Bereiche außerhalb der Wirtschaft, wie der wissenschaftlichen Forschung in sehr unterschiedlichen Disziplinen (Chemie, Physik, Optik, Ingenieurwesen, Informatik usw.). Eine solche Definition von Rechenzentren grenzt zwar einerseits ein, was als "Rechenzentrum" gilt, damit nicht alles, was mit Rechnern verbunden ist, in diese Definition einfließt. Dies funktioniert aber andererseits eher rhetorisch als analytisch. Kleine Rechenzentren beispielsweise (wenige Rechner in Räumlichkeiten von weniger als 50 Quadratmetern), die von der Definition der Rechenzentren ausgeschlossen werden, tragen auch zum Problem der Energieeffizienz von größeren Rechenzentren bei, die durch diese Definition fokussiert werden. In diesem Zusammenhang ließe sich etwa der Zugang zum Internet erwähnen, der den Anschluss von kleinen Servern mit größeren Servern voraussetzt. Deshalb funktioniert der räumlich orientierte Ansatz bei der Definition von Rechenzentren entweder gar nicht oder nur bedingt. Er muss also um einen wissenschaftlich-technischen Ansatz ergänzt werden, was zugleich den typischen Weg der Politik zur gezielten Einflussnahme in der Wirtschaft auf der Grundlage wissenschaftlicher Expertise widerspiegelt. Der wissenschaftlich-technische Ansatz wird sich dabei jedoch als wichtiger erweisen, damit die deutsche Politik ihr Verständnis von Rechenzentren besser in der Wirtschaft lancieren und Unterstützer aus der Wirtschaft für ihre Satellisierungsstrategie mobilisieren kann.

* Die Notwendigkeit der stärkeren Investition in wissenschaftliche Expertise

Der Einbezug einer wissenschaftlich-technischen Expertise vereinfacht das Problem aber nicht unbedingt. Er steigert vielmehr die thematische Komplexität zum Energieverbrauch von Rechenzentren. Auch Aebischer adressiert die problematische Frage des Energieverbrauchs von Rechenzentrengreift in folgender Weisen: "Ideally, energy efficiency of a data centre should be measured in terms of energy consumption per unit of service delivered to the customer. However, there exists no commonly agreed method to measure the service provided by a data centre" [cite:@aebischer03:_energ 437]. Anders gesagt: Die technologische Entwicklung erschwert die Herstellung von einem Referenzwert der Energieeffizienz für Rechenzentren. Er würde erlauben, genaue Messungen des Energieverbrauchs und der Energieverluste in Rechenzentren durchzuführen. Hieraus ließen sich Standards für Messzahlen mit dem Ziel definieren, den Energieverbrauch von unterschiedlichen Rechenzentren trans-national miteinander zu vergleichen. Selbst Aebischer schlägt einen "Coefficient of Energy Efficiency (CEE)" auf der Grundlage von zwei Richtwerten, C1 und C2, vor, wobei CEE = C1*C2 ist (ebd.). C1 soll dabei die Effizienz der Infrastruktur von einem Rechenzentrum messen, wohingegen C2 die Effizienz der Rechentechnik in dieser Infrastruktur beziffert (ebd., 438). Während nun aber der Wert von C1 unmittelbar bestimmt werden kann, ist der Wert von C2 demgegenüber nur schwer oder lediglich mittelbar bezifferbar (Unterschied zwischen dem gesamten Strom, der in das Rechenzentrum fließt, und dem Strom, der darin verloren geht; ebd.). Deshalb bleibt der CEE als Indikator der Messung von der Energieeffizienz der Rechenzentren unbefriedigend. Er kann folglich nicht unmittelbar als Grundlage für die Formulierung von Vorschlägen vonseiten der Politik verwendet werden.

Im Jahr 2014 verallgemeinert Aebischer diese Schlussfolgerung auf alle Indikatoren, die im Bereich der Energieeffizienz der Rechenzentren eingesetzt werden. Dies gilt etwa auch für den Indikator von Green Grid /Power Usage Effectiveness/ (PUE) [cite:@haas09:_usage_public_repor_guidel_green], der seit 2009 weltweit eingesetzt wird, um die Energieeffizienz von Rechenzentren zu messen [cite:@aebischer14:_energ_deman_ict 11]. Die positive Seite dieser Messungsproblematik ist, dass das Interesse für den Energieverbrauch von Rechenzentren steigt. Wie Aebischer zeigt, wurden seit dem mehrere Initiativen weltweit ergriffen (angefangen bei der Akzentsetzung auf die Virtualisierung von Dienstleistungen über /cloud computing/ bis hin zu der Initiative /Energy Star/ in den Vereinigten Staaten, den europäischen /Code of Conduct for Data Centers/ oder die Initiative /CRC Energy Efficiency Scheme/ in Großbritanien; ebd., 12), um mehr Erkenntnisse zum Stromverbrauch von Rechenzentren in der Hoffnung zu sammeln, dass in der nahen Zukunft energieeffizientere Rechenzentren gebaut werden.

Borderstep folgt diesen Entwicklungen, insofern m Ansatz auch und versucht in einem zweiten Bericht in Begleitung von BITKOM die Frage des Energieverbrauchs bzw. der Energieeffizienz von Rechenzentren auf den Grund zu gehen. Wie Borderstep in seinem ersten Bericht sagte: "Für die Ermittlung und das Monitoring des Energieverbrauchs von Rechenzentren ist die Frage zentral, wie viele Rechenzentren welchen Typs und welcher Größe es gibt. Hierzu existieren bis dato weder in der Wissenschaft noch bei den Branchenverbänden oder den einschlägigen Marktforschungseinrichtungen Statistiken" [cite:@fichter07:_zukun_energ_rechen 8]. Deshalb wird 2010 eine materielle Bestandaufnahme von der geschätzten Anzahl an Rechenzentren angestrebt. Dabei wird die eingeschränkte Definition der Rechenzentren von 2007 zwar wieder erwähnt [cite:@hintemann10:_mater_rechen_deuts 13], aber nicht weiter verwendet. Im Bericht von 2010 geht es dagegen darum, alles, was Server enthält, im Blick zu nehmen. Dies zeigt einerseits, dass bei Borderstep und beim Auftraggeber BMU die Vermutung konkreter geworden ist, dass Rechenzentren nicht mehr nur diese Rechenzentren sind, die Universitäten und Firmen in der Unterstützung der eigenen Bedürfnissen an Automatisierung entwickelt haben. Es gibt eine Informationsgesellschaft, davon die gesellschaftlichen Instanzen mediale Verhältnisse in der Gesellschaft vermehren wollen, weshalb sie auf Rechenzentren angewiesen ist, die entsprechend entweder vermehrt und vergrößert (Stichwort /collocation datacentres/) werden. Andererseits zeigt es, dass sich Borderstep wie das BMU bewusst von der wachsender Bedeutung des wissenschaftlich-technischen Ansatzes und des stärkeren Einbezugs einer wissenschaftlichen Expertise werden. So können sie der Einflussstrategie der Medienwelt im Sinne einer besseren Regulation vom Energieverbrauch und von der Energieeffizienz der Rechenzentren entscheidend entgegenwirken.

In der Folge verlässt Borderstep ihre wirtschaftlichen Semantik zur Codierung vom Rechenzentren als wichtigem Markt vollständig. Es argumentiert dezidierter auf der Grundlage von einem wissenschaftlich-technischen empirischen Ansatz, innerhalb dessen Borderstep seinen ehemaligen räumlichen Ansatz neu formuliert. Kleinere "Rechenzentren" bzw. "Serverschränke" werden in der Analyse einbezogen. So können 53170 Rechenzentren für Deutschland im Jahr 2010 erfasst werden, die je nach Anzahl an Servern, die sie beinhalten, mehr als 1.280.000 Servern entsprechen (ebd., 25). Die Schätzung vom Energieverbrauch dieser Rechenzentren erfolgt in Bezug auf die Einzelkomponenten der Server- und Speichertechnik mit Einbezug der Netzwerktechnik. Weil der Energieverbrauch der Netzwerktechnik nur mittelbar geschätzt werden kann, wird sie mit einem Energieverbrauch von 10% der Servertechnik vorgesehen (ebd., 34). Diese Daten stellen die Grundlage für die Prognosen des Energieverbrauches von Rechenzentren in Deutschland bis 2015. Diese Prognosen richten sich nach Szenarien aus dem Bericht der /Lawrence Berkeley National Laboratory/ (LBNL) in Zusammenarbeit mit der /U.S. Environmental Protection Agency/ (EPA) zur Veranschaulichung von möglichen Trends beim Energieverbrauch von Rechenzentren in den Vereinigten Staaten [cite:@brown08:_repor_congr_server_data_center_energ_effic 8-10;@hintemann10:_mater_rechen_deuts 85-90].

Übersetzt und vereinfacht -- LBNL spricht von fünf Szenarien, Borderstep bildet zwei davon ab -- kommt Borderstep zum folgenden Schluss: Ohne Veränderungen im Vergleich zur vergangenen Entwicklungen der Rechenzentren in Deutschland sollte ihr Energieverbrauch von 2008 bis 2015 40% zunehmen (Szenario "Business as usual"). Wenn aber die "Green IT" im Rahmen von Rechenzentren entwickelt wird, dann könnte der Energieverbrauch von Rechenzentren in die umgekehrte Richtung gehen bzw. in der Zeit von 2008 bis 2015 40% abnehmen (ebd., 90). Diese Schätzung von +- 40% ist jedoch breit, weshalb Borderstep in seinen Schlussfolgerungen vorsichtig bleibt. Energieeffizienz kann zwar erreicht werden. Wie und wann sie erreicht werden kann, hängt aber von vielen Faktoren ab bzw. bleibt offen. Für die Machtbalance, die die Politik durch ihre Satellisierung aufzubauen abzielt, war nicht nur diese Analyse aufwendig, sondern auch ihr Ergebnis sieht eher mäßig aus. Dies stellt keine Ausnahme in der Landschaft von Berichten zum Energieverbrauch bzw. zur Energieeffizienz von Rechenzentren, die politische Instanzen in Europa bestellen.

* Verwundbare Machtbalancen

Aebischer merkte im Jahr 2009 an: "Bis heute hat sich aber noch keine Organisation auf ein Messkonzept einigen können, das erlauben würde, die Energieeffizienz von verschiedenen Rechenzentren verlässlich miteinander zu vergleichen. Es ist auch noch nicht gelungen, ein umfassendes Mass für die Energieeffizienz der Data Centres zu definieren" [cite:@aebischer09:_energ_rechen 18]. Im Jahr 2014 in seiner detaillierten Behandlung der unterschiedlichen Messwerte und Indikatoren, die weltweit zur Messung vom Energieverbrauch der Rechenzentren entwickelt werden, hat sich dieses Bild nicht verändert. Die Frage "Wie viele Energie verbrauchen Rechenzentren?" kann deshalb nicht zufriedenstellend beantwortet werden [cite:@aebischer14:_energ_deman_ict]. Zur konvergierenden Feststellung kommt in Deutschland der Bericht von Murzakulova im Auftrag für das Bundesministeriums für Wirtschaft und Klimaschutz [cite:@murzakulova25:_stand_entwic_rechen_deuts]. Wie Aebischer schon anmerkte, ist selbst der PUE-Wert unbefriedigend, der vom /Gesetz zur Steigerung der Energieeffizienz in Deutschland 1/ (EnEfG, 2023, Absch. 4, §11) mit dem Ziel aufgegriffen wird, klimaneutrale Rechenzentren zu etablieren. Zum Beispiel berücksichtigt er die "Anforderungen an Verfügbarkeiten und Redundanz von Ressourcen (...) sowie gängige Geschäftsmodelle" nicht, die im praktischen Betrieb von Rechenzentren Energie verlangen (ebd., 100). Dies setzt den realen PUE-Wert von Rechenzentren zu hoch. Er ist bei 1.8 bzw. 1.9, d. h. für 1 KW, der von der IT-Technik verbraucht wird, muss noch 0.8 bzw. 0.9 KW für die Umgebung der IT-Technik verbraucht werden. Damit übersteigt dieser PUE-Wert den Wert, der im Gesetz vorgesehen ist (1.2 bis 1.5). Deshalb ist es für die Betreiber von Rechenzentren unmöglich, die angeforderten PUE-Werte vom EnEfG zu treffen (ebd.).

Dies motiviert den Protest von diesen Betreibern, die den Eindruck haben, dass ihnen die Regierung das Geschäft zerstören will. In der Folge organisieren sie sich, um Druck auf politischen Instanzen auszuüben, wie dies etwa im Rahmen des /Climate Neutral Data Centre Pact/ ab 2021 geschieht. Es ist ein Netzwerk von Rechenzentrenbetreibern mit im Jahr 2025 Mitglieder in der Höhe von 85% des Marktanteils von Rechenzentren europaweit (vgl. https://www.climateneutraldatacentre.net/). Ein solches Netzwerk setzt sich unmittelbar in Unterstützung des Ansatzes der Medienwelt. Es verlangt, dass der PUE-Wert sowie weitere Instrumente und Richtwerte wie etwa für den Verbrauch vom Wasser zur Kühlung der Rechenzentren (sog. WUE-Wert für /Water Usage Effectiveness/) angepasst bzw. höher gesetzt werden. Sie wirken somit unmittelbar auf die Entschärfung der Satelliseirungsstrategie der Politik, derer Einfluss entsprechend eingeschränkt wird. Aber ein anderes und vielleicht wichtigeres Problem gefährdet diese Strategie: Die Rekonfiguration der Medienwelt um eine Relationalität, die sich in ihrer Entwicklung verändert.

"ICT products are changing their nature from owned goods to services" [cite:@aebischer14:_energ_deman_ict 20]. Weil IKT immer mehr zu Dienstleistungen werden -- ein Trend, der vom /cloud computing/ (2014) und von der KI (2017) beschleunigt wird --, ist es in der Folge immer schwieriger, eine Dienstleistung zu einem genauen Gerät (/device/), einem genauen Markt, einer genauen Gruppen von Firmen zuzuschreiben. Daher können solche Produkte in der Form von Dienstleistungen nicht mehr mit einer genauen Rechenzentrenleistung verbunden werden. Geben wir ein Beispiel. Prozessoren und Mikrokontroller befinden sich längst nicht mehr nur in Rechnern, sondern in vielen alltäglichen Gegenständen (Autos, Kühlschränken, Uhren, Smartphones, Fernsehern, Rundfunkgeräten). Diese Gegenstände verbinden sich nicht nur mit dem Internet, sondern sie bleiben auch tendenziell immer an. Dies kostet nicht nur Strom an der Seite der Endbenutzer. Es verbraucht auch viel Strom an der Seite der Rechenzentren, ohne dass man feststellen kann, wie viel Strom es ist.

Dazu kommt ein weiteres Problem. Die Miniaturisierung von technischen Komponenten der Rechner und Server hängt von der Verwendung vom Silikon ab, und Silikon ist nicht unendlich vorhanden. Es ist vorgesehen, dass die Verwendung vom Silikon für Transistoren auf Mikrochips um 2040 auslaufen sollte (ebd., 2; andere Prognosen setzen die Frist um 2027-2035 [cite:@epoch2022predictinggpuperformance]). Wenn dieser Silikon etwa von 2D Materialien mit einer Breite von drei Atomen nicht ersetzt werden kann, dann können Transistoren und Mikrochips nicht mehr miniaturisiert werden. Die Energie könnte dann nicht mehr gespart werden. Mit der Steigerung der Nachfrage von IKT, die sich als historischer Trend erweist, würde dann der Energieverbrauch automatisch ansteigen. Dies sind Schwierigkeiten, die gut bekannt sind. Weitere Schwierigkeiten bleiben dagegen weniger überschaubar -- wie etwa das Problem der /life cycle/ von IKT Geräten und Komponenten, ihr /recycling/, das Problem des Softwares, das wenn nicht angepasst ebenfalls zu Erhöhung vom Stromverbrauch bei Rechenzentren führen kann. Diese zusätzlichen Schwierigkeiten schwächen noch mehr die Strategie der Politik bei ihrem Versuch, Rechenzentren auf der Grundlagen von einem besseren Energieverbrauch und einer besseren Energieeffizienz zu regulieren. Diese Komplexität der technischen Entwicklung bei steigender Nachfrage von technologischen Medien gekoppelt mit schwachen Regularien geht dagegen in Unterstützung des Ansatzes der Medienwelt, die zudem dem Wunsch der Betreiber von Rechenzentren folgt. Ein letztes Element hält die Einflussstrategie von politischen Instanzen zur Regulierung von Rechenzentren im Schach: Das Szenario "Green IT" setzt sich bei Rechenzentren und im Allgemeinen bei IKT nicht durch.

* Green IT nicht in Sicht

In seinem Bericht von 2012 verzeichnet Borderstep eine sinkende Tendenz beim Energieverbrauch in Rechenzentren ab 2008-2010 in Deutschland. Diese Tendenz würde belegen, dass sich das Szenario "Green IT" durchsetzen könnte [cite:@hintemann14:_rechen_deuts 38-39]. Dies wäre ein wichtiger Beleg dafür, dass trotz ihrer schwierigen Entwicklung die Satellisierungsstrategie der deutschen Politik doch etwas erreichen könnte und an Stabilität gewinnen würde. Aber Borderstep merkt gleichzeitig an, dass sich diese Tendenz auch aus der Finanzkrise von 2008-2009 ergeben könnte, die zum Verkauf von wenigen Servern geführt hat. Würden nach dieser Zeit mehr Server wieder verkauft werden, dann würde "der Energiebedarf der Server- und Rechenzentren voraussichtlich wieder ansteigen" [cite:@hintemann12:_energ_energ_server_rechen_deuts 3]. In den nachfolgenden Jahren bestätigt sich den stetigen Anstieg des Energieverbrauches von Rechenzentren. Es fällt deutlich höher als die ersparte Energie aus, die dank der technischen Entwicklung von Komponenten für Rechenzentren und von der entsprechenden Gebäudetechnik erreicht wurde [cite:@hintemann20:_rechen]. Im Bericht von Murzakulova steigt die prognostizierte Entwicklung vom Energieverbrauch steil [cite:@murzakulova25:_stand_entwic_rechen_deuts 9]. Er hat sich innerhalb von 14 Jahren (2010-2024) verdoppelt, und diese Entwicklung sollte sich bis 2045 auf 80 Mrd. KWh/Jahr (400% mehr als im Jahr 2024; ebd.) durchsetzen. Diese Prognose berücksichtigt die Maßnahmen, die bis heute ergriffen worden sind, um Energie zu sparen -- wie etwa das EnEfG-Gesetz. In Bezug auf die Karbonspur von Rechenzentren stellt der Bericht von Murzakulova eine mögliche sinkende Tendenz bei CO2-Emissionen fest. Aber diese Tendenz setzt voraus, dass der Energiemix erfolgreich durchgesetzt wird bzw. dass die Rechenzentren mit hauptsächlich (idealerweise: nur) erneuerbaren Energien laufen (ebd.). Im Sinne der Machtbalance, die die Politik aufzubauen versucht, setzt dies voraus, dass alle Akteure d. h. Wissenschaftler, Unternehmer und auch die Instanzen der Medienwelt besser miteinander und mit regulatorischen Instanzen der Politik arbeiten. Nur so könnten Rechenzentren klimaneutral werden. Ein Blick auf die /Energy Efficiency Directive/ der Europäischen Kommission (2012 mit Revisionen in den Jahren 2018 und 2023) zu klimaneutralen Rechenzentren dämpft jedoch diese Hoffnung.

Im Juli 2025 veröffentlicht der /Climate Neutral Data Centre Pact/ (CNDCP) einen kritischen Bericht zur /Energy Efficiency Directive/ der Europäischen Kommission, die in Deutschland zum EnEfG geführt hat. Der CNDCP stellt fest, dass das Ziel, klimaneutrale Rechenzentren im Jahr 2030 zu erreichen, sich weit aus der Reichweite befindet [cite:@pact25:_minim_perfor_stand_data_centr]. Die Gründe dafür bestehen zuerst in den Regularien, die von der EU und von der Politik in den Europäischen Ländern formuliert werden. Sie weichen stark von der Praxis im Bereich des Betriebs von Rechenzentren ab [cite:@pact25:_minim_perfor_stand_data_centr 3-4]. Dies betrifft nicht nur die Definition vom  PUE-Wert und WUE-Werte zur Förderung der Energieeffizienz von Rechenzentren. Es betrifft auch die Verwendung von solchen Werten, die nur Rechenzentren betreffen, die mehr als 500 KW verbrauchen. Diese Werte gelten für kleinere Rechenzentren (Rechenzentren, die weniger als 500 KW verbrauchen) nicht. Jedoch sind diese kleineren Rechenzentren diejenige, die am wenigsten energieeffizient sind. Mit der /Directive/ ist es also /de facto/ nicht möglich, die Rechenzentren zu identifizieren, die am wenigsten energieeffizient sind und entsprechend umgebaut werden sollten (ebd., 6). Im Sinne von klimaneutralen Rechenzentren ist es deshalb besonders bedauerlich, weil solche kleinere Rechenzentren die große Mehrheit der Rechenzentren in Europa darstellen. Dies führt dazu, dass die Datenlage zu Rechenzentren, die die EU-Kommission zusammenstellt, um ihre /Directive/ zu verbessern, lückenhaft bzw. von schlechter Qualität ist. Damit wird die /Directive/ nicht nur geschwächt. Auch ihre adäquate Zusammenstellung mit anderen Maßnahmen der EU-Kommission zur Durchsetzung der Energieeffizienz von Rechenzentren in Europa wird erschwert. Aus Sicht der CNDCP wird eindeutig, dass die Machtbalence im Bereich der Rechenzentren, die die Politik mit der Wissenschaft und der Wirtschaft zu konsolidieren versucht, nicht funktioniert.

Für die großen Techkonzernen, die in der Medienwelt tätig sind, ist es ein wichtiges Signal. Ab diesem Moment verstehen sie, dass sie in ihrem Einfluss auf die Gesellschaft nicht ernsthaft gebremst werden können. Entsprechend denken sie daran, eigene Rechenzentren zu entwickeln, dafür "Green IT" nicht wirklich in Frage kommt. Solche Rechenzentren müssen in der Unterstützung der Art von Informationsgesellschaft kommen, die sich diese Techkonzerne vorstellen. Mit dem Durchbruch der KI wird diese Vorstellung von Techkonzernen mit eigenen Rechenzentren konkreter.

* Rechenzentren in der KI-Zeit

Der Bericht /AI-2027/ beschäftigt sich mit Prognosen zur Entwicklung von KI-Technologien in der Gesellschaft [cite:@ai-2027]. KI-Technologien sind Algorithmen zur Herstellung von Sprachmodellen bzw. von Matrizen der Verbindungen zwischen Informationselemente aus Texten, Bildern, Musik usw., die im Internet veröffentlicht werden. Solche Sprachmodelle können von Endbenutzern verwendet werden, um Fragen zu beantworten, Produkte herzustellen und weitere Anliegen und Bedürfnisse zu befriedigen. In Ihrem Bericht geht es für die Autoren darum, diese Entwicklung besser zu verstehen. Deshalb arbeiten sie an der Herstellung von einer Zeitspanne zur Einschätzung der Fortschritte, die in diesem Bereich gemacht werden können, wenn man von den historischen Trends in der Entwicklung von IKT ausgeht. Sie kommen zu dem Schluss, dass in einer nahen Zukunft um das Jahr 2027 (von 2027 bis 2033) KI-Technologien immer genauer arbeiten, weil sie sich selbst immer besser korrigieren. Dies eröffnet den Weg für autonome KI-Technologien, die ohne menschliche Steuerung sondern im Netzwerk funktionieren. Im Laufe der Verbesserung ihrer rechnerischen Operationen gipfeln sie zu einer Superintelligenz, die überall in Geräten und Gegenständen (etwa Robotern) implementiert werden. In diesem Zusammenhang spielen die Rechenzentren eine sehr wichtige Rolle, weil sie solche KI-Technologien empfangen, die auf ihren Servern laufen müssen. Wie wir es oben angemerkt haben, haben auch Geräte und technologische Anwendungen eine wichtige Bedeutung für die Frage vom Energieverbrauch bzw. von der Energieeffizienz von Rechenzentren. In ihrem Versuch, die unterschiedlichen Konsequenzen der Entwicklung von KI-Technologien anzusprechen, haben die Autoren von /AI-2027/ auch diese Frage berücksichtigt. Daraus ergeben sich zwei wichtigen Ergebnisse.

Zwischen den Rechenzentren und Betreibern von Rechenzentren wird eine Grenze immer deutlicher. Einerseits gibt es Akteuren, die in der Wissenschaft und in der Wirtschaft unterwegs sind. Andererseits gibt es Akteure von großen Techkonzernen, die ihr Geschäft mit reinen medialen Dienstleistungen zur Förderung, Kauf und Verkauf von medialen Verhältnissen mittels KI gestützter Geräte und Anwendungen machen (wie etwa Meta, Google, OpenAI, Anthropic). Diese Grenze zeigt sich ganz konkret in Bezug auf Rechenzentren als Verbindung von Techniken und Räumlichkeiten und in Bezug auf ihren Energieverbrauch. Wie Akteure der Politik formulieren Techkonzerne das Problem von Energieverbrauch von Rechenzentren als Umverteilungsproblem. Aber im Unterschied zu den Akteuren der Politik verstehen sie dieses Umverteilungsproblem anders bzw. nach der eigenen Relationalität, wie sie allumfassender wird. Um KI-Technologien weiter entwickeln zu können, braucht man deshalb deutlich mächtigere Server als diejenige, die zur Zeit existieren. Deshalb müssen die vorliegenden Ressourcen in aktuellen Rechenzentren aus diesen Rechenzentren genommen werden und in neue KI-Rechenzentren gebracht werden. Solche KI-Rechenzentren folgen dem Konzept der Hyperscaler. Solche Hyperscaler sind Rechenzentren mit mehr Stromverbrauch, der notwendig ist, um die immer komplexeren Sprachmodellen in akzeptabler Zeit zu trainieren und bessere Sprachmodellen und Algorithmen zu entwickeln. Dies bieten die bestehenden Rechenzentren nicht an. Wenn sie KI-Technologien beherbergen, dann ist es meistens im Sinne der Verbreitung solcher Technologien [cite:@lehdonvirta24:_comput_north]. Wie BITKOM in seinem Bericht von 2024 anmerkt: "Für die Betreiber von Colocation-Rechenzentren besteht hier (...) das Marktrisiko, dass Hyperscaler in Deutschland wie auch in anderen Ländern dazu übergehen, ihre Gebäude selbst zu betreiben" [cite:@bitkom24:_rechen_deuts 60] -- oder anders gesagt: Neue Rechenzentren einer ganz anderen Größenordnung werden von KI-Techkonzernen für ihre Bedürfnisse gebaut. Solche Rechenzentren sprengen den Rahmen von bestehenden Regularien im Bereich des Energieverbrauches bzw. der Energieeffizienz.

Im Bericht /AI-2027/ wird prognostiziert, dass solche KI-Hyperscaler eine Steigerung von ihrem Stromverbrauch von 5GW (Gigawatt) im Jahr 2023 bis auf 62GW im Jahr 2027 erleben werden [cite:@ai-2027 Compute Forecast, Section 1]. In diesem Zusammenhang sind die großen Techkonzerne schon am Start, wie etwa Mark Zuckerberg (Meta/Facebook), der im Juli 2025 den Aufbau von einem solchen Rechenzentrum namens 'Hyperion' zur Training der eigenen KI ankündigt. Ob sich solche KI-Hyperscaler realisieren lassen, bleibt jedoch fraglich, selbst wenn man sich vorstellen könnte, dass Sprachmodelle nicht innerhalb von einem einzigen Rechenzentren trainiert werden würden, sondern auf mehrere Rechenzentren. Solche KI-Hyperscaler brauchen sehr viel Raum (man spricht von hunderten Fußballplätzen), die wie im Fall von anderen Rechenzentren mit speziellen Techniken und Verfahren des Bauwesens sowie Energiequellen ausgerüstet werden müssen, damit die Server verschont werden können und andauernd funktionieren. Abgesehen von den Kosten für die Infrastruktur (wir reden von hunderten Milliarden Dollars für Rechenzentren von 5GW) sind dann die Energiekosten im Sinne vom Gesamtenergieverbrauch und CO2-Emissionen erheblich. Eine Prognose von /Epoch AI/, die die Prognose von /AI-2027/ deutlich relativiert, kommt jedoch zu beeindruckenden Zahlen im Bereich des Energieverbrauches von KI-Hyperscalern [cite:@epri25:_scalin_intel]. /Epoch AI/ sieht eine jährliche Steigerung vom Energieverbrauch der KI-Hyperscalers von 2,2x bis 2,9x in der Zeit von 2025 bis 2030 (ebd., 24) -- dies repräsentiert insgesamt 15% der Energie, die alle Rechenzentren Weltweit verbrauchen (ebd., 19). Im Vergleich zum gesamten Stromverbrauch in den Vereinigten Staaten (1300 GW) sind es 5% von dieser Energie. Im Kontext von unserer Diskussion bedeutet dies, dass sich die großen Techkonzerne nicht nur von aktuell geltenden Regularien im Bereich des Energieverbrauches bzw. der Energieeffizienz von Rechenzentren verabschieden. Sie können auch Druck auf die Politik mit dem Argument ausüben, dass sie im Interesse der ganzen Gesellschaft neue Regularien brauchen, die besagen, dass sie immer mehr Energie verbrauchen dürfen, damit Dienste in der Gesellschaft weiterhin gewährleistet werden. Sie sichern sich somit nicht nur strukturelle, sondern auch relationale Vorteile im Sinne der Expansion ihrer Satellisierungsstrategie mit Einbezug von immer mehr Akteuren in die Machtbalance, die sie zu herstellen beabsichtigen. Im Allgemeinen stärken sie somit ihre Einflussmacht in der Gesellschaft und können die hergestellte Machtbalance besser kontrollieren. Eine solche Vision der Herstellung von Machtbalancen, die solche Konzerne kontrollieren würden, ergibt sich unmittelbar daraus, wie diese Konzerne das Problem vom verantwortlichen Umgang mit natürlichen Ressourcen umformulieren. Mit diesem letzten Punkt schließen wir unseren Beitrag ab.

* Die relationale Macht von Techkonzernen

Die kritische Literatur zu Rechenzentren hat deutlich gemacht, dass Rechenzentren keine ad hoc Strukturen sind, die zufällig in bestimmten Regionen aufgebaut werden. Wie Sackmann für die Lebensläufe unterstreicht, entwickeln sich Rechenzentren auch in sozialen Geflechten eingebettet. Was dabei unterbelichtet bleibt, bezieht sich auf die Vorteil, die sich die Techkonzerne damit sichern wollen, wenn sie solche Rechenzentren aufbauen. Es sind nicht nur strukturelle Vorteile in dem Sinn etwa von einem besseren Zugang zu natürlichen Ressourcen für die Kühlung von Rechenzentrenanlagen. Es sind auch relationale Vorteile, die abgesichert werden sollen [cite:@mirrlees2020getting]. Es sind Vorteile bei dem Einbezug von lokalen Gemeinschaften, von der lokalen Wirtschaft, von der lokalen Politik, die in eine Machtbalance einbezogen werden, die von diesen Konzernen kontrolliert werden.

Solche relationale Vorteile sind für diese Techkonzerne umso wichtiger geworden, als große Rechenzentren immer mehr in die Kritik geraten sind. Sie werden verurteilt, natürliche Ressourcen plündern zu wollen, was zu Protesten gegen großen Techkonzernen mit KI-Rechenzentren und Vorschläge für "anti-datacentres" geführt hat [cite:@pasek2023getting]. Manche davon hervorheben, dass mit dem Klimawandel strategische natürliche Ressourcen wie etwa Trinkwasser unbedingt reglementiert werden muss, damit Rechenzentren keinen Zugang zu solchen Ressourcen erhalten [cite:@hogan2015archive]. Techkonzerne haben solche Proteste wahrgenommen, und in der Zusammenarbeit mit der Wissenschaft Lösungsvorschläge gemacht, die darauf abzielen, ihre Macht zu relationieren, um die erwünschte Machtbalance herstellen zu können. In diesem Zusammenhang ist ein Szenario entstanden, der den Kursor zu verschieben erzielt und das Problem von mächtigen Rechenzentren anders auffasst. Der Ansatz ist hier, dass der Energieverbrauch von Rechenzentren in Relation zum Gesamtverbrauch von Energie in einer Gemeinschaft gebracht werden muss und energetische Subprodukte vom Energieverbrauch der Rechenzentren auf andere Bereiche der Gesellschaft aufgeteilt wird.

Ein erstes Beispiel in diesem Szenario betrifft eine neue Auffassung vom Energiemix zur Energieeffizienz von Rechenzentren am Beispiel vom Trinkwasser für die Kühlung von Rechenzentrenanlagen [cite:@LEI2025108310]. Wenn vieles noch getan werden soll, um den Wasserverbrauch der Rechenzentren adäquat messen zu können -- insbesondere bessere Daten zu erheben, die bis lang fehlen --, kann es vorgeschlagen werden, dass Messinstrumente danach gerichtet werden sollten, den Verbrauch vom Wasser nach dem Workload von Servern zu messen. Dann könnte es genauer ermittelt werden, wie viel Wasser bei steigendem Workload von Servern verwendet werden sollte, um diese Server abzukühlen. Dies würde erlauben, zuverlässige Empfehlungen für die wissenschaftliche Gemeinschaft und die Politik zu formulieren. Damit könnte es vermieden werden, den Verbrauch von Trinkwasser für Rechenzentren zu verbieten und ihn kontrolliert zu gewähren. Zudem wäre es somit auch möglich, Wasser mit anderen erneuerbaren Energien (wie etwa Luft bzw. Wind) zur Kühlung von Rechenzentrenanlagen in einem effizienteren Mix zu verwenden. Damit könnte Trinkwasser weniger belastet werden und insgesamt besser in der Gesellschaft verwaltet werden.

Ein zweites Beispiel betrifft die Nutzung vom energetischen Output des Energieverbrauches von Rechenzentren wie etwa Hitze. Hitze kann nicht nur etwa für die Erwärmung von Büroräumen verwendet werden, sondern auch andere Verwendungsmöglichkeiten von dieser Hitze sind denkbar, wie etwa in der Landwirtschaft, um Lebensmittel zu produzieren [cite:@KARNAMA2019100063]. Diese Hitze könnte durch dichte Röhre zu neben von Rechenzentren aufgebauten Foliengewächshäusern geführt werden, um die Temperaturen in solchen Häusern zu stabilisieren. Dies hätte die Folge, dass Gemüse, Pflanzen und Früchte mit niedrigem Energieverbrauch auch in Regionen kultiviert werden könnten, die nicht dafür vorgesehen waren. Zudem würde es auch erlauben, die Kosten von solchen Kulturen zu senken und am Ende des Produktionsprozesses billigere Waren anzubieten. Eine Untersuchung in Schweden simuliert einen solchen Ansatz, um zu wissen, welche Art von Foliengewächshäusern gebraucht werden würden [cite:@LJUNGQVIST2021119169], wenn etwa in Sub-Arktis Regionen Tomaten geerntet werden sollten. Die Autoren kommen zum Schluss, dass große Foliengewächshäuser (etwa 10.000 Quadratmeter) würden billigere Tomaten im Vergleich zu kleineren Foliengewächshäusern (etwa 2.000 Quadratmeter) produzieren. Weil sie größer sind, generieren sie insgesamt weniger Kosten als kleinere Foliengewächshäuser; der Verbrauch der Hitze von Rechenzentren trägt dazu bei, diese Kosten noch mehr sinken zu lassen. Die Produktion von kleineren Foliengewächshäuser wäre jedoch nachhaltiger, weil sie wegen ihrer Größe die Hitze von Rechenzentren effizienter einsetzen könnten. Diese Hitze könnte etwa auch gebraucht werden, wenn diese Rechenzentren weniger Hitze produzieren würden (wie im Winter). Dies ist nicht der Fall von großeren Foliengewächshäusern, die aufgrund ihrer Größe die Hitzedefizite der Rechenzentren mit anderen Wärmeanlagen kompensieren sollte.

Diese zwei Beispiele zeigen eindeutig, wie Techkonzerne ihre KI-Rechenzentren relationieren, was für diese Techkonzerne nicht nur einen Grund mehr gibt, die Notwendigkeit von mächtigen Rechenzentren in der Gesellschaft unabdingbar zu machen. Es bringt Ihnen auch einen entscheidenden relationalen Vorteil im Sinne einer Verstärkung ihrer Einflussmacht in der Gesellschaft und der stärkeren Kontrolle der Machtbalance, die sie entlang ihrer Satellisierungstrategien aufzubauen versuchen. Nach einer Zeit, in der die Satellisierungstrategien, die die Politik mit der Wissenschaft und der Wirtschaft innerhalb und außerhalb Europa zu entwickeln beabsichtigte, schrumpft, folgt einer Zeit der neuen Satellisierung von Gesellschaft durch Techkonzerne und der Einbettung von (Kollektiv)Akteuren dieser Gesellschaft in einer Machtbalance, die von der Relationalität strukturiert wird, die diese Techkonzerne in Zusammenhang der wachsenden Entwicklung von KI-Vorhaben verbreiten.

* Schlussbetrachtung

In unserem Beitrag haben wir versucht, Sackmanns Interpretation vom figuarationssoziologischen Ansatz Norbert Elias' mit der Theorie der Relation zu erweitern. Dabei haben wir zwei Begriffe aus diesem Theorierahmen übernommen und verwendet: Den Begriff der Relationsstruktur und den Begriff der Satellisierung. Diese Begriffe setzen die Annahme der Interdependenz aus, die im Kern Elias' Figurationsbegriff steckt. Für die Rekonstruktion vom Einflussmacht der (Kollektiv)Akteure in ihren jeweiligen Relationsstrukturen und die sich daraus ergebende Satellisierungsstrategie ist dies vorteilhaft. Eine solche Einflussmacht kann somit auf der Grundlage von einem relationalen Verständnis der Macht verstanden werden bzw. auf der Basis der Relationierung von Macht, die in der Untersuchung vom Allianzenaufbau mit (Kollektiv)Akteuren in anderen Relationsstrukturen erklärt werden kann. Daraus ergibt sich die Möglichkeit, Machtbalancen dynamisch in ihrer mehr oder weniger festen Zusammenstellungen zu evaluieren, sie mit der Stärkung oder Schwächung von anderen Machtbalancen in der Gesellschaft zu vergleichen und mit entsprechenden Satellisierungsversuchen von (Kollektiv)Akteuren anderer Relationsstrukturen zu relationieren. Damit erfolgt eine Beschreibung von relationalen Vorteilen, die sich aus der Durchsetzung von Relationsstrukturen mittels ihrer Satellisierung ergeben. Weiter führt die Untersuchung vom Umgang mit solchen relationalen Vorteilen zur Beschreibung ihrer Wirkung auf die gesellschaftliche Struktur, wie sie dort greifen und was sie dort bewirken.

Am Beispiel der Frage nach dem Energieverbrauch und der Energieeffizienz von Rechenzentren, wie sie in Deutschland besprochen werden und darüber hinaus in Europa und weltweit entwickelt werden, haben wir diesen Ansatz umgesetzt. Dabei ist es deutlich geworden, dass die Frage des Energieverbrauches und der Energieeffizienz von Rechenzentren in den letzten zwei Dekaden an Relevanz gewonnen und Debatten hervorgerufen hat. Sie stellt sich zwischen dem Wunsch, diese Energie von Rechenzentren besser regulieren zu wollen, und der unvermeidlichen Feststellung, dass Rechenzentren immer wichtiger für die Gesellschaften werden, die entscheidend den Weg ihrer Digitalisierung beschreiten und auf mehr und mächtigere Rechenzentren angewiesen sind. Am Beispiel der Debatten im deutschen Bundestag zum Thema Rechenzentren haben wir gezeigt, dass die deutsche Politik trotz ihrer Allianzen mit Instanzen der Wissenschaft und der Wirtschaft immer mehr in Schwierigkeiten bei der Formulierung von Regularien geraten ist, um die Frage vom Energieverbrauch und der Energieeffizienz von Rechenzentren zu adressieren. Diese Schwierigkeiten spielen in die Karten von Betreibern der Rechenzentren. Mit dem Durchbruch der KI und dem Vorrücken von großen Techkonzernen sind sie immer mehr in der Lage, ihre Vorstellung von mehr und mächtigeren Rechenzentren in der Gesellschaft zu verbreiten und Expertise aus der Wissenschaft und der Wirtschaft in der Unterstützung dieser Vorstellung zu bringen. Dabei relativieren sie die Argumente zum Energieverbrauch und zur Energieeffizienz von Rechenzentren und formulieren sie um: Mehr und mächtigeren Rechenzentren fördern die bessere Energieverwaltung in der Gesellschaft.

Ob eine solche Satellisierungsstrategie von Techkonzernen ausreicht, um ihre Macht so zu relationieren, dass weitere Satellisierungsversuche von anderen (Kollektiv)Akteuren ab ihrer Ausgangspunkt geschwächt werden, bleibt ungewiss. Sicher ist jedoch, dass die Relationalität, die Techkonzerne unterstützen und die Medienwelt verbreitet, den Vorteil hat, dass sie durch KI-Geräte und Dienstleistungen unterstützt wird. Deshalb kann sie bedeutsam expandieren, ohne Arbeit und Zeit im Aufbau von Allianzen mit weiteren entsprechenden (Kollektiv)Akteuren investieren zu müssen. Es bleibt fraglich, ob sich dieses Modell der Einflussmacht durch die Vermehrung von Technologien, die in der Lage sind, die Relationierung der Macht automatisch über digital mediatisierte Verhältnisse vorzunehmen, tatsächlich durchsetzt. Von dieser Frage hängt nicht nur die Zukunft vom Energieverbrauch und von der Energieeffizienz der Rechenzentren ab. Aufgrund ihrer künftigen wachsenden Rolle in der Gesellschaft in der Koppelung mit neueren Innovationen wie Quantenrechnern, Bio- und DNA-Computing hinterfragen Rechenzentren die gerechte Verteilung von Energieressourcen in der Gesellschaft.

* Literatur

#+cite_export: csl /home/cpsoz/OrgCSL/apa.csl
#+print_bibliography:
