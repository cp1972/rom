#+Setupfile: /home/cpsoz/OrgTemplates/odt-de.org
#+Title: Rechenzentren in Machtbalancen. Ein Erweiterungsvorschlag.
#+Bibliography: /home/cpsoz/Github/rom/CP-ROM.bib

* Einleitung

Im Oeuvre Reinhold Sackmanns hat uns ein Ansatz besonders interessiert, den er im Rahmen seiner unterschiedlichen Arbeiten zur Demographie, zur Lebenslaufsoziologie und zu gesellschaftlichen Instanzen der Sozialisation wie den (Hoch)Schulen, dem Arbeitsmarkt oder dem Rentensystem entwickelt hat. Dieser Ansatz finden wir in seinen Arbeiten unterschiedlich ausgedruckt. Nehmen wir etwa die Schlussfolgerungen seiner Habilitationsschrift, wenn er eine Bilanz zur Lebenslaufsoziologie wie folgt zieht: "An den Anfängen dieser Disziplin (...) stand die Vorstellung, daß Alter neben seiner biologischen Komponente auch gesellschaftlich kulturelle Elemente enthält. Gesellschaft war ein Nebenfaktor, der wahrgenommen werden sollte. In der Theorie des institutionalisierten Lebenslaufs gewann die Vorstellung Kontur, daß die modernen gesellschaftlichen Institutionen (...) spezifische Lebensläufe konstituieren" [cite:@sackmann98:_konkur_gener_arbeit 228-229]. Dabei legt Sackmann nah, dass sich die künftige Forschung in der Lebenslaufsoziologie mit der Art und Weise auseinandersetzen sollte, wie Lebensläufe als eingebettete Prozesse an der Schnittstelle der Biographien von Akteuren und der formalen Operationen von gesellschaftlichen Instanzen entstehen und von einer solchen Einbettung strukturiert werden. "Lebensläufe", wie er in einem späteren Beitrag sagt, "vollziehen sich eingebettet, in Gruppen, in Gemeinschaften, Gesellschaften und v.a. Organisationen" [cite:@sackmann07:_leben_biogr 206]. Dieser Ansatz ist aus den folgenden Gründen interessant.

Sackmann versteht Lebensläufe nicht mehr im geläufigen soziologischen Sinn von "trajectoires", die den Fokus auf den Weg der Akteure von gesellschaftlichen Instanzen der Sozialisation zu weiteren gesellschaftlichen Instanzen der Sozialisation setzen. Damit wird gesagt, das gesellschaftliche Sozialisationsinstanzen wie etwa (Hoch)Schulen oder Arbeitsmarkt mehr als nur "verpflichtende Anlaufstationen" von Akteuren sind [cite:@latour05:_reass_social], die Akteure registrieren würden und sie je nach Sozialisationserfolg unterschiedlich auf weitere gesellschaftliche Bahnen umverteilen würden. Gesellschaftliche Instanzen sind keine irreflexive Orte der Vergebung von Titeln und Rechten, sondern sie geben den Akteuren Einschreibungsmöglichkeiten in der Gesellschaft und reflektieren entsprechend über ihre Rolle in diesem Zusammenhang. Auch zu diesem Zweck entwickeln gesellschaftliche Instanzen dauernd formale Verfahren, die Orientierungsmuster bzw. "Leitbilder" für die Akteure schaffen und deshalb auf ihre Laufbahnen wirken [cite:@sackmann07:_leben_biogr 206]. Dass eine solche Wirkung auch unintendierte Folgen hat und Ungleichheiten zwischen Akteuren bzw. Akteurgenerationen generiert, hat Sackmann mehrmals im Sinne einer kritischen soziologischen Betrachtung von gesellschaftlichen Instanzen unterstrichen [cite: vgl. etwa @sackmann15:_bedeut_auswah_erzeug_bildun; vgl. auch @sackmann19:_mechan_eliteb]. Aber eine kritische Betrachtung von gesellschaftlichen Instanzen reicht nicht allein aus. Nach Sackmann müssen ebenfalls Korrekturmaßnahmen von gesellschaftlichen Instanzen abgebildet werden, die darauf abzielen, Maßnahmen und entsprechende formale Verfahren zur Einschränkungen bzw. Schrumpfung der Ungleichheitsproduktion zu definieren.

Mit diesem konstruktiven Korrelat zur kritischen Betrachtung von gesellschaftlichen Instanzen rundet Sackmann seinen Ansatz ab: Weil Kollektivakteure als Teil des Einschreibungskontextes fungieren, den sie mit den Akteuren aufbauen und innerhalb dessen die Laufbahn von solchen Akteuren strukturiert wird, ist es aus Sicht einer soziologischen Makroperspektive nicht ausreichend, nur die Defizite von Kollektivakteuren in ihren Wechselwirkungen mit Einzelakteuren hervorzuheben. Es muss ebenfalls verstanden werden, wie gesellschaftliche Instanzen an ihren formalen Operationen arbeiten, um sie nicht nur im Sinne der Stärkung der eigenen Position in der Gesellschaft zu verbessern, sondern auch im Sinne der Förderung des Lebenslaufs ihrer Adressaten bzw. der Zuverlässigkeit von (positiven wie negativen) Sanktionsoperationen an der Wurzel der (Um)Verteilung von Akteuren auf gesellschaftliche Tätigkeiten, entsprechende Bereiche und dort aktive Instanzen. Aus einem solchen Ansatz ziehen wir zwei wichtigen Botschaften.

Die erste Botschaft betrifft den gesellschaftlichen Zusammenhalt. Der gesellschaftliche Zusammenhalt ist eine Dynamik [cite:@sackmann98:_konkur_gener_arbeit 82], die eine eigene Elastizität je nachdem hat, wie gut oder weniger gut die Lebensläufe durch die Einbettung von Akteuren und gesellschaftlichen Instanzen strukturiert werden. In seinem Ansatz denkt Sackmann eine solche Dynamik mit dem Begriff der Figuration von Norbert Elias, von dem er insbesondere die Interdependenz der protagonistischen und antagonistischen Akteuren in Figurationen sowie die entsprechenden Machtbalancen hervorhebt (ebd., bes. 73ff.). Figurationen sind keine Zustände, sondern Zusammenstellungen von Einzel- wie Kollektiveakteuren und Nicht-Akteuren, die sich in Zeit und Raum mehr oder weniger verbreiten oder schrumpfen. Die zweite Botschaft betrifft diese Verbreitung bzw. Schrumpfung. Im Rahmen von Figurationen denkt sie Elias als von Machtbalancen innerhalb von Figuration sowie von den Machtbalancen zwischen Figurationen abhängig. Dies bedeutet, dass (Kollektiv)Akteure in Figurationen "nicht gleich stark" sind (ebd. 75), weshalb auch Asymmetrien entstehen, die jedoch keine radikalen Asymmetrien im Sinne der Monopolisierung von Macht bilden: "selten gelingt es einer Konfliktpartei, die andere vollkommen zu entmachten" (ebd.). Die Macht wird in Figurationen eng mit der Interdependenz von den unterschiedlichen (Kollektiv)Akteuren verbunden und somit dynamisiert, was im Begriff "Balance" wiedergegeben wird. Die Macht ist im Wechselspiel der (Kollektiv)Akteure eingebettet, und sie wird im Laufe der Strukturierung der Lebensläufe von Einzelakteuren und der Position von gesellschaftlichen Instanzen mitstrukturiert. Einmal figurationssoziologisch aufgefasst, sehen Lebensläufe von Einzelakteuren und Generationen von Akteuren nicht mehr wie individuelle Mikrophänomenen "neben" der Gesellschaft (als Makrophänomen) aus. Eine solche Unterscheidung kann zugunsten von einem prozeduralen Verständnis von Figurationen als Einbettungs- bzw. Einschreibungskontexten unterschiedlicher gesellschaftlicher Dimensionen eingesetzt werden. Damit stellt sich die folgende analytische Frage: Was haben wir für Figurationen in unserer Gesellschaft, und welche Folgen haben sie für die Handlung in dieser Gesellschaft und schließlich für diese Gesellschaft selbst?

Eine solche Frage teilen wir im Rahmen der Theorie der Relation, die Relation nach einem Makroansatz definiert und entwickelt [cite:@papilloud22:_skizz_theor_relat]. Verglichen mit dem figurationssoziologischen Ansatz Sackmanns geht es in diesem Theorierahmen darum, die Einbettungszusammenhänge radikaler als Relationsstrukturen zu konzipieren. Sie stellen Ordnungen von Verhältnissen mit (Kollektiv)Akteuren, Nicht-Akteuren und Medien dar, die sich nach einer spezifischen Dynamik entwickeln bzw. die verbreitet oder geschrumpft werden. Wichtig dabei bleibt der Ansatz, den wir im Rahmen Sackmanns Deutung der Figuration Elias' zusammengefasst haben: Relationsstrukturen stellen stratifizierte Einbettungs- bzw. Einschreibungskontexte von gesellschaftlichen Phänomenen, Akteuren und Kollektiven in der Form von Verhältnissen dar, die nach einer spezifischen Dynamik der Balance von all möglichen Verhältnissen strukturiert werden, was wiederum eine solche Dynamik strukturiert bzw. verbreitet, be- oder entschleunigt, schrumpfen lässt oder korrigiert. In einem solchen Rahmen bewegt sich die nachfolgende einführende Untersuchung vom Kollektivakteur "Rechenzentrum", mit der wir einen Beitrag zur Frage leisten wollen, welche Machtbalance Rechenzentren in unserer Gesellschaft in den Vordergrund bringen und welche Folgen entstehen daraus für weitere Ordnungen von Verhältnissen. Als erster Schritt in dieser Untersuchung wollen wir verstehen, was Rechenzentren für eine Art von gesellschaftlichen Instanzen sind.

* Rechenzentren als eine Art gesellschaftlicher Instanzen

Ein erstes Problem, das die Theorie der Relation lösen will, betrifft die Diskrepanz zwischen dem Realen und dem Formalen bei der Verortung von Instanzen der Gesellschaft bzw. bei der Beschreibung der Position von gesellschaftlichen Instanzen in Ordnungen von Verhältnissen. Real können Instanzen und Instanzfraktionen in unterschiedlichen Orten der Gesellschaft gefunden werden. Nehmen wir das Beispiel der Forschung: Sie kann als akademische Forschung im Rahmen von Hochschulen oder von Forschungszentren stattfinden, aber sie kann auch in Abteilungen von Industrien oder Firmen sowie auch im Rahmen der Politikberatung oder des Journalismus praktisiert werden. Formal setzt Forschung jedoch vergleichbare Rahmenbedingungen in Bezug auf die Mittel sowie auf die Zwecken der Forschung voraus: Einen Zugang zu einer zuverlässigen Information, die durch Einbezug von weiteren Akteuren, Kollektiven, Nicht-Akteuren und Medien kontrolliert und vertieft werden kann und eine mehr oder weniger breite Öffentlichkeit erreichen muss. Forschung kann folglich überall in der Gesellschaft auftauchen, aber nicht überall in dieser Gesellschaft ist Forschung gleich Forschung. Diese Diskrepanz zwischen dem Realen und dem Formalen löst die Theorie der Relation mit der Berücksichtigung von unterschiedlichen Ordnungen von Verhältnissen, die eine entsprechende Forschungspraxis bevorzugen. Forschung ist dann nicht gleich Forschung, sondern es hängt davon ab, welche Ordnung von Verhältnissen Forschung einerseits strukturiert und Forschung andererseits unterstützt. Damit wird verstanden, dass die Forschung an Universitäten im Vergleich etwa zur Forschung in Firmen nicht besser/schlechter, wichtiger/weniger wichtig, schneller/langsamer, stärker/schwächer bzw. nicht kategoriell unterschiedlich wäre, sondern Verhältnisse zwischen Akteuren, Instanzen, Nicht-Akteuren und Medien in der Forschung anders gestaltet bzw. eine andere Relationalität oder relationale Dynamik zwischen ihnen entwickelt. Daraus ergibt sich, dass die relationale Dynamik einer Ordnung von Verhältnissen als Leitbild für die Entwicklung der gesellschaftlichen Zirkulation von Akteuren und die Positionierung bzw. Verortung von gesellschaftlichen Instanzen funktioniert und ihre Handlung entsprechend beeinflusst. Diese Überlegung kann gleichermaßen zwischen Ordnungen von Verhältnissen bzw. Relationsstrukturen entwickelt werden. Eine Ordnung von Verhältnissen versucht stets, die anderen Ordnungen von Verhältnissen über ihre eigenen Instanzen nach ihrer eigenen Dynamik zu beeinflussen, um sich auf die anderen Ordnungen von Verhältnissen so zu verbreiten, als ob diese anderen Ordnungen von Verhältnissen Merkmale ihrer Dynamik wären. Diese Einflussstrategie nennt die Theorie der Relation eine Satellisierung von Ordnungen von Verhältnissen durch die anderen Ordnungen von Verhältnissen.

Aus unserem Beispiel zur Forschung kann zuerst schlussfolgert werden, dass Rechenzentren nicht zwangsläufig in einem bestimmten Bereich der Gesellschaft angesiedelt sind, oder in den Begriffen der Theorie der Relation, dass sie sich nicht nur in einer Einzelordnung von Verhältnissen befinden. Dies bedeutet jedoch nicht, dass Rechenzentren vergleichbare Rahmenbedingungen nicht teilen würden, selbst wenn sie verstreut in den Bereichen der Gesellschaft implementiert werden und solche Rahmenbedingungen entsprechend unterschiedlich unterstützen und zusammenstellen. Wenn wir davon ausgehen, dass sehr gute Beispiele dessen, was Rahmenbedingungen von Rechenzentren sind, in der Medienwelt vorliegen, dann kann die Theorie der Relation mit ihrer Problematisierung der Instanzen einer medialen Relationsstruktur bzw. einer Ordnung von Verhältnissen, die maßgeblich durch die Verwendung von analogen und digitalen Medien strukturiert wird, herangezogen werden, um diese Rahmenbedingungen besser zu veranschaulichen. Nach dem Ansatz der Theorie der Relation sind Instanzen der medialen Relationsstruktur diejenige, die an der Optimierung der Attraktivität von Medien in allen Formen von Verhältnissen und deshalb an der Optimierung von solchen medialen Verhältnissen arbeiten. Diese Arbeit setzt eine Beschäftigung mit den materiellen Bedingungen von solchen medialen Verhältnissen voraus, um die Investition in solche Verhältnisse zu vermehren und die Mobilisierung von solchen Verhältnissen in der Gesellschaft zu intensivieren. So kann die Repräsentation von solchen medialen Verhältnissen und deren entsprechenden Medien in der Gesellschaft gestärkt und verbreitet werden sowie andere Verhältnisse nach diesem Muster strukturieren.

Die erste -- materielle -- Bedingung zur Verortung von Rechenzentren ist in der soziologischen bzw. sozialwissenschaftlichen Literatur zu Rechenzentren gut abgebildet, die die Rechenzentren bevorzugt als -- in unseren Worten -- Instanzen einer medialen Relationsstruktur versteht. In diesem Zusammenhang wird gesagt, dass die abstrakte bzw. virtuelle Welt der Informationsgesellschaft viele konkrete Elemente voraussetzt, ohne die sie gar nicht existieren könnte [cite:vgl. etwa @blanchette11:_mater_histor_bits;@mattern13:_code_clay_data_dirt;@parks15:_signal_traff;@starosielski15:_under_networ]. Diese Informationsgesellschaft verbraucht immer mehr Medien als materielle Bedingungen der Entwicklung von immer mehr/besseren/umfangreicheren medialen Verhältnissen. Nach diesem Ansatz versteht diese Literatur die materielle Bedingung von Rechenzentren in Bezug auf die Selbstverständlichkeit der Vervielfältigung von Medien in Unterstützung der vielfältigen medialen Verhältnissen der Informationsgesellschaft. Dieser Ansatz, der erst seit der letzten Dekade in den Sozialwissenschaften aufgegriffen wird, unterscheidet sich von einem anderen Ansatz, der die materiellen Bedingungen von Rechenzentren ebenfalls berücksichtigt sie jedoch anders problematisiert. Er taucht in einer Fülle von Beiträgen aus der Literatur in den Bereichen der Technikwissenschaften (Ingenieurwissenschaft, Informatik, Physik) auf, die sich speziell mit Rechenzentren als Zusammenstellung von unterschiedlichen wissenschaftlichen Verfahren und Techniken auseinandersetzen. In dieser Literatur werden Rechenzentren nicht bevorzugt als Instanzen einer medialen Relationsstruktur verstanden, sondern vor allem als Instanzen der Wissenschaft im Rahmen der entsprechenden Relationsstruktur. Rechenzentren werden hier als Ort der Optimierung von Materien zum Vorteil der Miniaturisierung von Techniken zur Stärkung der Investition in wissenschaftlichen Vorhaben wahrgenommen (bessere rechnerischen Kapazitäten von Rechenzentren, die weniger Raum brauchen und schneller funktionieren usw.). In dieser Hinsicht stellen Rechenzentren eine Möglichkeit dar, mit weniger Materie mehr wissenschaftliche Leistung zu generieren.

In vergangenen Arbeiten haben wir Untersuchungen zu diesem letzten Ansatz vorgelegt, der sich nach dem Zweiten Weltkrieg mit der Entstehung von interaktiven Medien und der Entwicklung von Nanotechnologien in Verbindung mit unterschiedlichen Branchen der Wirtschaft (Kommunikationstechnologien, Lebensmittel, Verpackung) und Disziplinen der Wissenschaft (Chemie, Physik, Medizin und Pharmazie) unermüdlich weiter entwickelt. [cite:@monoPapilloud2007;@monoPapilloud2012;@kapitelPapilloud2013;@monoPapilloudSchultze2023]. Insbesondere im Zusammenhang der Nanotechnologien konnten wir feststellen, dass ein solcher Ansatz der Umverteilung von Räumlichkeiten (was da draußen als Raum beobachtet werden kann, wird dank der Eroberung von Räumlichkeiten innerhalb von Materien erspart) das Problem des Energieverbrauchs von Materialien lösen will. Oder anders gesagt: Die Umverteilung von Räumlichkeiten bringt eine Umverteilung von Energieressourcen. Wenn mehr Raum innerhalb von Materien für Technologien geschafft werden kann, dann können Technologien vermehrt werden, ohne mehr Räumlichkeiten in der Welt zu beanspruchen und ohne entsprechende zusätzliche Energieressourcen zu verlangen. Mehr (Technologien) führt zu weniger (Raum- und Energieverbrauch), was sich als eine Art negativer dialektischen Formulierung vom Mythos der Abundanz ergibt.

Dieser spezielle Ansatz zur Umverteilung von Energieressourcen wird in der wissenschaftlich-technischen Literatur zu Rechenzentren bedeutsamer, wenn es deutlich wird, dass Rechenzentren zum Kern von den Informations- und Kommunikationstechnologien (IKT) und damit von der Informationsgesellschaft fungieren. Gleichzeitig wirft er immer mehr Fragen nach seiner praktischen Umsetzung auf, die zuerst die Wissenschaft und dann zunehmend die Politik beschäftigen.

* Rechenzentren als Kern der Informationsgesellschaft

Dass Rechenzentren zum Kern der Informationsgesellschaft werden, heben die Arbeiten von Bernard Aebischer (ETH-Zürich) im Rahmen des /Centre for Energy Policy and Economics/ gut hervor. Aebischer arbeitet nicht speziell zu Rechenzentren, sondern er untersucht das breite Spektrum der IKT in historischer und transnationaler Perspektive mit einem Modellierungsansatz. Er schlägt eine Periodisierung der Entwicklung von IKT und eine Zeitspanne vor, ab der Rechenzentren immer mehr an Bedeutung für die Informationsgesellschaft gewinnen. Dieser Gewinn an Bedeutung beginnt mit der Suche nach Maßnahmen zur Einsparung von Energie nach den zwei Ölkrisen von 1973 und 1979 [cite:@aebischer14:_energ_deman_ict 6]. Strom wird überall teurer, deshalb wollen die Länder wissen, wie sie Strom sparen können. Alles, was Strom verbraucht, wird berücksichtigt, wie die Rechner, die im Lauf der 80er Jahre in der Form von /Personal Computer/ vermehrt in der Wirtschaft und in der Wissenschaft verwendet werden (ebd., 4). Die ersten Studien zum Stromverbrauch von Rechnern arbeiten mit einem Technologieansatz, der vom Moores Gesetz beeinflusst wird, nach dem die Anzahl an Transistoren in integrierten Schaltkreisen jede zwei Jahre verdoppelt wird (ebd.). Sie kommen zu vergleichbaren Ergebnissen. Die Vermehrung von Rechnern lassen den Energieverbrauch in der Gesellschaft steigen. Aber dank der technologischen Entwicklung soll er schnell wieder senken. Simulationen und Szenarien, die von 1980 bis 1990 für eine Zeitspanne von bis 40 Jahren gebildet werden (1985-2025), kommen zum Schluss, dass es gut möglich sei, dass in 2025 Rechner insgesamt nicht mehr Energie als im Jahr 1985 verbrauchen würden (etwa am Beispiel der Schweiz, ebd.). Dabei werden auch sog. /mainframes/ bzw. existierende Rechenzentren berücksichtigt, selbst wenn sie noch keine spezielle Hervorhebungen bekommen. Wie Aebischer unterstreicht, werden Rechenzentren in Gesellschaften vor dem Internet nicht wirklich mit der Vorstellung von einer Informationsgesellschaft verbunden. Häufig außerhalb von Großstädten in billigen Lagergebäuden angesiedelt, unterstützen solche Rechenzentren maßgeblich die rechnerischen Tätigkeiten in der Wissenschaft und in der Wirtschaft [cite:@carnino19:_du 168]. Sie bieten lediglich eine Automatisierung und eine Beschleunigung von einigen Verfahren an, die davor von Menschen mit Aufwand und nicht immer fehlerfrei durchgeführt wurden. Wie Aebischer in Bezug auf die Frage des Energieverbrauchs von solchen Rechenzentren sagt: "the financial sector, research institutions and universities, a few industries and some governmental agencies were the only important users of large computers. Electricity demand of these machines was a concern for these organizations but was barely registered by policy makers or the general public" (ebd., 11). Um genauer zu wissen, was Aebischer mit "barely registered by policy makers" meint, können wir das Beispiel Deutschland erwähnen. Dieses Beispiel bietet den zusätzlichen Vorteil an, dass wir damit auf einen methodologischen Ansatz bei Sackmann zurückgreifen, der eine Integration von qualitativer und quantitativer Forschung auf der Grundlage von Topic-Modellen vorsieht, daran Sackmann u.a. auch mit unserer Anwendung /MTA/ arbeitet [cite:@sackmann20:_sozial_zusam_pandem;@papilloud17:_mta_multi_text_analy].

In der Zwischenzeit ist diese Methode in den Sozialwissenschaften rezipiert worden, weshalb wir sie hier nicht nochmal darstellen [cite:vlg. stattdessen @papilloud18:_einfü_analy_texten_topic_model]. Den methodologischen Zusammenhang wollen wir dennoch kurz präzisieren, in dem wir die folgende Topic-Modellierung verwendet haben, weil er in unserem Fach unterbelichtet bleibt. Wir haben diese Modellierung im Rahmen von /workflows/ hergestellt, die dem Ansatz vom /literate programming/ folgen, nach dem Anwendungen so geschrieben werden, damit sie jeder Mensch versteht. In der Praxis bedeutet dies, dass ein Text (ein Bericht, ein Aufsatz, ein Buchkapitel usw.) geschrieben wird, der die methodologischen bzw. technischen Elementen enthält (wie etwa den Code/den Skript für die Ausführung von Anwendung zur Herstellung von Statistiken, Tabellen, Graphiken usw.), die im Rahmen von diesem Text verwendet werden. Ein solcher Text bzw. eine solche Textdatei kann anschließend nicht nur als Bericht/Aufsatz, sondern auch als Anwendung benutzt werden. Sie kann ausgeführt werden, und dabei führt sie weitere Anwendungen aus, die für die Ausführung des Codes in der Datei notwendig sind. Damit wird eine vollständige Transparenz und Reproduzierbarkeit der unterschiedlichen Stufen erzielt, die zu einem Ergebnis geführt haben, das der Text veröffentlicht. Im Rahmen von solchen /workflows/ harmonieren qualitative sowie quantitative Daten im Dienst der wissenschaftlichen Untersuchung, dass eine Textdatei repräsentiert und aufgrund ihres Formates als Textdatei überall entweder als reine Textdatei oder als Anwendung verwendbar ist (die /worflows/, die im Rahmen dieses Vorhaben verwendet wurden, befinden sich an der folgenden Adresse: https://github.com/cp1972/rom.git).

In dem Kontext dieses Vorhabens haben wir als Grundlage der Untersuchung zur Frage der Aufmerksamkeit von Politik in Deutschland auf die Fragen, die Rechenzentren stellen, die Parlamentsdokumente der Bundesrepublik Deutschland und die Protokollen des Bundestages herangezogen. Diese Dokumente können auf die folgende Adresse als XML-Dateien, mit einer API oder nach handwerklicher Suche heruntergeladen werden: https://www.bundestag.de/services/opendata. Ein Github-Konto bietet diesen Datensatz als R-Objekt an: https://github.com/benjaminguinaudeau/tidybundestag. Inhaltlich liefern diese Dokumente unterschiedliche Informationen zu den politischen Entscheidungen, die von 1949 bis heute auf Bundesebene getroffen werden. Bezogen auf unser Vorhaben erlauben sie eine Rekonstruktion der thematischen Zusammenhänge, in denen die Rechenzentren in Deutschland von der Politik wahrgenommen wurden. Wir haben uns auf die XML-Dateien bezogen, die wir in Textdateien umgewandelt haben. Wir haben diese Dateien mit den letzten Parlamentsdokumenten und Protokollen (bis Juni 2025) vervollständigt. Anschließend haben wir die Dokumente nach Wahlperioden klassifiziert, selektiert und nach Datum, Sprecher, politischer Partei vom Sprecher und politischem Status des Sprechers (etwa Ministerpräsidenten) zerlegt. Bei der Selektion sind wir zuerst mit einem breiten Ansatz vorgegangen, nach dem wenn das Wort "Rechenzentr" zumindest einmal in einem ganzen Dokument erscheint dieses Dokument in die Analyse einfließt. Weil wir mit diesem Ansatz sehr viele Dokumente generiert haben, die mit dem Thema "Rechenzentrum" lose verbunden waren, haben wir den Ansatz enger gefasst und nur die Teile von Dokumenten bzw. die einzelnen Wortmeldungen von Sprechern ausgewählt, die sich unmittelbar mit dem Thema "Rechenzentrum" beschäftigt haben. Mit diesem letzten Ansatz konnten wir eine verdichtete Abbildung der Themen zum Oberthema "Rechenzentrum" im Bundestag in der Zeit erhalten (vgl. Abbildung 1).

#+Caption: Entwicklung der Themen zu "Rechenzentrum" in den Debatten des deutschen Bundestages
#+ATTR_ODT: :width 15 :height 15
[[./Trends7T.png]]

Die Abbildung 1 zeigt einerseits, dass die Debatten im Bundestag das Thema "Rechenzentrum" aus verschiedenen Perspektiven behandeln, die in der Zeit unterschiedlich bedeutsam sind. In Bezug auf die Aussage von Aebischer kann gesagt werden, dass die Politik in Deutschland auf Rechenzentren schon aufmerksam war. Aber wenn wir das Thema Energie fokussieren, sieht man dann, dass es nur im Themenkomplex Energie, Wirtschaft, Optimierung, Nachhaltigkeit behandelt wird und nur zwischen 1995 und 2000 ein Leitthema der Debatten zu Rechenzentren im Bundestag gewesen ist. Davor steckt dieses Themenkomplex hinter dem Thema des Datenschutzes, und danach verliert es an Bedeutung im Vergleich zu den Themen der Forschung, der Wissenschaft und der Bildung sowie der Apotheken und der Medizin (in diesem Zusammenhang insbesondere in Bezug auf die Verbesserung der automatischen Herstellung von Rechnungen und der entsprechenden Zahlung dieser Rechnungen). Am Ende der Zeitspanne herrschen insbesondere die Themen der Bundesverteidigung und der Forschung und Bildung in Bezug auf die Veränderung der internationalen Lage (Krieg zwischen Russland und der Ukraine, Covid-19 und Entwicklung der Fernarbeit, Einsatz des Blockchains zur Verschlüsselung von Transaktionen und Kommunikationen, Durchbruch der künstlichen Intelligenz).

Wenn wir zurück auf das Themenkomplex Energie, Wirtschaft, Optimierung, Nachhaltigkeit in den Jahren 1995-2000 schauen, dann sehen wir nur eine Erwähnung der Energie im Rahmen von Rechenzentren in Bezug auf den FCKW-Halon-Verbot, die Frau Monika Ganseforth (SPD) am 16.03.1995 anspricht. Frau Ganseforth bedauert, dass dieser Verbot u.a. für Rechenzentren und EDV-Anlagen noch nicht gelte. Aebischer hat dann Recht, wenn er sagt, dass die Strom- und im Allgemeinen die Energiefrage bei Rechenzentren in den 90er Jahren von der deutschen Politik kaum berücksichtigt wurde. In den Debatten des Bundestags bleibt es so fast bis heute, wie unsere Abbildung nahelegt, die dennoch eine leichte Wiederbelebung vom Themenkomplex Energie, Wirtschaft, Optimierung, Nachhaltigkeit ab 2022-2023 zeigt. Wenn wir diese letzten Jahre fokussieren, merken wir, dass die Debatten über die Rechenzentren sich um die Frage drehen, ob Rechenzentren als Hebel einer grünen Ökonomie fungieren könnten, die von wissenschaftlichen Innovationen unterstützt wäre. Diese Frage lässt jedoch die deutsche Politik uneins und für die Betreiber von Rechenzentren in Deutschland und ihre Partnern in der Wirtschaft und in der Wissenschaft schwer zu beeinflussen. Dieser Aspekt der jüngsten Debatten um die Rechenzentren im deutschen Bundestag wollen wir im folgenden vertiefen, weil er ein bedeutsames Problem betrifft, das dazu beigetragen hat, die Bedeutung von Rechenzentren in der Gesellschaft zu verdeutlichen: Das Dilemma Energieverbrauch vs. Energieeffizienz.

* Energieverbrauch und Energieeffizienz von Rechenzentren

Dass Rechenzentren für die Politik in den letzten Jahren an Bedeutung im Vergleich zu den Jahren davor gewonnen haben, zeigt unsere Topic-Modell-Analyse. Das dies nicht immer der Fall war, kann am Beispiel der Auseinandersetzung zwischen Paul Laufs (CDU) und Erwin Stahl (SPD) zu den Rechenzentren im Protokoll des Bundestages vom 28.09.1978 veranschaulicht werden: "(Laufs) Aus welchen Gründen schlägt die Bundesregierung vor, die Mittelzuweisungen aus dem Haushalt für Forschung und Technologie für die Finanzierung von regionalen Rechenzentren gegenüber dem Plan des 3. DV-Programms 1976-79 drastisch zu kürzen?"; "(Stahl) Herr Kollege Dr. Laufs, es trifft nicht zu, daß die Mittel für die Finanzierung von regionalen Rechenzentren gegenüber dem Plan des 3. DV-Programms drastisch gekürzt worden sind. Im Zeitraum von 1976 bis 1979 werden 142 Millionen DM bereitgestellt werden; das sind 15 % weniger als ursprünglich geplant. Die Mittel haben bisher ausgereicht und werden auch im Jahre 1979 ausreichen"; "(Laufs) Herr Staatssekretär, sind Ihnen die Befürchtungen bei den regionalen Rechenzentren bekannt, daß die deutsche rechenintensive Forschung gegenüber der Industrie und dem Ausland ins Hintertreffen geraten wird, weil die regionalen Großrechenanlagen hinsichtlich ihres PreisLeistungs-Verhältnisses und auch ihrer Rechenleistung durch diese Politik der Bundesregierung nicht auf dem Stand der Zeit gehalten werden können?"; "(Stahl) Derartige Äußerungen, Herr Kollege Dr. Laufs, sind mir nicht bekannt. Ich darf nochmals darauf aufmerksam machen, daß für DV-Beschaffungen im Regionalprogramm bis zum 31. Dezember 1977 einschließlich des DV-Sonderprogramms insgesamt 290,6 Millionen DM ausgegeben worden sind. Weitere Klagen sind nicht bekannt". 45 Jahre später ist für die deutsche Politik unumstritten, dass es angesichts der wachsenden Bedeutung von Rechenzentren in der ganzen Gesellschaft in Rechenzentren investiert werden muss. Aber vollkommen ausgeräumt sind die Kontroversen nicht, sondern sie betreffen eine andere Frage, die an der umstrittenen Schnittstelle des ökonomischen Wachstums und der ökologischer Bilanz debattiert wird. Das Protokoll des Bundestages zur Sitzung vom 17.05.2023 zeigt exemplarisch, wie die Politik uneins in Bezug auf Rechenzentren reagiert. In seinem Redebeitrag im Bundestag stellt Uwe Kamann (LKR, IT-Unternehmer) die folgende Frage, die eine Debatte zu den Rechenzentren in dieser Sitzung hervorrufen wird: "Sie fordern von der Bundesregierung, den Stromverbrauch für den Ausbau des 5G-Netzes und die Auswirkung dessen auf Rechenzentren zu validieren. Wenn diese dann höher ausfallen, als es ideologisch akzeptierbar ist, was ist dann? Wollen Sie dann wie beim Schadstoffausstoß des Diesels willkürliche Grenzwerte festlegen, oder wollen Sie gar ganze Rechenzentren stilllegen?". Dazu äußern sich Timon Gremmels und Falko Mohrs (SPD) sowie Dieter Janecek (Bündnis 90/Die Grünen), um zu sagen, dass Rechenzentren auch im Rahmen der Energiewende berücksichtigt werden müssen, weil sie in den Debatten zur Digitalisierung eine wichtige Rolle spielen. Hansjörg Durz (CSU) antwortet darauf, dass dies schon seit 2022 der Fall ist, und er fügt hinzu, dass Rechenzentren bald Teil von einem "Digitalagenda" sein werden: "Viele Ihrer Forderungen sind darin bereits enthalten. Auch die Forderung nach energieeffizienteren digitalen Produkten und der Nutzung der Abwärme von Rechenzentren ist eine Forderung, die in Papieren der Union aus den vergangenen Jahren zu finden ist". Nichtsdestotrotz werfen Die Linke durch Frau Anke Domscheit der Regierung vor, dass eine solche Agenda eher vage bleibt.

In den Debatten im Bundestag kommt deutlich zum Vorschein, dass es daran gezweifelt wird, wie energieeffiziente Rechenzentren gelingen können, ohne dass eine solche Energieeffizienz zu weniger Leistung führen würde, was die Wissenschaft wie die Wirtschaft benachteiligen könnte. Falko Mohrs erinnert in der Sitzung des Bundestages vom 17.05.2023, dass dieser Punkt schon 2008 im Rahmen "der Beschaffungsstrategie des Bundes verankert [wurde]". Dies lässt sich auf der Grundlage der Protokolle des Bundestages nicht wieder finden, zumal es eine Beschaffungsstrategie des Bundes nicht gibt, sondern mehrere (etwa für Raumfahrttechnologien in der Partnerschaft mit der EU, für Rohstoffe und Energiequellen oder für Autos), die seit 1983 im Bundestag kontroverse diskutiert werden aber das Thema Rechenzentren nicht unmittelbar betreffen. Die Erwähnung vom Jahr 2008 ist dennoch interessant, weil in diesem Jahr anschließend an der IT-Messe CeBIT eine Debatte einerseits zur Unterstützung der Forschung in den IT-Bereichen und andererseits zur ökologischen Maßnahmen stattfindet (Sitzung des Bundestages am 05.03.2008). Zum ersten Punkt äußert sich Lothar Bisky (Die Linke), der besonders bedauert, dass die Bundesregierung die Forschung in den IT-Bereichen grundsätzlich als nur von den IT-Industrien getrieben sieht. Er plädiert stattdessen für mehr Unterstützung der wissenschaftlichen Forschung: "IT-Forschung ist nach dem Verständnis der Bundesregierung daher vorrangig ein Programm zur Subventionierung von Informations- und Kommunikationstechnologie in ausgewählten Anwendungsbereichen, vor allem Automobilbau, Telekommunikation, Logistik und Medizintechnik. (...) Darauf allein (...) lässt sich die Basis für eine Informations- und Wissensgesellschaft nicht gründen. (...) Den Hochschulen kommt auf diesem Feld eine wichtige, wenn nicht entscheidende Aufgabe für die Zukunft zu". Wissenschaftliche statt industrielle Forschung ist deshalb wichtig, weil sich dort das Potential zur Herstellung von grüneren Produkten befinde: "Nicht umsonst gibt es 'Green IT', ein Schwerpunktthema der CeBIT". Heinz Schmitt (SPD) verlängert die Überlegung von Bisky: "Laut BUND ist der Stromverbrauch von IT-Geräten für 43 Prozent der CO2-Emissionen in Deutschland verantwortlich. Handy, Computer, Fernseher, moderne Informationstechnik benötigt immer mehr Energie. (...) Um den Energieverbrauch vom Wirtschaftswachstum zu entkoppeln, müssen wir quer durch alle Wirtschaftsbereiche energieeffiziente Produkte konstruieren, produzieren, nutzen und - ein ganz wichtiger Punkt - recyclen. Und dies ist nur mit innovativer Hightech machbar. Moderne Informationstechnik und Umweltschutz müssen also miteinander kombiniert werden. Davon profitiert die Umwelt; mit Green IT lässt sich aber auch viel Geld verdienen bzw. viel Geld einsparen".

Diese Debatten zu Rechenzentren im Bundestag verdeutlichen das, was für die deutsche Politik in diesem Zusammenhang auf dem Spiel steht. Einerseits haben wir Betreiber von Rechenzentren zusammen mit IT-Unternehmen, die versuchen, Einfluss auf die Politik zu nehmen, um Rechenzentren weiterhin in der ganzen Gesellschaft zu verbreiten. Die Politik spielt einerseits mit, um Elias' Bild vom Fußballspiel zu übernehmen. Andererseits greift sie die Frage des Energieverbrauches der Rechenzentren auf, um sich von dieser Einflussstrategie der Betreiber von Rechenzentren und IT-Unternehmen zu befreien und diese Unternehmer im Umkehrschluss zu beeinflussen. Zu diesem Zweck setzt die Politik ein wichtiges Mittel ein, dass der Redebeitrag von Schmitt verdeutlicht, wenn er später in seiner Ausführung die Expertise vom Fachverband BITKOM im Bereich IT erwähnt, der mobilisiert werden sollte, um mehr zu dieser Frage des Energieverbrauches von Rechenzentren in Deutschland zu erfahren. Der Wunsch nach Expertisen in der Mitarbeit mit spezialisierten Verbänden aus der Wirtschaft sowie der Wissenschaft, wie wir es sehen werden, verdeutlicht die Entwicklung von einer Satellisierungsstrategie, die von der Politik bis in die Wirtschaft mit dem Ziel gehen sollte, vertretbare Rechenzentren verbreiten zu lassen. Der deutschen Politik geht es in diesem Zusammenhang um Machtbalance als Problem der Allianz mit Akteuren aus der Wirtschaft und der Wissenschaft bzw. als Zusammenstellung von Verhältnissen in der Durchsetzung von einer Ordnung von Verhältnissen in der Gesellschaft, die das Selbstverständnis der Politik widerspiegelt. Für die deutsche Politik ist es wichtig, so unwiderstehlich Rechenzentren sein mögen bzw. so attraktiv sie sein können, dass besonders bei Fragen des Energieverbrauchs und der Energieeffizienz andere gesellschaftliche Instanzen sowie Akteure in der Gesellschaft dieser Attraktivität von Rechenzentren nicht aufgeopfert werden. Energie brauchen nicht nur Rechenzentren, und Energie hat einen Preis im Sinne des Verbrauches von ökologischen Ressourcen sowie im Sinne der Weltverschmutzung und des Klimawandels. Dabei geht es für die deutsche Politik um die Repräsentation bzw. die gerechte Verteilung von Energie mit Blick auf Verbrauch, Preise und Natur. Oder anders gesagt: Es geht ihr darum, ihre Attraktivität im Dienst dieser Repräsentation von Energie in der Gesellschaft zu bringen und damit die eigene Repräsentation in der Gesellschaft zu stärken. Die deutsche Politik versteht entsprechend Rechenzentren als Umverteilungsproblem bzw. als Problem der Umverteilung von Energie und der Gewichtung von medialen Verhältnissen in der Gesellschaft im Vergleich zu anderen Ordnung von Verhältnissen und anderen Formen des Umgangs mit Energie. Sie braucht entsprechende Instanzen, die an dieser Umverteilung arbeiten, die sie schon im Jahre 2007 durch das Bundesministerium für Umwelt, Naturschutz, Bau und Reaktorensicherheit (BMU) mobilisiert. Das BMU veranstaltet einen "Fachdialog (...) zum Thema 'Zukunftsmarkt 'grüne' Rechenzentren'" mit BITKOM sowie Partnern aus der Wissenschaft (Oldenburg Center for Sustainability Economics and Management der Universität Oldenburg, dem Fraunhofer Institut für System- und Innovationsforschung in Karlsruhe sowie dem Institut für Zukunftsstudien und Technologiebewertung) [cite:@fichter07:_zukun_energ_rechen, I]. In diesem Zusammenhang beauftragt es die unabhängige und gemeinnützige Forschungseinrichtung Borderstep (Berlin) mit einem Bericht zur Frage der Rechenzentren und deren Energieeffizienz, der im selben Jahr veröffentlicht wird.

* Energieeffiziente Rechenzentren

Weil mit ihrer Satellisierungstrategie die deutsche Politik ihren Einfluss bis in die Wirtschaft mit dem Ziel zu erstrecken versucht, Allianzen zur Herstellung von einer Machtbalance in der Frage der deutschen Rechenzentren zu knüpfen, überrascht die Feststellung nicht, dass sie Rechenzentren mit der ökonomischen Semantik codiert. Der Berichts von Borderstep bildet ein solches Verständnis von Rechenzentren unmittelbar ab: Im Thema Rechenzentrum "stehen dabei die Entwicklung der Wettbewerbsfähigkeit deutscher und europäischer Unternehmen im internationalen Vergleich, ihr Umfeld sowie Ansatzpunkte für eine Stärkung des deutschen und europäischen Innovationssystems" (ebd.). Dieses Merkmal ist zum einen typisch von der politischen Wahrnehmung der Technologien, die sich im politischen Diskurs niederschlägt, der seit den 70er Jahren in den industriellen Gesellschaften die Partnerschaft zwischen Wissenschaft und Wirtschaft zur Entstehung einer Wissensökonomie fördern will. Zum zweiten spiegelt es die Grundlage von der Satellisierungsstrategie der Politik in der Gesellschaft wider, die darin besteht, Expertise aus der Wissenschaft einzubeziehen, um gesellschaftliche Probleme zu dimensionieren, während Lösungsvorschläge aus der Wirtschaft erwartet werden. So erfolgt die politische Handlung nicht nur formal in rechtlichen Regeln und Normen, sondern auch konkret in Förderungsmaßnahmen und Zuwendungen. Bei dieser Strategie der Satellisierung von Wissenschaft und Wirtschaft, die wir bereits im Rahmen von Hochtechnologie beschrieben haben [cite:@monoPapilloud2012;@monoPapilloudSchultze2023], spielen Instanzen der Umverteilung in der Politik eine wichtige Rolle. Wie Instanzen der Umverteilung in anderen Bereichen der Gesellschaft tragen sie zur Erkennung von Problemen zwecks der Formulierung von Vorschlägen für die Orientierung von Akteuren und gesellschaftlichen Instanzen in Einbettungskontexten bzw. zu ihrer neuen Orientierung und zur neuen Strukturierung von solchen Einbettungskontexten bei. Unmittelbar oder mittelbar durch satellisierte Umverteilungsinstanzen in anderen gesellschaftlichen Bereichen messen, wiegen, vergleichen, beziffern, berechnen sie die Realität. Sie symbolisieren sie in Zahlen, Formeln, Indikatoren und geben somit dem Unbekannten Formen. Im Fall der Rechenzentren geht es ihnen darum, dass "das Potential von einem solchen Markt besser benutzt wird" (ebd., 1).

Die Wahrnehmung von Rechenzentren als Markt soll in erster Linie dabei helfen, das Problem der Definition von Rechenzentren zu lösen: "Bislang gibt es keine allgemein gültige Definition des Begriffs 'Rechenzentrum' bzw. 'data centre'" (ebd. 5). Mit dem Wort "Rechenzentrum" wird zwar eine Verbindung zwischen Rechnern und Räumlichkeiten bezeichnet, aber Rechenzentrum ist nicht gleich Rechenzentrum. Deshalb orientiert sich zuerst die Definition von Boderstep im Einklang mit der jüngsten Expertenliteratur in den Vereinigten Staaten an der Schnittstelle zwischen Rechentechnik und Räumlichkeit, um sie zu beziffern und somit den Begriff "Rechenzentrum" zu präzisieren. Demnach gelten als Rechenzentren diejenige Zusammenstellungen von Duzenden bis Tausenden Servern in Räumlichkeiten von mindestens 50 bis mehr als 500 Quadratmeter (ebd., 5-6). Im Sinne von einer technischen Definition bedeutet diese räumlich orientierte Definition von Rechenzentren, dass Rechenzentren als solche gelten, wenn sie Server, Speicher, die Netzwerkausrüstung, die unterbrechungsfreie Stromversorgung, die Stromverteilung sowie die Klimatisierung und die Kühlung voraussetzen (ebd., 8). Das Problem von dieser Definition der Rechenzentren ergibt sich von selbst: Rechenzentren sind eher ein Markt der Märkte, die auf IT-Produkte, auf Dienstleistungen im Bereich von Telekommunikationen, auf die Halbleiterindustrie, auf die Stromindustrie, auf das Bauwesen bis hin zu Startups und Spin-offs, bis zu Bereichen außerhalb der Wirtschaft wie der wissenschaftlichen Forschung in sehr unterschiedlichen Disziplinen (Chemie, Physik, Optik, Ingenieurwesen, Informatik usw.) verweisen. Eine solche Definition von Rechenzentren grenzt zwar einerseits ab, was als "Rechenzentrum" gilt, damit nicht alles, was mit Rechnern verbunden ist, in diese Definition einfließt. Aber dies funktioniert eher rhetorisch als analytisch.

Kleine Rechenzentren (wenige Rechner in Räumlichkeiten von weniger als 50 Quadratmetern), die von der Definition der Rechenzentren ausgeschlossen werden, tragen auch zum Problem der Energieeffizienz von größeren Rechenzentren bei, die diese Definition fokussiert. Etwa der Zugang zum Internet kann erwähnt werden, der den Anschluss von kleinen Servern mit größeren Servern voraussetzt. Deshalb funktioniert den räumlichen Ansatz bei der Definition von Rechenzentren nicht oder zumindest nicht allein, sondern er muss mit einem wissenschaftlich-technischen Ansatz verbunden werden. Dass der Einbezug von einem solchen wissenschaftlich-technischen Ansatz das Problem der Definition von Rechenzentren und daher deren Lokalisierung in der Gesellschaft erschwert, kommentiert Aebischer in Bezug auf die Frage des Energieverbrauchs von Rechenzentren: "Ideally, energy efficiency of a data centre should be measured in terms of energy consumption per unit of service delivered to the customer. However, there exists no commonly agreed method to measure the service provided by a data centre" [cite:@aebischer03:_energ 437]. Anders gesagt: Die technologische Entwicklung erschwert die Etablierung von einem Referenzwert der Energieeffizienz von Rechenzentren, der erlauben würde, genaue Messungen vom Energieverbrauch und Energieverluste in Rechenzentren zu erhalten und daraus Standards für Messzahlen mit dem Ziel zu definieren, den Energieverbrauch von unterschiedlichen Rechenzentren transnational zu vergleichen. Zwar schlägt Aebischer einen "Coefficient of Energy Efficiency (CEE)" auf der Grundlage von zwei Richtwerten C1 und C2 vor, wo CEE = C1*C2 (ebd.). C1 misst die Effizienz der Infrastruktur von einem Rechenzentrum und C2 die Effizienz der Rechentechnik in dieser Infrastruktur (ebd., 438). Aber wenn der Wert von C1 unmittelbar erhalten werden kann, bleibt dagegen der Wert von C2 schwer und nur mittelbar erhältlich (Unterschied zwischen dem gesamten Strom, der in das Rechenzentrum kommt, und dem Strom, der dabei verloren geht; ebd.). Deshalb bleibt der CEE als Indikator der Messung von der Energieeffizienz der Rechenzentren unbefriedigend, und er kann nicht unmittelbar zu Vorschlägen für die politischen Akteuren und Instanzen führen. In 2014 verallgemeinert Aebischer diese Schlussfolgerung für alle Indikatoren, die im Bereich der Messung von der Energieeffizienz der Rechenzentren eingesetzt werden. Dies gilt etwa auch für den Indikator vom Green Grid /Power Usage Effectiveness/ (PUE) [cite:@haas09:_usage_public_repor_guidel_green], der seit 2009 weltweit eingesetzt wird, um die Energieeffizienz von Rechenzentren zu messen [cite:@aebischer14:_energ_deman_ict 11]. Die positive Seite von diesem Messungsproblem ist, dass das Interesse für den Energieverbrauch von Rechenzentren steigt. Wie Aebischer zeigt, wurden seitdem mehrere Initiativen weltweit ergriffen (die Akzentsetzung auf die Virtualisierung von Dienstleistungen bis hin zu /cloud computing/, die Initiative /Energy Star/ in den Vereinigten Staaten, den europäischen /Code of Conduct for Data Centers/, die Initiative /CRC Energy Efficiency Scheme/ in Großbritanien; ebd., 12), um mehr Erkenntnisse zum Stromverbrauch von Rechenzentren in der Hoffnung zu sammeln, dass in der nahen Zukunft energieeffizientere Rechenzentren gebaut werden können.

Borderstep folgt diesem Ansatz auch und versucht unmittelbar im Anschluß an seinem ersten Bericht in einem zweiten Bericht in Begleitung von BITKOM die Frage des Energieverbrauchs bzw. der Energieeffizienz von Rechenzentren auf den Grund zu gehen. Wie Borderstep in seinem ersten Bericht sagte: "Für die Ermittlung und das Monitoring des Energieverbrauchs von Rechenzentren ist die Frage zentral, wie viele Rechenzentren welchen Typs und welcher Größe es gibt. Hierzu existieren bis dato weder in der Wissenschaft noch bei den Branchenverbänden oder den einschlägigen Marktforschungseinrichtungen Statistiken" [cite:@fichter07:_zukun_energ_rechen 8]. Deshalb wird 2010 versucht, eine materielle Bestandaufnahme von der geschätzten Anzahl an Rechenzentren durchzuführen. Dabei wird zwar die eingeschränkte Definition der Rechenzentren von 2007 wieder erwähnt [cite:@hintemann10:_mater_rechen_deuts 13], aber sie wird für die Schätzung der Anzahl an Rechenzentren nicht weiter verwendet. Im Bericht von 2010 geht es dagegen darum, alles, was Server enthält, im Blick zu nehmen. Dies zeigt, dass bei Borderstep und beim Auftraggeber BMU die Vermutung konkreter geworden ist, dass Rechenzentren nicht mehr nur diese Rechenzentren sind, die Universitäten und Firmen in der Unterstützung der eigenen Bedürfnissen an Automatisierung entwickelt haben. Es gibt eine Informationsgesellschaft, die mediale Verhältnisse in der Gesellschaft vermehrt und immer mehr auf Rechenzentren angewiesen ist, die entsprechend entweder vermehrt oder vergrößert (Stichwort /collocation datacentres/) werden.

Deshalb orientiert sich Borderstep nicht mehr nach der wirtschaftlichen Semantik zur Codierung vom Rechenzentren als wichtigem Markt, sondern er argumentiert jetzt auf der Grundlage von einem dezidierten technischen empirischen Ansatz, innerhalb dessen Borderstep seinen ehemaligen räumlichen Ansatz verankert. Kleinere "Rechenzentren" bzw. "Serverschränke" werden hier im Detail berücksichtigt. Mit diesem Ansatz kommt Borderstep auf eine Anzahl von 53170 Rechenzentren für Deutschland im Jahr 2010, die je nach Anzahl an Servern, die sie beinhalten, unterschiedlich groß sind und ein bisschen mehr als 1.280.000 Mio. Servern entsprechen (ebd., 25). Anschließend erfolgt die Schätzung vom Energieverbrauch dieser Rechenzentren insbesondere in Bezug auf die Einzelkomponenten der Server- und Speichertechnik mit Einbezug der Netzwerktechnik unter der Annahme, dass die Netzwerktechnik, deren Energieverbrauch nur mittelbar geschätzt werden kann, 10% der Servertechnik entspricht (ebd., 34). Diese Daten stellen die Grundlage für die Prognosen des Energieverbrauches von Rechenzentren in Deutschland bis 2015. Diese Prognosen richten sich nach den Szenarien aus dem Bericht der /Lawrence Berkeley National Laboratory/ (LBNL) in Zusammenarbeit mit der /U.S. Environmental Protection Agency/ (EPA) zur Veranschaulichung von möglichen Trends beim Energieverbrauch von Rechenzentren in den Vereinigten Staaten [cite:@brown08:_repor_congr_server_data_center_energ_effic 8-10;@hintemann10:_mater_rechen_deuts 85-90]. Übersetzt und vereinfacht -- LBNL spricht von fünf Szenarien, Borderstep bildet zwei davon ab -- kommt Borderstep zum Schluss, dass ohne Veränderungen im Vergleich zur vergangenen Entwicklungen der Rechenzentren in Deutschland ihrer Energieverbrauch auf 40% von 2008 bis 2015 steigen sollte (Szenario "Business as usual"). Wenn aber die "Green IT" im Rahmen von Rechenzentren entwickelt wird, dann könnte der Energieverbrauch von Rechenzentren in die umgekehrte Richtung gehen bzw. von 40% in der Zeit von 2008 bis 2015 sinken (ebd., 90). Diese Schätzung von +- 40% ist im Vergleich zur Berechnung von LBNL optimistischer in Bezug auf den Szenario "Business as usual" (LBNL sieht eine Verdoppelung des Energieverbrauches von 2006 bis 2011). Sie ist fast identisch für den Szenario "Green IT". Ist eine solche relative Übereinstimmung der Prognosen von LBNL und Borderstep ein Beleg dafür, dass die Schätzung vom Energieverbrauches bzw. der Energieeffizienz von Rechenzentren zuverlässiger geworden ist? Wenn man Aebischer folgt, ist dies mehr "the consequence of using the same or similar data and making similar assumptions" [cite:@aebischer14:_energ_deman_ict 21]. Deshalb auch bleibt Borderstep in seinen Schlussfolgerungen vorsichtig: Energieeffizienz kann zwar erreicht werden, aber wie und wann sie erreicht werden kann, hängt von sehr vielen Faktoren ab bzw. bleibt offen. Für die Machtbalance, die die Politik durch ihre Satellisierung aufzubauen abzielt, ist das nicht besonders befriedigend.

* Folgen für die Machtbalance

Aus den unterschiedlichen Berichten zum Energieverbrauch bzw. zur Energieeffizienz von Rechenzentren ergeben sich zwei wichtigen Erkenntnissen. Zum einen ist und bleibt die Messung vom Energieverbrauch bzw. von der Energieeffizienz der Rechenzentren ungenau, nicht einheitlich und unvollständig. Aebischer merkte im Jahr 2009 an: "Bis heute hat sich aber noch keine Organisation auf ein Messkonzept einigen können, das erlauben würde, die Energieeffizienz von verschiedenen Rechenzentren verlässlich miteinander zu vergleichen. Es ist auch noch nicht gelungen, ein umfassendes Mass für die Energieeffizienz der Data Centres zu definieren" [cite:@aebischer09:_energ_rechen 18]. Im Jahr 2014 in seiner detaillierten Behandlung der unterschiedlichen Messwerte und Indikatoren, die weltweit zur Messung vom Energieverbrauch der Rechenzentren entwickelt werden, hat sich dieses Bild nicht verändert. Die Frage "Wie viele Energie verbrauchen Rechenzentren?" kann deshalb nicht zufriedenstellend beantwortet werden [cite:@aebischer14:_energ_deman_ict]. Zur konvergierenden Feststellung kommt in Deutschland der Bericht von Murzakulova im Auftrag für das Bundesministeriums für Wirtschaft und Klimaschutz [cite:@murzakulova25:_stand_entwic_rechen_deuts]. Wie Aebischer schon erwähnt hatte, ist selbst der PUE-Wert, der vom /Gesetz zur Steigerung der Energieeffizienz in Deutschland 1/ (EnEfG, 2023, Absch. 4, §11) mit dem Ziel aufgegriffen wird, klimaneutrale Rechenzentren zu etablieren, unbefriedigend. Er berücksichtigt etwa die "Anforderungen an Verfügbarkeiten und Redundanz von Ressourcen (...) sowie gängige Geschäftsmodelle" nicht, die im praktischen Betrieb von Rechenzentren Energie verlangen (ebd., 100). Dies setzt den realen PUE-Wert von Rechenzentren höher (um 1.8 bzw. 1.9, d. h. für 1 KW, der von der IT-Technik verbraucht wird, muss noch 0.8 bzw. 0.9 KW für die Umgebung der IT-Technik verbraucht werden), als der Wert, der im Gesetz vorgesehen wird (1.2 bis 1.5), weshalb diese Betreiber die angeforderten PUE-Werte vom EnEfG nicht erreichen können (ebd.). Es entstehen Initiativen wie den /Climate Neutral Data Centre Pact/ (ein Netzwerk von Rechenzentrenbetreibern und Vereinen, das seit 2021 existiert, von der EU-Kommission unterstützt wird und im Jahr 2025 Mitglieder in der Höhe von 85% des Marktanteils von Rechenzentren europaweit einbezieht; vgl. https://www.climateneutraldatacentre.net/) mit dem Ziel, Druck auf die politischen Instanzen auszuüben, damit den PUE-Wert sowie weitere Instrumente und Richtwerte wie etwa für den Verbrauch vom Wasser zur Kühlung der Rechenzentren (sog. WUE-Wert für /Water Usage Effectiveness/) umformuliert werden. Dies ist eine erste Schwierigkeit, die unmittelbar bremsend auf die Satelliseirungsstrategie der Politik wirkt.

Zum zweiten zeigt die Durchsetzung von einem empirischen technischen Ansatz in den Berichten zur Energieeffizienz von Rechenzentren im Auftrag der Politik in Deutschland bzw. die entsprechende Auseinandersetzung mit der technischen Komplexität von Rechenzentren eine zweite Schwierigkeit, die die Satellisierungsstrategie der Politik ebenfalls bremst. Das Problem wird immer komplexer, weil wie schon Aebischer anmerkte: "ICT products are changing their nature from owned goods to services" [cite:@aebischer14:_energ_deman_ict 20]. Weil IKT immer mehr zu Dienstleistungen werden -- ein Trend, der vom /cloud computing/ (2014) und von der KI (2017) beschleunigt wird --, ist es in der Folge immer schwieriger, eine Dienstleistung zu einem genauen /device/, einem genauen Markt, einer genauen Gruppen von Firmen usw. zuzuschreiben und daher sie mit einer genauen Rechenzentrenleistung zu verbinden. Um ein Beispiel zu erwähnen: Prozessoren und Mikrokontroller befinden sich längst nicht mehr nur in Rechnern, sondern in vielen alltäglichen Gegenständen (Autos, Kühlschränken, Uhren, Smartphones, Fernsehern, Rundfunkgeräten usw.), die sich nicht nur mit dem Internet verbinden lassen, sondern auch tendenziell immer eingeschaltet sind. Dies kostet nicht nur Strom an der Seite der Endbenutzer, sondern verbraucht auch viel Strom an der Seite der Rechenzentren, ohne dass man feststellen kann, wie viel Strom es ist. Immer noch in Verbindung mit diesem technischen empirischen Ansatz: Die Miniaturisierung von technischen Komponenten der Rechner und Server ist nicht unendlich. Es ist vorgesehen, dass die Verwendung vom Silikon für die Implementierung von Transistoren auf Mikrochips um 2040 auslaufen sollte (ebd., 2; andere Prognosen setzen die Frist um 2027-2035 [cite:@epoch2022predictinggpuperformance]). Wenn dieser Silikon etwa von 2D Materialien mit einer Breite von drei Atomen nicht ersetzt werden kann, dann ist es ein Problem. Die Energie, die im Bereich der IKT seit dem Ende des Zweiten Weltkrieges gespart werden konnte, hing von der Miniaturisierung dieser Komponenten ab. Mit der Steigerung der Nachfrage an IKT, die sich als historischer Trend erweist, würde dann der Energieverbrauch automatisch ansteigen. Das sind die Schwierigkeiten, die gut bekannt sind. Weitere Schwierigkeiten bleiben weniger überschaubar -- wie etwa das Problem der /life cycle/ von IKT Geräten und Komponenten, ihr /recycling/, das Problem des Softwares, das wenn nicht angepasst ebenfalls zu Erhöhung vom Stromverbrauch bei Rechenzentren führen kann. Im Allgemeinen kann das Problem der Satellisierungstrategie der Politik so zusammengefasst werden: Rechenzentren kommen immer mehr in der Unterstützung der Verbreitung von einer Informationsgesellschaft, die uns tagtäglich von immer mehr IKT als Hardware, Software und Dienstleistungen und daher von der Rechenleistung von Rechenzentren abhängig macht. Oder anders gesagt: Rechenzentren erfinden sich neu als Instanzen von einer medialen Relationsstruktur, die die Wirtschaft, die Wissenschaft, die Politik und die ganze Gesellschaft zu satellisieren versucht, und die dafür immer mehr und mächtigere Rechenzentren braucht.

In seinem Bericht von 2012 verzeichnet Borderstep zwar eine sinkende Tendenz beim Energieverbrauch in Rechenzentren ab 2008-2010 in Deutschland, die belegen würde, dass das Szenario "Green IT" durchgesetzt werden könnte [cite:@hintemann14:_rechen_deuts 38-39]. Aber Borderstep merkt gleichzeitig an, dass sich diese Tendenz auch aus der Finanzkrise von 2008-2009 ergeben könnte, die zum Verkauf von wenigen Servern geführt hat. Würden nach dieser Zeit mehr Server wieder verkauft werden, dann würde "der Energiebedarf der Server- und Rechenzentren voraussichtlich wieder ansteigen" [cite:@hintemann12:_energ_energ_server_rechen_deuts 3]. In den nachfolgenden Jahren bestätigt sich den stetigen Anstieg des Energieverbrauches von Rechenzentren, der deutlich höher als die ersparte Energie ausfällt, die dank der technischen Entwicklung von Komponenten für Rechenzentren und von der entsprechenden Gebäudetechnik erreicht wird [cite:@hintemann20:_rechen]. Im Bericht von Murzakulova steigt die prognostizierte Entwicklung vom Energieverbrauch steil [cite:@murzakulova25:_stand_entwic_rechen_deuts 9]. Er hat sich innerhalb von 14 Jahren (2010-2024) verdoppelt, und diese Entwicklung sollte sich bis 2045 auf 80 Mrd. KWh/Jahr (400% mehr als 2024; ebd.) durchsetzen. Diese Prognose berücksichtigt die Maßnahmen, die bis heute ergriffen worden sind, um Energie zu sparen -- wie etwa das EnEfG-Gesetz. In Bezug auf die Karbonspur von Rechenzentren ist der Bericht optimistischer. Es gäbe eine mögliche sinkende Tendenz bei den CO2-Emissionen. Aber diese Tendenz setzt voraus, dass der Energiemix erfolgreich durchgesetzt wird bzw. dass die Rechenzentren mit hauptsächlich (idealerweise: nur) erneuerbaren Energien laufen (ebd.). Im Sinne der Machtbalance, die die Politik aufzubauen versucht, setzt dies voraus, dass alle Akteure entlang ihrer Satellisierungstrategie bzw. dass Wissenschaftler wie Unternehmer besser miteinander und mit regulatorischen Instanzen der Politik arbeiten, damit das Ziel der klimaneutralen Rechenzentren erreicht wird. Dass dies keine Selbstverständlichkeit ist, kann an dem folgenden Beispiel auf der Ebene der /Energy Efficiency Directive/ der Europäischen Kommission (2012 mit Revisionen in den Jahren 2018 und 2023) zu klimaneutralen Rechenzentren gezeigt werden.

Im Juli 2025 veröffentlicht der /Climate Neutral Data Centre Pact/ einen kritischen Bericht zur /Energy Efficiency Directive/ der Europäischen Kommission, die in Deutschland zum EnEfG geführt hat. Der CNDCP stellt fest, dass das Ziel, klimaneutrale Rechenzentren im Jahr 2030 zu erreichen, sich weit aus der Reichweite befindet [cite:@pact25:_minim_perfor_stand_data_centr]. Die Gründe dafür bestehen zuerst in den Regularien, die von der EU und von der Politik in den Europäischen Ländern formuliert werden, die stark von der Praxis im Bereich des Betriebs von Rechenzentren abweichen [cite:@pact25:_minim_perfor_stand_data_centr 3-4]. Dies betrifft nicht nur die Definition vom  PUE-Wert und WUE-Werte zur Förderung der Energieeffizienz von Rechenzentren, die wir oben erwähnt haben. Dies betrifft auch die Verwendung von solchen Werten, die nur Rechenzentren betreffen, die mehr als 500 KW verbrauchen. Diese Werte gelten für kleinere Rechenzentren (Rechenzentren, die weniger als 500 KW verbrauchen) nicht. Jedoch sind diese kleineren Rechenzentren diejenige, die am wenigsten energieeffizient sind. Mit der /Directive/ ist es also /de facto/ nicht möglich, die Rechenzentren zu identifizieren, die am wenigsten energieeffizient sind und entsprechend umgebaut werden sollten (ebd., 6). Im Sinne von klimaneutralen Rechenzentren ist es deshalb besonders bedauerlich, weil solche kleinere Rechenzentren die große Mehrheit der Rechenzentren in Europa darstellen. Dies führt dazu, dass die Datenlage zu Rechenzentren, die die EU-Kommission zusammenstellt, um ihre /Directive/ zu verbessern, lückenhaft bzw. von schlechter Qualität ist, was die /Directive/ nicht nur schwächt, sondern auch ihre adäquate Zusammenstellung mit anderen Maßnahmen der EU-Kommission zur Durchsetzung der Energieeffizienz von Rechenzentren in Europa erschwert. Dabei lässt sich die Botschaft von CNDCP eindeutig erkennen, die wie folgt zusammengefasst werden kann: die Machtbalence um die Rechenzentren, die die Politik mit der Wissenschaft und der Wirtschaft zu konsolidieren versucht, funktioniert nicht. Dies spielt in die Karten von großen Techkonzernen, die im Laufe der technischen Entwicklung im IT-Bereich daran denken, eigene Rechenzentren zu entwickeln, dafür "Green IT" nicht wirklich in Frage kommt, weil solche Rechenzentren vollkommen in der Unterstützung der Art von Informationsgesellschaft kommen müssen, die sich diese Techkonzerne vorstellen. Mit dem Durchbruch der KI wird diese Vorstellung von Techkonzernen mit eigenen Rechenzentren konkreter.

* Rechenzentren in der KI-Zeit

Der Bericht /AI-2027/ beschäftigt sich mit Prognosen zur Entwicklung von KI-Technologien in der Gesellschaft [cite:@ai-2027]. KI-Technologien sind Algorithmen zur Herstellung von Sprachmodellen bzw. von Matrizen der Verbindungen zwischen Informationselemente aus Texten, Bildern, Musik usw., die im Internet veröffentlicht werden. Solche Sprachmodelle können von Endbenutzern verwendet werden, um Fragen zu beantworten, Produkte herzustellen und weitere Anliegen und Bedürfnisse zu befriedigen. In Ihrem Bericht geht es für die Autoren darum, diese Entwicklung besser zu verstehen. Deshalb arbeiten sie an der Herstellung von einer Zeitspanne zur Einschätzung der Fortschritte, die in diesem Bereich gemacht werden können, wenn man von den historischen Trends in der Entwicklung von IKT ausgeht. Sie kommen zu dem Schluß, dass in einer nahen Zukunft um das Jahr 2027 (von 2027 bis 2033) KI-Technologien immer genauer arbeiten, weil sie sich selbst immer besser korrigieren. Dies eröffnet den Weg für autonome KI-Technologien, die ohne menschliche Steuerung sondern im Netzwerk funktionieren und im Laufe der Verbesserung ihrer rechnerischen Operationen zu einer Superintelligenz gipfeln würden, die überall in Geräten und Gegenständen (etwa Robotern) implementiert werden könnten. In diesem Zusammenhang spielen die Rechenzentren eine sehr wichtige Rolle, weil sie solche KI-Technologien empfangen, die auf ihren Servern laufen müssen. Wie wir es oben angemerkt haben, haben auch Anwendungen eine wichtige Bedeutung für die Frage vom Energieverbrauch bzw. von der Energieeffizienz von Rechenzentren. In ihrem Versuch, die unterschiedlichen Konsequenzen der Entwicklung von KI-Technologien anzusprechen, haben die Autoren von /AI-2027/ auch diese Frage berücksichtigt. Daraus ergeben sich zwei wichtigen Ergebnisse.

Einerseits gibt es zwischen den Rechenzentren und Betreibern von Rechenzentren die Verdeutlichung von einer Grenze zwischen Akteuren, die in der Wissenschaft und in der Wirtschaft unterwegs sind, und andere Akteuren von großen Techkonzernen, die ihr Geschäft mit reinen medialen Dienstleistungen zur Förderung, Kauf und Verkauf von medialen Verhältnissen mittels KI gestützter Geräte und Anwendungen machen (wie etwa Meta, Google, OpenAI, Anthropic). Andererseits zeigt sich diese Grenze ganz konkret in Bezug auf Rechenzentren als Verbindung von Techniken und Räumlichkeiten und in Bezug auf ihren Energieverbrauch, was die großen Techkonzerne als Umverteilungsproblem umformulieren: Um KI-Technologien weiter entwickeln zu können, braucht man deutlich mächtigere Server als diejenige, die zur Zeit existieren. Deshalb müssen die vorliegenden Ressourcen in aktuellen Rechenzentren aus diesen Rechenzentren genommen werden und in neue KI-Rechenzentren gebracht werden, die dem Konzept der Hyperscaler entsprechen. Solche Hyperscaler sind Rechenzentren mit mehr Stromverbrauch, der im Fall von KI-Hyperscaler notwendig ist, um die immer komplexeren Sprachmodellen in akzeptabler Zeit zu trainieren und bessere Sprachmodellen und Algorithmen zu entwickeln. Dies bieten die bestehenden Rechenzentren nicht an, und wenn sie KI-Technologien beherbergen, dann ist es meistens im Sinne der Verbreitung solcher Technologien [cite:@lehdonvirta24:_comput_north]. Wie BITKOM in seinem Bericht von 2024 anmerkt: "Für die Betreiber von Colocation-Rechenzentren besteht hier (...) das Marktrisiko, dass Hyperscaler in Deutschland wie auch in anderen Ländern dazu übergehen, ihre Gebäude selbst zu betreiben" [cite:@bitkom24:_rechen_deuts 60] -- oder anders gesagt: Neue Rechenzentren einer ganz anderen Größenordnung werden von KI-Techkonzernen für ihre Bedürfnisse gebaut, die sich nicht nur von gewöhnlichen Rechenzentren, sondern auch von Regularien und darunter besonders Regularien im Bereich des Energieverbrauches bzw. der Energieeffizienz abgrenzen. Im Bezug auf den Ansatz der Techkonzerne wird deutlich, wie wir es am Beispiel der soziologischen bzw. sozialwissenschaftlichen Literatur erwähnt haben, dass für solche Techkonzerne Rechenzentren dezidiert als Instanzen von einer medialen Relationsstruktur fungieren und im Dienst ihrer Satellisierungsstrategien arbeiten müssen.

Im Bericht /AI-2027/ wird prognostiziert, dass solche KI-Hyperscaler eine Steigerung von ihrem Stromverbrauch von 5GW (Gigawatt) im Jahr 2023 bis auf 62GW im Jahr 2027 erleben werden [cite:@ai-2027 Compute Forecast, Section 1]. In diesem Zusammenhang sind die großen Techkonzerne schon am Start, wie etwa Mark Zuckerberg (Meta/Facebook), der im Juli 2025 den Aufbau von einem solchen Rechenzentrum namens 'Hyperion' zur Training der eigenen KI angekündigt hat. Ob sich solche KI-Hyperscaler realisieren lassen, bleibt jedoch fraglich, selbst wenn man sich vorstellen könnte, dass Sprachmodelle nicht innerhalb von einem einzigen Rechenzentren trainiert werden würde, sondern auf mehrere Rechenzentren. Solche KI-Hyperscaler brauchen sehr viel Raum (man spricht von hunderten Fußballplätzen), die wie im Fall von anderen Rechenzentren mit speziellen Techniken und Verfahren des Bauwesens sowie Energiequellen ausgerüstet werden müssen, damit die Server verschont werden können und andauernd funktionieren. Abgesehen von den Kosten für die Infrastruktur (wir reden von hunderten Milliarden Dollars für Rechenzentren von 5GW) sind dann die Energiekosten im Sinne vom Gesamtenergieverbrauch und CO2-Emissionen erheblich. Eine Prognose von /Epoch AI/, die die Prognose von /AI-2027/ deutlich relativiert, kommt jedoch zu beeindruckenden Zahlen im Bereich des Energieverbrauches von KI-Hyperscalern [cite:@epri25:_scalin_intel]. /Epoch AI/ sieht eine jährliche Steigerung vom Energieverbrauch der KI-Hyperscalers von 2,2x bis 2,9x in der Zeit von 2025 bis 2030 (ebd., 24) -- dies ist 15% der Energie, die alle Rechenzentren Weltweit verbrauchen (ebd., 19). Im Vergleich zum gesamten Stromverbrauch von den Vereinigten Staaten (1300 GW) sind es 5% von dieser Energie. Im Kontext von unserer Diskussion bedeutet dies, dass sich die großen Techkonzerne nicht nur von aktuell geltenden Regularien im Bereich des Energieverbrauches bzw. der Energieeffizienz von Rechenzentren verabschieden. Sie können auch Druck auf die Politik mit dem Argument machen, dass sie im Interesse der ganzen Gesellschaft neue Regularien brauchen, die besagen, dass sie immer mehr Energie verbrauchen können. Somit würden solche Techkonzerne ihre Satellisierung der Politik und der damit verbundenen Akteuren in anderen gesellschaftlichen Bereichen deutlich stärken und eine neue Machtbalance etablieren.

Direkte Beispiele von einem derartigen Szenario ergeben sich unmittelbar in Verbindung mit den Ressourcen, die solche KI-Rechenzentren benutzen würden, davon einige wie Trinkwasser schon bei weniger mächtigen Rechenzentren für die Kühlung der Gebäude und der IT-Technik bereits eingesetzt werden. Mit dem Klimawandel rückt Trinkwasser und im Allgemeinen Wasser immer mehr zu einer der wichtigsten Ressource für Gesellschaften in der ganzen Welt vor, die deshalb versuchen, Wasser aufzubewahren bzw. zu erhalten/kaufen. Deshalb ist es wichtig, wie eine jüngste Studie zum Thema Wasser im Rahmen von Rechenzentren zeigt, dass es genau gemessen werden kann, wie viel Wasser Rechenzentren verbrauchen [cite:@LEI2025108310]. Dies Studie kommt zu dem Schluss, dass in diesem Zusammenhang vieles noch getan werden sollte, da gute Daten zur genauen Messung vom Wasserverbrauch der Rechenzentren fehlen. Insbesondere fehlt eine Messung des Wasserverbrauches nach dem Workload von Servern, die erlauben würde, zuverlässige Empfehlungen für die wissenschaftliche Gemeinschaft und die Politik zu formulieren. Wenn es besser verstanden wird, wann Wasser je nach Workload von Servern besonders gebraucht werden würde, wäre es zudem auch möglich, Wasser mit anderen erneuerbaren Energien (wie etwa Luft bzw. Wind) zur Kühlung von Rechenzentrenanlagen in einem effizienten Mix zu verwenden. Indirekte Beispiele gibt es auch wie etwa den Umgang mit der Hitze, die Rechenzentren produzieren und die nicht nur für die Erwärmung von Büros, sondern auch etwa in der Landwirtschaft gebraucht bzw. recycliert werden könnte, um Lebensmittel zu produzieren.

In diesem Zusammenhang sehen die Wissenschaftler die Vermehrung von Rechenzentren und die Entwicklung von mächtigeren Rechenzentren wie KI-Hyperscalers nicht unbedingt nur als Risiko für Gesellschaften, sondern als eine mögliche Chance. Rechenzentren produzieren immer mehr Hitze, was jedoch recycliert werden könnte, um nicht nur Gebäude oder Büros aufzuwärmen, sondern auch die Landwirtschaft dabei zu unterstützen, besser mit natürlichen Ressourcen umzugehen [cite:@KARNAMA2019100063]. Die Hitze, die Rechenzentren produzieren und wie eine verschwendete Energie gesehen werden kann, könnte durch dichte Röhre zu neben von Rechenzentren aufgebauten Foliengewächshäusern geführt werden, um die Temperaturen in solchen Häusern zu stabilisieren. Dies hätte die Folge, dass Gemüse, Pflanzen und Früchte mit niedrigem Energieverbrauch kultiviert werden könnten, die deshalb auch weniger Kosten generieren würden und am Ende des Produktionsprozesses billiger würden. Eine weitere Untersuchung in Schweden simuliert ein solches Szenario, um zu wissen, von welcher Art von Foliengewächshäusern wir in diesem Fall sprechen würden [cite:@LJUNGQVIST2021119169], wenn wir etwa in Sub-Arktis Regionen Tomaten ernten wollten. Die Autoren kommen zum Schluß, dass große Foliengewächshäuser (in ihrer Studie benutzen sie ein Foliengewächshaus von 10.000 Quadratmeter) würden billigere Tomaten als kleinere Foliengewächshäuser (in ihrer Studie 2.000 Quadratmeter) produzieren. Weil sie größer sind haben sie insgesamt weniger Kosten als kleinere Foliengewächshäuser, und der Verbrauch der Hitze von Rechenzentren trägt dazu bei, diese Kosten noch mehr sinken zu lassen. Aber die Produktion von kleineren Foliengewächshäuser wäre nachhaltiger, weil sie wegen ihrer Größe die Hitze von Rechenzentren effizienter einsetzen können bzw. sie auch gebrauchen können, wenn diese Rechenzentren weniger Hitze produzieren (wie etwa im Winter). Dies ist nicht der Fall von großeren Foliengewächshäusern, die aufgrund ihrer Größe die Hitzedefizite der Rechenzentren mit anderen Wärmeanlagen kompensieren müssen.

Diese zwei Beispiele illustrieren die Reichweite des möglichen Einflusses von mit KI-Hyperscalern ausgerüsteten Techkonzernen in verschiedenen gesellschaftlichen Angelegenheiten. Welche Machtbalance sich daraus ergeben würde, bleibt unklar. Um Elias' Bild vom Fussballspiel ein letztes Mal zu verwenden: Wenn Fussballspiele mit immer mehr Spieler in beiden Mannschaften gespielt werden, dann wird das Spiel selbst schwierig, wenn überhaupt spielbar, auch weil das Fußballfeld nicht ausdehnbar ist. Im Fall von Techkonzernen mit KI-Hyperscalern, die begrenzte Ressourcen für ihre Rechenzentren verbrauchen, stellt sich deshalb die Frage, ob solche Machtbalancen mit sehr vielen involvierten Akteuren im Sinne der Gewichtung der Macht in der Gesellschaft funktionieren bzw. konstruktiv für die Gesellschaft eingesetzt werden können. Abgesehen davon, kann jedoch festgestellt, dass große Techkonzernen durch die Entwicklung von ihrer Satellisierungsstrategie ab der Verbreitung von KI-Technologien bereits etwas erreicht haben, was eine Zäsur in der Welt der Rechenzentren einführt, die mit der Trennung von Rechenzentren in der Wissenschaft und der Wirtschaft und Rechenzentren der Informationsgesellschaft gut abgebildet wird. Damit stärken sie die Verbreitung von einer Ordnung von Verhältnisse in der Gesellschaft, die aus medialen Verhältnissen das Gravitationszentrum von allen anderen Arten von Verhältnissen dieser Gesellschaft zu machen versucht.

* Schlussbetrachtung

Mit dem figurationssoziologischen Ansatz Sackmanns und seine Auffassung von Machtbalancen lässt sich gut untersuchen, wie sich heterogene Akteure, die sich gegenseitig aufeinander beziehen, in Konkurrenz geraten, und wie in diesem Zusammenhang Handlungsoptionen definiert werden, die Handlungen leiten bzw. strukturieren. In diesem Vorhaben haben wir den Satellisierungsansatz der Theorie der Relation verwendet, um diesen Ansatz der Machtbalance zu erweitern bzw. um zu verstehen, welche Elemente dazu führen, Machtbalancen zu konsolidieren bzw. sie zu schwächen und zu stören, daraus weitere Satellisierungen anderer Ordnungen von Verhältnissen in der Gesellschaft entwickelt werden. Diesen Vorschlag haben wir an der Frage der Rechenzentren bevorzugt in Deutschland entwickelt. Dabei haben wir dargestellt, wie die deutsche Politik die Frage vom Energieverbrauch bzw. von der Energieeffizienz der Rechenzentren in Deutschland verwendet, um eine eigene Satellisierung von Wissenschaft und Wirtschaft zu entfalten. Diese Satellisierung zielt darauf ab, in der Allianz mit Wissenschaft und Wirtschaft die Rechenzentren zu regulieren und aus dieser Regulation von Rechenzentren eine Stärkung der politischen Repräsentation in den Bereich der Energieeffizienz und im Allgemeinen des verantwortlichen Umgangs mit natürlichen Ressourcen und mit der Umwelt zu gewinnen.

Diese Satellisierungsstrategie argumentiert von einem erprobten Ansatz an der Schnittstelle zwischen Räumlichkeit und Technologien, der jedoch im Zusammenhang von einer Informationsgesellschaft im Werden, davon die Folgen bis 2009 von der deutschen Politik wenig thematisiert werden, immer weniger in der Lage ist, die Komplexität der Entwicklung von Rechenzentren und deren Umwelt adäquat abzubilden. Im Hintergrund von dieser Satellisierung entwickelt sich eine andere Satellisierung von Techkonzernen, die immer mächtiger wird und auf der Grundlage von Rechenzentren einer ganz anderen Art entwickelt wird, die ihre Auffassung der Informationsgesellschaft stützen müssen. Im Zentrum dieser Auffassung der Informationsgesellschaft steht die Vorherrschaft von medialen Verhältnissen als Gravitationszentrum aller anderen Arten von Verhältnissen in der Gesellschaft. Oder um die Begriffe der Theorie der Relation zu verwenden: Es steht die Verbreitung einer medialen Relationsstruktur in allen Bereichen der Gesellschaft zur Stärkung der Satellisierungsstrategie, die solche Techkonzerne entwickeln.

In diesem Zusammenhang verabschieden sich diese Techkonzerne zumindest auf dem Papier von jeglichem Ansatz einer "Green IT" und damit von jeder Art der politischen Regulation. Die Rechenzentren, die sie aufzubauen beabsichtigen, übertreffen im räumlichen Umfang, in technologischer Komplexität und nicht zuletzt im Energieverbrauch alles, was bis jetzt bekannt war. Im aktuellen Stand der Forschung kann nicht zuverlässig beurteilt werden, ob solche Pläne verwirklicht werden können. Was dagegen vorausgesetzt werden kann, ist die Durchsetzung der Satellisierungsstrategie von Techkonzernen, die ein Mittel für sie darstellt, die Rahmenbedingung vom Energieverbrauch in der Gesellschaft zu beeinflussen. Damit beeinträchtigen sie die Satellisierungsstrategie der Politik im Bereich des Energieverbrauches von Rechenzentren, und sie entmachten die Balance, die eine solche Satellisierung zu etablieren versuchte. Wie lange solche Techkonzerne in der Lage sein werden, ihre Satellisierung weiter zu unterstützen, bleibt fraglich. Diese Satellisierung hängt davon ab, ob und wie die Gesellschaft das Leitbild, das eine solche Satellisierung an die Gesellschaft adressiert, in /für/ oder /gegen/ widerstehen wird bzw. wie sie es aufgreift, um ihre Handlung zu strukturieren. Die Konturen von einem solchen Leitbild lassen sich bereits jetzt gut erkennen: Einerseits gibt es eine Gesellschaft, die Energiemängel in Kauf nehmen würde, um andererseits das Leben, dass die von Superrechenzentren gestützte Informationsgesellschaft anbieten würde, weiter genießen zu können. Weniger (verfügbare Energie) soll zu mehr (gesellschaftlichem Leben in der Informationsgesellschaft) führen -- an dieser neuen Umformulierung vom Mythos der Abundanz durch die Techkonzerne hängt jetzt die Etablierung einer neuen Machtbalance in der Gesellschaft ab.

* Literatur

#+cite_export: csl /home/cpsoz/OrgCSL/chicago-author-date.csl
#+print_bibliography:
